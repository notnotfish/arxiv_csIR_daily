<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv cs.IR 每日论文摘要 - 2026年02月03日 12:18:55</title>
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,
        <svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22>
            <ellipse cx=%2250%22 cy=%2275%22 rx=%2235%22 ry=%2220%22 fill=%22%23FFD700%22 stroke=%22%23E6C200%22 stroke-width=%223%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2225%22 ry=%2215%22 fill=%22%23FFF8E7%22/>
            <circle cx=%2240%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2260%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2242%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <circle cx=%2262%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2210%22 ry=%226%22 fill=%22%23FF6B35%22/>
            <path d=%22Q 35 72, 25 85 Q 20 95, 35 95 Q 50 95, 45 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <path d=%22Q 65 72, 75 85 Q 80 95, 65 95 Q 50 95, 55 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <ellipse cx=%2250%22 cy=%2220%22 rx=%2215%22 ry=%2212%22 fill=%22%238B4513%22/>
        </svg>">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #f6f8fa;
            padding: 20px;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: #ffffff;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);
        }

        h1 {
            font-size: 2em;
            margin-bottom: 0.5em;
            padding-bottom: 0.3em;
            border-bottom: 2px solid #eaecef;
            color: #0366d6;
        }

        h2 {
            font-size: 1.5em;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
            padding-bottom: 0.2em;
            border-bottom: 1px solid #eaecef;
        }

        h3 {
            font-size: 1.25em;
            margin-top: 1em;
            margin-bottom: 0.5em;
        }

        p {
            margin-bottom: 1em;
        }

        strong {
            font-weight: 600;
        }

        a {
            color: #0366d6;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        hr {
            border: 0;
            border-top: 1px solid #eaecef;
            margin: 2em 0;
        }

        code {
            background-color: #f6f8fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            font-size: 0.9em;
        }

        pre {
            background-color: #f6f8fa;
            padding: 16px;
            border-radius: 6px;
            overflow-x: auto;
            margin-bottom: 1em;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        .footer {
            margin-top: 3em;
            padding-top: 1em;
            border-top: 1px solid #eaecef;
            text-align: center;
            color: #586069;
            font-size: 0.9em;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }

            body {
                padding: 10px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ArXiv cs.IR 每日论文摘要</h1>
<p><strong>生成时间</strong>: 2026年02月03日 12:18:55<br />
<strong>论文数量</strong>: 20 篇（Top 20）<br />
<strong>排序规则</strong>: 按关键词命中数 + 兴趣评分排序</p>
<hr />
<h2>1. GRAB：一种受大语言模型启发的序列优先点击率预测建模范式</h2>
<p><strong>英文标题</strong>: GRAB: An LLM-Inspired Sequence-First Click-Through Rate Prediction Modeling Paradigm</p>
<p><strong>作者</strong>: Shaopeng Chen、Chuyue Xie、Huimin Ren、Shaozong Zhang、等10人</p>
<p><strong>提交时间</strong>: 2026-02-02 17:38</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.01865v1">查看原文</a></p>
<p><strong>所属公司</strong>: 百度</p>
<p><strong>命中关键词</strong>: 【4】 ranking, recommendation, ctr, causal</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接聚焦于排序阶段的CTR预估核心问题，并创新性地引入了因果推断思想来建模用户行为序列，与重排、价值建模和因果推断等研究方向高度契合。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对传统深度学习推荐模型在泛化能力和长序列建模上的瓶颈，受大语言模型成功经验的启发，提出了一个端到端的生成式点击率预测框架GRAB。其核心创新在于设计了一种新颖的因果动作感知多通道注意力机制，能够有效捕捉用户行为序列中的时序动态和特定动作信号。该模型已在百度广告系统中全面部署，在线实验表明其在收入和点击率上均有显著提升，并且展现出良好的扩展性，即随着使用更长的交互序列，其表达能力呈现单调且近似线性的提升。</p>
<hr />
<h2>2. LLaTTE：大规模广告推荐中多阶段序列建模的缩放定律</h2>
<p><strong>英文标题</strong>: LLaTTE: Scaling Laws for Multi-Stage Sequence Modeling in Large-Scale Ads Recommendation</p>
<p><strong>作者</strong>: Lee Xiong、Zhirong Chen、Rahul Mayuranath、Shangran Qiu、等16人</p>
<p><strong>提交时间</strong>: 2026-01-28 05:59</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.20083v1">查看原文</a></p>
<p><strong>所属公司</strong>: Meta</p>
<p><strong>命中关键词</strong>: 【4】 facebook, ranking, recommendation, uplift</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接涉及推荐系统的核心排序技术，提出了创新的多阶段序列建模架构，并来自Meta这样的知名公司，对重排、价值建模和因果推断方向有重要参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了LLaTTE，一种用于生产环境广告推荐的可扩展Transformer架构。研究发现推荐系统中的序列建模遵循类似大语言模型的幂律缩放规律，并指出语义特征是实现有效缩放的前提条件，能够使模型充分利用更深、更长架构的能力。为在严格延迟约束下实现持续缩放，作者引入了一种两阶段架构，将大型长上下文模型的重计算卸载到异步上游用户模型中，并证明上游改进可预测地传递到下游排序任务。该多阶段框架作为Meta最大的用户模型部署，在Facebook Feed和Reels上实现了4.3%的转化提升，为工业推荐系统利用缩放定律提供了实用蓝图。</p>
<hr />
<h2>3. OneMall：一种架构，更多场景——快手电商端到端生成式推荐家族</h2>
<p><strong>英文标题</strong>: OneMall: One Architecture, More Scenarios -- End-to-End Generative Recommender Family at Kuaishou E-Commerce</p>
<p><strong>作者</strong>: Kun Zhang、Jingming Zhang、Wei Cheng、Yansong Cheng、等28人</p>
<p><strong>提交时间</strong>: 2026-01-29 22:22</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.21770v2">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文系统性地整合了召回、排序及端到端生成式推荐，并利用强化学习进行联合优化，属于推荐系统核心技术的创新性工作。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一个名为OneMall的端到端生成式推荐框架，旨在统一快手电商平台下的多种商品分发场景，包括商品卡片、短视频和直播。其核心创新点在于：首先，设计了一个电商语义分词器，能够捕捉跨场景的真实世界语义和特定业务商品关系；其次，采用基于Transformer的架构，利用Query-Former进行长序列压缩、交叉注意力进行多行为序列融合，以及稀疏MoE实现可扩展的自回归生成；最后，通过强化学习管道连接召回和排序模型，使排序模型能够作为奖励信号，优化端到端的策略召回模型。实验表明，该框架在所有电商场景均取得显著效果提升。</p>
<hr />
<h2>4. 面向内容推荐的领域自适应可扩展稠密检索</h2>
<p><strong>英文标题</strong>: Domain-Adaptive and Scalable Dense Retrieval for Content-Based Recommendation</p>
<p><strong>作者</strong>: Mritunjay Pandey</p>
<p><strong>提交时间</strong>: 2026-02-01 04:58</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.00899v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 amazon, retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文深入研究了推荐系统的核心召回环节，提出了创新的稠密检索方法并实现了高效的工程部署，对推荐算法工程师具有重要参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对电商推荐中关键词稀疏匹配（如BM25）因词汇不匹配导致召回效果差的问题，提出将基于内容的推荐建模为“推荐即检索”任务。核心方法是采用双塔编码器架构，在亚马逊评论数据集上通过监督对比学习和多重负样本排序损失进行微调，利用用户评论作为查询代理、商品元数据作为正样本来构建训练对。创新点在于设计了一个端到端的可扩展稠密检索系统，结合FAISS HNSW索引和ONNX Runtime INT8动态量化推理管道，在82.6万商品规模的评测中，将Recall@10从0.26提升至0.66，同时实现6.1毫秒的中位CPU推理延迟和模型体积减少4倍。</p>
<hr />
<h2>5. 基于对抗对齐与解耦的跨域CTR预测模型：利用全域特征</h2>
<p><strong>英文标题</strong>: Adversarial Alignment and Disentanglement for Cross-Domain CTR Prediction with Domain-Encompassing Features</p>
<p><strong>作者</strong>: Junyou He、Lixi Deng、Huichao Guo、Ye Tang、等2人</p>
<p><strong>提交时间</strong>: 2026-01-24 22:20</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.17472v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 recommendation, ctr, explore, cold-start</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文专注于跨域CTR预估这一推荐系统核心排序问题，并提出了融合对抗对齐与特征解耦的创新方法，对解决冷启动和稀疏性问题有直接参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种名为A²DCDR的创新跨域推荐模型，旨在解决数据稀疏和冷启动问题。模型通过三个关键组件提升性能：采用对抗训练改进最大均值差异（MMD）以增强泛化能力；利用特征解耦器和重构机制实现域内特征解耦；创新性地融合了域不变特征、未对齐特征与原始上下文信息。在真实数据集和在线A/B测试中的实验表明，该模型优于现有方法，验证了其有效性和实用性。</p>
<hr />
<h2>6. 分块、检索与重排：政策文档问答中RAG架构的实证评估</h2>
<p><strong>英文标题</strong>: Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering</p>
<p><strong>作者</strong>: Anuj Maharjan、Umesh Yadav</p>
<p><strong>提交时间</strong>: 2026-01-22 04:52</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.15457v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, ranking, explore, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文深入研究了检索后的重排技术（交叉编码器重排），这是推荐系统排序阶段的核心技术，对提升结果相关性有直接参考价值。</p>
<p><strong>摘要总结</strong>:<br />
本研究针对大语言模型在公共卫生政策领域应用时易产生幻觉的问题，实证评估了检索增强生成架构在政策文档问答中的有效性。研究比较了基础LLM、基础RAG和采用交叉编码器重排的高级RAG三种方案，使用Mistral-7B模型和MiniLM嵌入模型处理CDC政策文档，并分析了递归字符分块和基于语义的令牌分块两种策略对系统准确性的影响。创新点在于通过两阶段检索机制（检索+重排）显著提升了生成内容的忠实度，发现高级RAG架构在忠实度指标上达到0.797，相比基础RAG的0.621和基准模型的0.347有显著改进，证明了重排技术对专业领域问答精度的重要性。</p>
<hr />
<h2>7. 为何链接：社交媒体帖子中包含超链接的意图分类体系</h2>
<p><strong>英文标题</strong>: Why They Link: An Intent Taxonomy for Including Hyperlinks in Social Posts</p>
<p><strong>作者</strong>: Fangping Lan、Abdullah Aljebreen、Eduard C. Dragut</p>
<p><strong>提交时间</strong>: 2026-01-25 05:32</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.17601v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 twitter, retrieval, recommendation, advertising</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文构建的意图分类体系可直接用于提升推荐系统的意图理解和内容相关性，但未深入探讨推荐算法本身的核心技术。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对社交媒体中广泛存在的超链接现象，从读者视角而非作者视角出发，研究用户如何理解帖子中包含超链接的意图。研究方法采用混合方法：首先通过大规模众包标注进行自下而上的数据驱动分析，然后借助大语言模型辅助生成描述性类别名称和精确定义，最终构建了一个包含6个顶层类别和26个细粒度意图类别的分类体系。该研究应用该体系对1000条用户帖子进行标注分析，发现广告、争论和分享是最普遍的意图。这一分类体系为意图感知的信息检索和自然语言处理应用提供了基础，能提升社交媒体内容检索、推荐和理解的准确性。</p>
<hr />
<h2>8. 通过检索增强生成和多目标对齐统一查询自动补全中的排序与生成</h2>
<p><strong>英文标题</strong>: Unifying Ranking and Generation in Query Auto-Completion via Retrieval-Augmented Generation and Multi-Objective Alignment</p>
<p><strong>作者</strong>: Kai Yuan、Anthony Zheng、Jia Hu、Divyanshu Sheth、等7人</p>
<p><strong>提交时间</strong>: 2026-02-01 13:15</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.01023v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接涉及推荐系统的核心排序技术，并创新性地将检索增强生成与多目标对齐应用于工业场景，具有较高的实践参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种统一的查询自动补全框架，将传统检索排序流程与生成式方法相结合，以解决现有方法在长尾覆盖、特征工程和幻觉安全方面的挑战。核心方法包括：将QAC重新定义为端到端列表生成任务，并采用检索增强生成和多目标直接偏好优化进行训练；设计了一套基于规则、模型和LLM作为评判器的验证器，结合RAG、多目标DPO和迭代批判-修订流程来生成高质量合成数据；提出了一种混合服务架构，在严格延迟约束下实现高效生产部署。实验表明，该框架在离线指标、人工评估和在线A/B测试中均取得显著提升，验证了统一生成方法在工业级搜索推荐系统中的有效性。</p>
<hr />
<h2>9. LURE-RAG：面向高效RAG的轻量级效用驱动重排</h2>
<p><strong>英文标题</strong>: LURE-RAG: Lightweight Utility-driven Reranking for Efficient RAG</p>
<p><strong>作者</strong>: Manish Chandra、Debasis Ganguly、Iadh Ounis</p>
<p><strong>提交时间</strong>: 2026-01-27 20:26</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.19535v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接研究重排（Reranking）技术，并采用列表排序损失（listwise ranking loss）进行优化，这与推荐系统排序阶段的核心技术高度相关，且方法具有较好的创新性。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对传统检索增强生成（RAG）管道中基于相关性的检索与下游任务实际效用不匹配的问题，提出了一种轻量级效用驱动重排框架LURE-RAG。该框架的核心创新在于，通过引入基于LambdaMART的重排器，并采用由大语言模型（LLM）效用指导的列表排序损失进行训练，直接优化检索文档的排序顺序以提升生成质量。与现有方法相比，LURE-RAG避免了资源密集型的查询编码过程，且在训练中考虑了文档间的相对顺序对生成结果的关键影响。实验表明，该方法在保持训练和推理高效性的同时，性能可达到当前最优稠密神经基线的97-98%，其稠密变体UR-RAG甚至能超越现有最佳基线达3%。</p>
<hr />
<h2>10. 大语言模型作为编排者：面向推荐系统的约束合规多智能体优化</h2>
<p><strong>英文标题</strong>: LLMs as Orchestrators: Constraint-Compliant Multi-Agent Optimization for Recommendation Systems</p>
<p><strong>作者</strong>: Guilin Zhang、Kai Zhao、Jeffrey Friedman、Xu Chu</p>
<p><strong>提交时间</strong>: 2026-01-27 10:46</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.19121v2">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 amazon, recommendation, diversity</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接针对推荐系统的核心挑战——多目标优化与硬约束满足，并创新性地将LLM用于协调多智能体进行重排优化，与工程师的研究方向高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对推荐系统需同时优化多个目标并满足硬性业务约束（如公平性、覆盖率）的挑战，提出了一个名为DualAgent-Rec的LLM协调双智能体框架。该框架将优化任务分解为两个部分：一个是在硬约束下优先保证准确性的利用智能体，另一个是通过无约束帕累托搜索来促进多样性的探索智能体。创新之处在于引入了一个基于LLM的协调器，根据优化进度和约束满足情况自适应地在两个智能体之间分配资源，并采用自适应epsilon松弛机制保证最终解的可行性。在Amazon Reviews 2023数据集上的实验表明，该方法实现了100%的约束满足率，并将帕累托超体积提升了4-6%，同时保持了有竞争力的准确性与多样性权衡。</p>
<hr />
<h2>11. GenCI：基于群体意图学习的生成式用户兴趣漂移建模用于CTR预测</h2>
<p><strong>英文标题</strong>: GenCI: Generative Modeling of User Interest Shift via Cohort-based Intent Learning for CTR Prediction</p>
<p><strong>作者</strong>: Kesha Ou、Zhen Tian、Wayne Xin Zhao、Hongyu Lu、等1人</p>
<p><strong>提交时间</strong>: 2026-01-26 16:15</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.18251v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 ranking, ctr, advertising</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接针对CTR预测的核心问题，提出了结合生成式建模和上下文感知排序的创新框架，对推荐系统排序阶段有重要参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对CTR预测中存在的两个关键问题提出GenCI框架：一是现有判别式模型容易过度拟合历史主导特征，难以适应快速变化的用户兴趣；二是点对点排序范式忽略了召回集合整体的丰富上下文信息，导致长期偏好掩盖了用户的即时意图。GenCI采用生成式建模方法，通过下一项预测目标训练生成模型，主动生成候选兴趣群体作为用户即时意图的显式表示。然后通过分层候选感知网络将这些上下文信号注入排序阶段，利用交叉注意力机制使其与用户历史和目标商品对齐。整个模型端到端训练，构建了更对齐且有效的CTR预测流程。在三个广泛使用的数据集上的实验证明了该方法的有效性。</p>
<hr />
<h2>12. 按需思考：基于大语言模型排序的模型感知推理路由</h2>
<p><strong>英文标题</strong>: Think When Needed: Model-Aware Reasoning Routing for LLM-based Ranking</p>
<p><strong>作者</strong>: Huizhong Guo、Tianjun Wei、Dongxia Wang、Yingpeng Du、等3人</p>
<p><strong>提交时间</strong>: 2026-01-26 13:09</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.18146v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接针对推荐系统中的排序任务，提出了创新的推理路由框架来平衡效果与效率，与推荐系统核心技术高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对大语言模型应用于检索和推荐排序任务时，推理提示技术带来的计算成本高且效果不稳定的问题，提出了一种推理路由框架。核心方法是设计一个轻量级、即插即用的路由头，在生成前根据预生成信号（包括紧凑的排序感知特征和模型感知的难度信号）为每个实例决策是直接推理还是进行复杂推理。创新点在于通过可控令牌实现推理模式的动态选择，并能在部署时沿验证帕累托前沿自适应调整策略，从而在系统约束变化下将计算资源动态分配给最可能受益于推理的实例。实验表明该方法在多个公开排序数据集上能显著提升排序效果并大幅降低计算开销。</p>
<hr />
<h2>13. PI2I：一种个性化的基于物品的协同过滤召回框架</h2>
<p><strong>英文标题</strong>: PI2I: A Personalized Item-Based Collaborative Filtering Retrieval Framework</p>
<p><strong>作者</strong>: Shaoqing Wang、Yingcai Ma、Kairui Fu、Ziyang Wang、等3人</p>
<p><strong>提交时间</strong>: 2026-01-23 23:10</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.16815v1">查看原文</a></p>
<p><strong>所属公司</strong>: 阿里巴巴（淘宝）</p>
<p><strong>命中关键词</strong>: 【3】 taobao, retrieval, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文聚焦于推荐系统的核心召回阶段，提出了创新的两阶段个性化框架，并在淘宝真实场景中验证了效果，具有较高的实践参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对传统协同过滤和双塔模型在捕捉复杂用户-物品交互时存在的不足，提出了一个名为PI2I的两阶段个性化召回框架。该框架在第一阶段通过放宽截断阈值来优化检索池，以最大化命中率；在第二阶段引入交互式评分模型，克服了内积计算的局限性，从而能更丰富地建模用户-物品交互。此外，论文还基于触发-目标关系构建负样本，确保了离线训练与在线推理的一致性。在淘宝“猜你喜欢”场景的线上部署中，该框架实现了交易率1.05%的提升。</p>
<hr />
<h2>14. PRISM：用于生成式序列推荐的净化表示与集成语义建模</h2>
<p><strong>英文标题</strong>: PRISM: Purified Representation and Integrated Semantic Modeling for Generative Sequential Recommendation</p>
<p><strong>作者</strong>: Dengzhao Fang、Jingtong Gao、Yu Li、Xiangyu Zhao、等1人</p>
<p><strong>提交时间</strong>: 2026-01-23 16:50</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.16556v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接针对推荐系统的核心环节（召回与排序的统一建模），提出了创新的语义量化与生成框架，对解决实际推荐问题具有较高参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对生成式序列推荐（GSR）中存在的两大关键问题提出了PRISM框架。首先，通过设计净化语义量化器，采用自适应协同去噪和分层语义锚定机制构建鲁棒码本，解决了传统量化方法因交互噪声和码本坍缩导致的语义ID歧义问题。其次，提出集成语义推荐器，通过动态语义集成机制融合细粒度语义信息，并利用语义结构对齐目标增强生成的逻辑有效性，弥补了离散化过程中的信息损失。实验表明，PRISM在四个真实数据集上显著优于现有基线，尤其在数据稀疏场景下性能提升明显。</p>
<hr />
<h2>15. 通过上下文老虎机优化用户档案以实现检索增强的大语言模型个性化</h2>
<p><strong>英文标题</strong>: Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization</p>
<p><strong>作者</strong>: Linfeng Du、Ye Yuan、Zichen Zhao、Fuyuan Lyu、等7人</p>
<p><strong>提交时间</strong>: 2026-01-17 23:05</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.12078v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文提出的PURPLE框架将用户档案构建建模为排序问题，并采用Plackett-Luce模型处理集合生成中的依赖关系，与推荐系统中的重排和多样性优化技术高度相关，具有较好的创新性。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对大语言模型个性化响应中，传统基于语义相关性的检索增强方法存在不足的问题，提出了PURPLE框架。该方法将用户档案构建视为一个集合生成过程，利用Plackett-Luce排序模型捕捉记录间复杂的依赖关系，而非贪婪选择最相关记录。通过使用参考响应的似然概率作为密集反馈进行训练，使检索直接与生成质量对齐，在九个个性化任务上的实验表明其在效果和效率上均优于现有基线方法。</p>
<hr />
<h2>16. LANCER：基于大语言模型的子信息覆盖重排方法</h2>
<p><strong>英文标题</strong>: LANCER: LLM Reranking for Nugget Coverage</p>
<p><strong>作者</strong>: Jia-Huei Ju、François G. Landry、Eugene Yang、Suzan Verberne、等1人</p>
<p><strong>提交时间</strong>: 2026-01-30 01:16</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.22008v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索结果重排以优化信息覆盖，与推荐系统中的多样性、覆盖度优化有相关性，但并非直接针对传统推荐场景（如CTR预估、LTV建模）。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对长文本检索增强生成任务中信息覆盖不足的问题，提出了一种名为LANCER的大语言模型重排方法。该方法的核心创新在于：首先预测满足信息需求所需的子问题集合，然后判断各文档能回答哪些子问题，最后通过重排文档以最大化覆盖尽可能多的信息单元。实验表明，LANCER在信息覆盖指标（如α-nDCG）上优于其他基于大语言模型的重排方法，且子问题生成被证明是关键环节。</p>
<hr />
<h2>17. XProvence：面向检索增强生成的多语言零成本上下文剪枝模型</h2>
<p><strong>英文标题</strong>: XProvence: Zero-Cost Multilingual Context Pruning for Retrieval-Augmented Generation</p>
<p><strong>作者</strong>: Youssef Mohamed、Mohamed Elhoseiny、Thibault Formal、Nadezhda Chirkova</p>
<p><strong>提交时间</strong>: 2026-01-27 03:00</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.18886v1">查看原文</a></p>
<p><strong>所属公司</strong>: NAVER</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, explore</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索与重排（re-ranking）技术，这是推荐系统排序阶段的相关技术，但核心应用场景是问答而非典型推荐。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了XProvence模型，这是一种面向检索增强生成（RAG）的多语言零成本上下文剪枝方法。该方法基于Provence框架，通过在多语言数据集（16种语言）上进行训练，并利用有效的跨语言迁移能力，可支持超过100种语言。研究探索了多种策略，将原本仅适用于英语的高效零成本上下文剪枝与重排模型集成的框架推广到多语言场景。在四个多语言问答基准测试中，XProvence能够在几乎不损失性能的情况下有效剪枝RAG上下文，并优于多个强基线模型。</p>
<hr />
<h2>18. 基于大语言模型的金融技术专利实时引文推荐</h2>
<p><strong>英文标题</strong>: LLM-powered Real-time Patent Citation Recommendation for Financial Technologies</p>
<p><strong>作者</strong>: Tianang Deng、Yu Deng、Tianchen Gao、Yonghong Hu、等1人</p>
<p><strong>提交时间</strong>: 2026-01-23 22:21</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.16775v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及推荐系统的召回（近似最近邻搜索）和排序（语义相似度排序）阶段，但未深入探讨重排、价值建模或因果推断等推荐系统核心方向。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对金融技术领域专利快速增长、更新频繁的特点，提出了一种实时专利引文推荐框架。该方法采用三阶段流程：首先利用大语言模型（LLM）生成专利摘要的语义嵌入表示；然后通过高效的近似最近邻搜索（基于HNSW图）构建候选集；最后根据语义相似度对候选专利进行排序，生成top-k推荐。核心创新在于采用增量索引策略，能够在不重建整个索引的情况下动态添加新专利，显著降低了计算成本并提高了召回率，有效解决了传统静态索引或定期重训练方法在动态环境中的局限性。</p>
<hr />
<h2>19. 科学信息的“三巨头”：Web of Science、Scopus和OpenAlex的比较文献计量综述</h2>
<p><strong>英文标题</strong>: The 'Big Three' of Scientific Information: A comparative bibliometric review of Web of Science, Scopus, and OpenAlex</p>
<p><strong>作者</strong>: Daniel Torres-Salinas、Wenceslao Arroyo-Machado</p>
<p><strong>提交时间</strong>: 2026-01-30 00:00</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.21908v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 recommendation, explore, diversity</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要关注文献数据库的比较评估，与推荐系统的核心技术（如重排、LTV、因果推断）关联较弱，仅涉及“多样性”这一宽泛概念。</p>
<p><strong>摘要总结</strong>:<br />
该论文对Web of Science核心合集、Scopus和OpenAlex这三个主要的多学科文献数据库进行了比较研究，旨在通过覆盖范围、元数据质量和功能特征的最新证据，为研究评估中的战略决策提供参考。研究方法包括两个互补部分：首先对近期学术文献进行系统综述，分析记录量、开放获取覆盖、语言多样性、参考文献覆盖和元数据质量；随后对2015-2024年期间进行原创的文献计量分析，探讨纵向分布、文献类型、主题分布、语言差异和数据库间的重叠情况。论文的创新点在于提供了对这三个主流数据库全面且最新的比较评估，并提出了十点执行摘要和五项建议，为学术界和评估机构的选择提供了实证依据。</p>
<hr />
<h2>20. FinMetaMind：面向金融知识搜索的自然语言查询系统技术蓝图</h2>
<p><strong>英文标题</strong>: FinMetaMind: A Tech Blueprint on NLQ Systems for Financial Knowledge Search</p>
<p><strong>作者</strong>: Lalit Pant、Shivang Nagar</p>
<p><strong>提交时间</strong>: 2026-01-24 14:30</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.17333v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要关注信息检索中的检索和排序技术，与推荐系统的核心方向（如重排、LTV、因果推断）关联较弱。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种面向金融知识搜索的现代自然语言查询（NLQ）系统技术蓝图，旨在通过自然语言处理、搜索工程和向量数据模型等核心技术，提升金融数据检索的准确性和召回率。论文详细阐述了金融领域NLQ系统的独特需求，设计了离线索引和在线检索的架构组件，并探讨了在金融服务中的实际应用场景。该系统的创新点在于能够高效关联分散的金融对象、事件和关系，通过改进相关性排序、数据新鲜度和实体识别等关键技术，为金融知识搜索提供更深入的洞察。</p>
<hr />
        <div class="footer">
            <p><a href="../../index.html">← 返回主页</a></p>
            <p>生成时间: 2026年02月03日 12:18:55</p>
        </div>
    </div>
</body>
</html>