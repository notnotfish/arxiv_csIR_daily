<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv cs.IR 每日论文摘要 - 2026年02月12日 12:27:16</title>
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,
        <svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22>
            <ellipse cx=%2250%22 cy=%2275%22 rx=%2235%22 ry=%2220%22 fill=%22%23FFD700%22 stroke=%22%23E6C200%22 stroke-width=%223%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2225%22 ry=%2215%22 fill=%22%23FFF8E7%22/>
            <circle cx=%2240%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2260%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2242%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <circle cx=%2262%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2210%22 ry=%226%22 fill=%22%23FF6B35%22/>
            <path d=%22Q 35 72, 25 85 Q 20 95, 35 95 Q 50 95, 45 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <path d=%22Q 65 72, 75 85 Q 80 95, 65 95 Q 50 95, 55 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <ellipse cx=%2250%22 cy=%2220%22 rx=%2215%22 ry=%2212%22 fill=%22%238B4513%22/>
        </svg>">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #f6f8fa;
            padding: 20px;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: #ffffff;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);
        }

        h1 {
            font-size: 2em;
            margin-bottom: 0.5em;
            padding-bottom: 0.3em;
            border-bottom: 2px solid #eaecef;
            color: #0366d6;
        }

        h2 {
            font-size: 1.5em;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
            padding-bottom: 0.2em;
            border-bottom: 1px solid #eaecef;
        }

        h3 {
            font-size: 1.25em;
            margin-top: 1em;
            margin-bottom: 0.5em;
        }

        p {
            margin-bottom: 1em;
        }

        strong {
            font-weight: 600;
        }

        a {
            color: #0366d6;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        hr {
            border: 0;
            border-top: 1px solid #eaecef;
            margin: 2em 0;
        }

        code {
            background-color: #f6f8fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            font-size: 0.9em;
        }

        pre {
            background-color: #f6f8fa;
            padding: 16px;
            border-radius: 6px;
            overflow-x: auto;
            margin-bottom: 1em;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        .footer {
            margin-top: 3em;
            padding-top: 1em;
            border-top: 1px solid #eaecef;
            text-align: center;
            color: #586069;
            font-size: 0.9em;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }

            body {
                padding: 10px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ArXiv cs.IR 每日论文摘要</h1>
<p><strong>生成时间</strong>: 2026年02月12日 12:27:16<br />
<strong>论文数量</strong>: 20 篇（Top 20）<br />
<strong>排序规则</strong>: 按关键词命中数 + 兴趣评分排序</p>
<hr />
<h2>1. 基于大语言模型搜索的生成引擎中输出排名的控制</h2>
<p><strong>英文标题</strong>: Controlling Output Rankings in Generative Engines for LLM-based Search</p>
<p><strong>作者</strong>: Haibo Jin、Ruoxi Chen、Peiyan Zhang、Yifeng Luo、等3人</p>
<p><strong>提交时间</strong>: 2026-02-03 22:59</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.03608v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【5】 amazon, retrieval, ranking, recommendation, explore</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接针对LLM搜索/推荐场景下的结果排序（重排）问题进行创新性方法研究，并构建了大规模评测基准，与推荐系统的排序和公平性高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对基于大语言模型（LLM）的搜索（生成引擎）中，初始检索顺序会严重影响最终推荐结果，导致小企业和独立创作者曝光受限的问题，提出了一种名为CORE的优化方法。CORE的核心创新在于，由于LLM与搜索引擎的交互是黑盒的，它通过向搜索引擎返回的内容中附加精心设计的优化内容（包括基于字符串、推理和评论的三种类型）来间接引导LLM的输出排名。为了在真实场景下评估CORE，作者构建了一个名为ProductBench的大规模基准数据集，涵盖15个产品类别，每个类别包含200个产品及其对应的亚马逊搜索推荐。实验结果表明，CORE在四种具备搜索能力的LLM上，能够以高成功率（例如Top-1达80.3%）提升目标产品的排名，且优于现有方法，同时保持了内容的流畅性。</p>
<hr />
<h2>2. SMES：通过专家稀疏化实现可扩展的多任务推荐</h2>
<p><strong>英文标题</strong>: SMES: Towards Scalable Multi-Task Recommendation via Expert Sparsity</p>
<p><strong>作者</strong>: Yukun Zhang、Si Dong、Xu Wang、Bo Chen、等10人</p>
<p><strong>提交时间</strong>: 2026-02-10 11:56</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.09386v1">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, ranking, recommendation, uplift</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接涉及推荐系统的核心排序技术，提出了创新的多任务学习框架，并已在快手大规模场景中成功应用，对重排和价值建模有重要参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对工业级推荐系统中多任务学习面临的挑战，提出了一种可扩展的稀疏混合专家框架SMES。核心创新在于通过渐进式专家路由机制，将专家激活分解为跨任务共享的专家子集和任务自适应的私有专家，从而在保证实例级稀疏性的同时满足不同任务的容量需求。此外，SMES引入了全局多门负载均衡正则化器，通过调节所有任务的专家利用率来稳定训练。该方法已在快手大规模短视频服务中部署，支持超过4亿日活用户，在线实验表明其在GAUC和用户观看时长方面均取得了稳定提升。</p>
<hr />
<h2>3. 生成式推理重排器</h2>
<p><strong>英文标题</strong>: Generative Reasoning Re-ranker</p>
<p><strong>作者</strong>: Mingfu Liang、Yufei Li、Jay Xu、Kavosh Asadi、等17人</p>
<p><strong>提交时间</strong>: 2026-02-08 10:12</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.07774v2">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, ranking, recommendation, explore</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接聚焦于推荐系统的核心重排阶段，并深入探讨了强化学习奖励设计、推理能力增强等关键技术，与重排、价值建模方向高度契合。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了生成式推理重排器（GR2），这是一个专门为重排任务设计的端到端框架。其核心创新在于三阶段训练流程：首先通过语义ID编码解决工业系统中数十亿非语义ID的可扩展性问题；然后利用大规模LLM生成高质量推理轨迹进行监督微调，以增强模型的推理能力；最后采用解耦裁剪和动态采样策略优化（DAPO）进行强化学习监督，并设计了可验证的奖励函数来优化重排性能。实验表明，GR2在真实数据集上超越了现有最佳方法，且消融实验证实了高级推理轨迹和精心设计的RL奖励对重排效果至关重要。</p>
<hr />
<h2>4. GRAB：一种受大语言模型启发的序列优先点击率预测建模范式</h2>
<p><strong>英文标题</strong>: GRAB: An LLM-Inspired Sequence-First Click-Through Rate Prediction Modeling Paradigm</p>
<p><strong>作者</strong>: Shaopeng Chen、Chuyue Xie、Huimin Ren、Shaozong Zhang、等10人</p>
<p><strong>提交时间</strong>: 2026-02-02 17:38</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.01865v2">查看原文</a></p>
<p><strong>所属公司</strong>: 百度</p>
<p><strong>命中关键词</strong>: 【4】 ranking, recommendation, ctr, causal</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接聚焦于排序阶段的CTR预估核心问题，并创新性地引入了因果推断思想来建模用户行为序列，与重排、价值建模及因果推断等研究方向高度契合。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对传统深度学习推荐模型在泛化能力和长序列建模上的瓶颈，提出了一种受大语言模型成功经验启发的端到端生成式点击率预测框架GRAB。其核心创新在于设计了一种新颖的因果动作感知多通道注意力机制，能够有效捕捉用户行为序列中的时序动态和特定动作信号。通过在百度广告系统的大规模在线部署验证，该模型在收入和点击率上均取得显著提升，并展现出随着交互序列增长而近似线性提升的可扩展性。</p>
<hr />
<h2>5. 基于福利主义公式的多样化相似性搜索</h2>
<p><strong>英文标题</strong>: Welfarist Formulations for Diverse Similarity Search</p>
<p><strong>作者</strong>: Siddharth Barman、Nirjhar Das、Shivam Gupta、Kirankumar Shiragur</p>
<p><strong>提交时间</strong>: 2026-02-09 22:42</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.08742v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, recommendation, diversity, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接涉及推荐系统核心问题（多样性-相关性权衡），提出了理论严谨且可部署的新方法，对重排和多样性优化有重要参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对最近邻搜索（NNS）中兼顾相关性与多样性的需求，提出了基于福利函数（特别是纳什社会福利）的数学经济学理论框架。该方法将多样性视为公平性公理，相关性视为经济效率公理，通过福利函数自适应地、查询依赖地平衡两者，克服了传统约束方法固定多样性水平的局限。论文设计了高效的近似最近邻算法，可在任意标准ANN方法基础上运行，实验证明其能显著提升多样性同时保持高相关性，为检索和推荐系统提供了灵活的参数化权衡控制。</p>
<hr />
<h2>6. RankGR：基于列表直接偏好优化的增强排序生成式检索推荐方法</h2>
<p><strong>英文标题</strong>: RankGR: Rank-Enhanced Generative Retrieval with Listwise Direct Preference Optimization in Recommendation</p>
<p><strong>作者</strong>: Kairui Fu、Changfa Wu、Kun Yuan、Binbin Cao、等7人</p>
<p><strong>提交时间</strong>: 2026-02-09 20:13</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.08575v1">查看原文</a></p>
<p><strong>所属公司</strong>: 阿里巴巴（淘宝）</p>
<p><strong>命中关键词</strong>: 【4】 taobao, retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文聚焦于推荐系统的生成式检索与排序优化，提出了创新的两阶段列表优化框架，并已在淘宝核心场景得到在线验证，与召回、排序等核心技术高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对生成式检索推荐中传统下一词预测范式存在的局限性，提出了一种名为RankGR的增强排序生成式检索方法。该方法将检索过程分解为初始评估阶段和精化评分阶段：在初始评估阶段引入新颖的列表直接偏好优化策略，以更好地建模用户偏好的层次结构和部分序关系；在精化评分阶段则通过轻量级评分模块对候选项目进行精细化评估。两个阶段在一个统一的生成式检索模型下联合优化，确保了系统的一致性和效率。论文还介绍了训练和部署中的多项实用改进，最终实现了一个能够每秒处理近万次请求的实时系统，并在淘宝“猜你喜欢”场景的在线实验中验证了其有效性和可扩展性。</p>
<hr />
<h2>7. QP-OneModel：小红书搜索中多任务查询理解的统一生成式大语言模型</h2>
<p><strong>英文标题</strong>: QP-OneModel: A Unified Generative LLM for Multi-Task Query Understanding in Xiaohongshu Search</p>
<p><strong>作者</strong>: Jianzhao Huang、Xiaorui Huang、Fei Zhao、Yunpeng Liu、等8人</p>
<p><strong>提交时间</strong>: 2026-02-10 23:38</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.09901v1">查看原文</a></p>
<p><strong>所属公司</strong>: 小红书</p>
<p><strong>命中关键词</strong>: 【4】 xiaohongshu, retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接涉及搜索中的排序（ranking）和相关性（relevance）优化，这是推荐系统的核心技术，且来自知名公司小红书，具有较好的创新性和工业落地价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了QP-OneModel，一个用于社交网络服务（SNS）领域多任务查询理解的统一生成式大语言模型。核心方法是将异构的子任务（如NER、词权重、查询改写等）重新表述为统一的序列生成范式，并采用渐进式三阶段对齐策略，最终结合多奖励强化学习进行优化。主要创新点在于：1）通过统一的生成模型替代传统孤立的判别模型流水线，提升了语义理解能力并降低了维护开销；2）引入意图描述生成作为新的高保真语义信号，有效增强了下游任务（如查询改写和排序）的性能；3）模型在离线评估中显著超越基线，并在线上A/B测试中验证了其工业价值，提升了检索相关性和用户留存。</p>
<hr />
<h2>8. PIT：一种用于端到端生成式推荐的动态个性化项目分词器</h2>
<p><strong>英文标题</strong>: PIT: A Dynamic Personalized Item Tokenizer for End-to-End Generative Recommendation</p>
<p><strong>作者</strong>: Huanjie Wang、Xinchen Luo、Honghui Bao、Zhang Zixing、等5人</p>
<p><strong>提交时间</strong>: 2026-02-09 19:28</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.08530v1">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, retrieval, recommendation, uplift</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文聚焦于生成式推荐系统的核心环节——召回（retrieval）的端到端优化，并涉及协同信号建模与动态索引构建，创新性强且来自知名工业界公司，与推荐系统核心技术高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对生成式推荐系统中现有方法依赖静态、解耦的项目分词（tokenization）而忽略协同信号的问题，提出了一种名为PIT的动态个性化项目分词器框架。其核心创新在于采用了一种协同生成架构，通过协同信号对齐来协调协同模式，并利用协同进化学习使项目分词器与生成式推荐器同步更新，从而实现了索引构建与推荐生成的动态、联合、端到端进化。此外，论文还设计了一种一对多的波束索引以确保可扩展性和鲁棒性，便于大规模工业部署。在快手的大规模在线A/B测试中，该框架显著提升了0.402%的应用停留时间，验证了其在动态工业环境中的有效性。</p>
<hr />
<h2>9. 面向内容推荐的领域自适应可扩展稠密检索方法</h2>
<p><strong>英文标题</strong>: Domain-Adaptive and Scalable Dense Retrieval for Content-Based Recommendation</p>
<p><strong>作者</strong>: Mritunjay Pandey</p>
<p><strong>提交时间</strong>: 2026-02-01 04:58</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.00899v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 amazon, retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文深入研究了推荐系统中的召回阶段，提出了创新的稠密检索方法，对实际工程落地有重要参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对电商推荐中关键词匹配存在的词汇不匹配问题，将基于内容的推荐任务转化为检索任务，提出了一种可扩展的稠密检索系统。该方法采用双塔编码器架构，在亚马逊评论数据集上使用带有多重负样本排序损失的监督对比学习进行微调，构建了从评论文本到商品元数据的训练对。系统结合FAISS HNSW索引和ONNX Runtime推理管道，实现了高效的在线服务，在包含82.6万商品的基准测试中，将Recall@10从BM25的0.26提升至0.66，同时满足低延迟和小模型尺寸的实践约束。</p>
<hr />
<h2>10. MSN：一种基于内存的稀疏激活扩展框架，用于大规模工业推荐系统</h2>
<p><strong>英文标题</strong>: MSN: A Memory-based Sparse Activation Scaling Framework for Large-scale Industrial Recommendation</p>
<p><strong>作者</strong>: Shikang Wu、Hui Lu、Jinqiu Jin、Zheng Chai、等8人</p>
<p><strong>提交时间</strong>: 2026-02-07 20:43</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.07526v1">查看原文</a></p>
<p><strong>所属公司</strong>: 字节跳动（Douyin/TikTok）</p>
<p><strong>命中关键词</strong>: 【4】 douyin, retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文聚焦于大规模工业推荐系统的排序环节，提出了创新的稀疏激活与个性化表征检索框架，对提升排序模型性能和效率有直接价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种名为MSN的基于内存的稀疏激活扩展框架，旨在解决大规模工业推荐系统中模型扩展与低延迟部署之间的矛盾。核心方法是通过一个参数化的大型内存动态检索个性化表征，并利用记忆门控机制将其集成到下游特征交互模块中，实现细粒度个性化且计算开销低。创新点包括采用乘积键值记忆（PKM）机制将内存检索复杂度从线性降至亚线性，引入归一化和过参数化技术以平衡内存利用并防止检索崩溃，并设计了定制化的Sparse-Gather算子和采用AirTopK算子来提升工业场景下的训练和推理效率。该框架已在抖音搜索排序系统中成功部署，在离线指标和大规模在线A/B测试中均取得了显著效果提升。</p>
<hr />
<h2>11. OneMall：一种架构，更多场景——快手电商端到端生成式推荐家族</h2>
<p><strong>英文标题</strong>: OneMall: One Architecture, More Scenarios -- End-to-End Generative Recommender Family at Kuaishou E-Commerce</p>
<p><strong>作者</strong>: Kun Zhang、Jingming Zhang、Wei Cheng、Yansong Cheng、等28人</p>
<p><strong>提交时间</strong>: 2026-01-29 22:22</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.21770v2">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文系统性地整合了召回、排序及端到端优化，并创新性地应用了强化学习连接两者，属于推荐系统的核心技术且有较好创新性。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一个名为OneMall的端到端生成式推荐框架，旨在统一快手电商平台下的多种商品分发场景，包括商品卡片、短视频和直播。其核心创新在于：首先，设计了一个电商语义分词器，能够捕捉跨场景的真实世界语义和特定业务商品关系；其次，采用基于Transformer的架构，利用Query-Former进行长序列压缩、交叉注意力进行多行为序列融合，以及稀疏MoE实现可扩展的自回归生成；最后，通过强化学习管道连接召回和排序模型，使排序模型能够作为奖励信号，以优化端到端的策略召回模型。实验表明，OneMall在所有电商场景中都取得了显著效果提升，并已部署服务于数亿日活用户。</p>
<hr />
<h2>12. EST：通过统一建模实现点击率预测的高效扩展定律</h2>
<p><strong>英文标题</strong>: EST: Towards Efficient Scaling Laws in Click-Through Rate Prediction via Unified Modeling</p>
<p><strong>作者</strong>: Mingyang Liu、Yong Bai、Zhangming Chan、Sishuo Chen、等4人</p>
<p><strong>提交时间</strong>: 2026-02-11 20:51</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.10811v1">查看原文</a></p>
<p><strong>所属公司</strong>: 阿里巴巴（淘宝）</p>
<p><strong>命中关键词</strong>: 【3】 taobao, ctr, advertising</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接针对工业级CTR预估的核心技术挑战，提出创新的统一建模框架，并在淘宝广告平台验证了显著业务收益，与推荐系统算法工程师的核心工作高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对工业级点击率预测模型的高效扩展问题，指出现有方法因早期聚合用户行为而丢失细粒度信息，形成扩展瓶颈。作者通过分析CTR预测与大语言模型的本质差异，提出两个关键特性：行为与非行为特征的信息密度不对称性，以及内容丰富信号的模态特定先验。基于此，论文提出高效可扩展Transformer模型，通过轻量级交叉注意力模块修剪冗余自交互以聚焦高影响力跨特征依赖，并利用内容稀疏注意力模块基于内容相似性动态选择高信号行为，实现所有原始输入的无损统一序列建模。实验表明该模型具有稳定高效的能量律扩展关系，在淘宝展示广告平台部署后实现了显著的RPM和CTR提升。</p>
<hr />
<h2>13. 学习缓解视频推荐中的熟悉度偏差</h2>
<p><strong>英文标题</strong>: Learning to Alleviate Familiarity Bias in Video Recommendation</p>
<p><strong>作者</strong>: Zheng Ren、Yi Wu、Jianan Lu、Acar Ary、等3人</p>
<p><strong>提交时间</strong>: 2026-02-08 22:27</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.07987v1">查看原文</a></p>
<p><strong>所属公司</strong>: YouTube（Google）</p>
<p><strong>命中关键词</strong>: 【3】 ranking, recommendation, diversity</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接涉及推荐系统的重排阶段，专注于解决熟悉度偏差这一核心排序问题，并来自YouTube这一知名工业界平台，具有明确的工程落地价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对视频推荐系统中存在的结构性曝光不平衡问题，提出了一种轻量级且模型无关的后排序框架LAFB，旨在缓解推荐结果中的熟悉度偏差。该方法通过离散和连续的交互特征建模用户与内容的熟悉度，并估计个性化的去偏因子来调整用户评分预测分数，从而减少熟悉内容在最终排序中的主导地位。研究在真实推荐系统中进行了大规模离线评估和在线A/B测试，结果表明LAFB能够提高新颖内容的观看时长占比、增加新兴创作者的曝光机会并提升整体内容多样性，同时保持总体观看时长和短期用户满意度稳定。该框架已在YouTube推荐系统的后排序阶段部署，验证了其在实际应用中的有效性。</p>
<hr />
<h2>14. ChainRec：一种能够为多样且不断演化的兴趣学习路由工具链的智能推荐代理</h2>
<p><strong>英文标题</strong>: ChainRec: An Agentic Recommender Learning to Route Tool Chains for Diverse and Evolving Interests</p>
<p><strong>作者</strong>: Fuchun Li、Qian Li、Xingyu Gao、Bocheng Pan、等6人</p>
<p><strong>提交时间</strong>: 2026-02-11 11:50</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.10490v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 amazon, recommendation, cold-start</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文聚焦于推荐系统的智能体架构和动态决策规划，虽未直接涉及重排、LTV或因果推断，但其在解决冷启动和兴趣演化等核心推荐挑战方面有显著创新。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种名为ChainRec的新型智能推荐系统，旨在解决现有基于大语言模型的推荐方法工作流程固定、无法适应多样化用户场景的问题。其核心创新在于构建了一个标准化的工具代理库，并训练了一个规划器，通过监督微调和偏好优化来动态选择推理工具、决定工具执行顺序以及判断何时停止推理。该方法在冷启动和兴趣演化等动态场景下表现尤为突出，在多个公开数据集上的实验表明其性能优于现有基线模型。消融研究进一步验证了工具标准化和偏好优化规划的重要性。</p>
<hr />
<h2>15. 基于单轮大语言模型查询重构的多阶段混合重排序方法用于舌尖效应已知项检索</h2>
<p><strong>英文标题</strong>: Single-Turn LLM Reformulation Powered Multi-Stage Hybrid Re-Ranking for Tip-of-the-Tongue Known-Item Retrieval</p>
<p><strong>作者</strong>: Debayan Mukhopadhyay、Utshab Kumar Ghosh、Shubham Chatterjee</p>
<p><strong>提交时间</strong>: 2026-02-11 05:59</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.10321v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文深入研究了多阶段重排序技术，与推荐系统的排序阶段高度相关，且提出了创新的轻量级查询重构方法。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对舌尖效应（ToT）检索中用户使用模糊描述查找已知项目的难题，提出了一种轻量级解决方案。核心方法是通过单次调用通用8B参数大语言模型进行查询重构，将表述不清的查询转化为更精确的信息需求，有效解决了传统伪相关反馈因初始召回率低而失效的问题。创新点在于无需对LLM进行领域微调，仅通过提示策略即可实现性能提升，并将重构后的查询输入多阶段检索管道（包括稀疏检索、稠密/延迟交互重排、交叉编码和列表式重排）。实验表明，该方法在TREC-ToT数据集上显著提升了召回率和排序指标，为下游排序器提供了高效的前置干预。</p>
<hr />
<h2>16. 查询混合兴趣提取与异构交互：面向工业推荐系统的可扩展CTR模型</h2>
<p><strong>英文标题</strong>: Query-Mixed Interest Extraction and Heterogeneous Interaction: A Scalable CTR Model for Industrial Recommender Systems</p>
<p><strong>作者</strong>: Fangye Wang、Guowei Yang、Xiaojiang Zhou、Song Yang、等1人</p>
<p><strong>提交时间</strong>: 2026-02-10 11:56</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.09387v1">查看原文</a></p>
<p><strong>所属公司</strong>: 阿里巴巴（AMAP平台）</p>
<p><strong>命中关键词</strong>: 【3】 ranking, recommendation, ctr</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文聚焦于工业级CTR排序模型的核心技术，在用户兴趣建模和特征交互机制上提出了创新性方法，具有明确的工程落地价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对工业推荐系统中多域输入稀疏和用户行为序列超长带来的挑战，提出了一种名为HeMix的可扩展排序模型。其核心创新在于设计了查询混合兴趣提取模块，通过动态和固定查询联合建模全局与实时行为序列中的上下文相关与上下文无关的用户兴趣。同时，模型采用异构混合器模块替代自注意力机制，实现了高效、多粒度的跨特征交互，通过多头令牌融合、异构交互和组对齐重建流程提升预测性能。实验表明，该模型在工业数据集上表现优异，并已在阿里巴巴的AMAP平台成功部署，带来了显著的在线业务指标提升。</p>
<hr />
<h2>17. 领英的语义搜索系统</h2>
<p><strong>英文标题</strong>: Semantic Search At LinkedIn</p>
<p><strong>作者</strong>: Fedor Borisyuk、Sriram Vasudevan、Muchen Wu、Guoyao Li、等70人</p>
<p><strong>提交时间</strong>: 2026-02-07 09:59</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.07309v1">查看原文</a></p>
<p><strong>所属公司</strong>: LinkedIn</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文深入探讨了搜索场景下的排序系统优化，涉及检索、相关性建模和效率提升等推荐系统核心技术，且来自LinkedIn的工业级实践。</p>
<p><strong>摘要总结</strong>:<br />
该论文介绍了LinkedIn基于大语言模型（LLM）的语义搜索框架，应用于AI职位搜索和AI人才搜索场景。核心方法结合了LLM相关性判断器、基于嵌入的检索系统，以及通过多教师蒸馏训练的小型语言模型，以联合优化相关性和用户参与度。创新点在于提出了一种面向预填充的推理架构，结合模型剪枝、上下文压缩和文本-嵌入混合交互技术，在固定延迟约束下将排序吞吐量提升超过75倍，同时保持接近教师模型的NDCG性能，实现了首个在生产环境中效率可与传统方法媲美的LLM排序系统，显著提升了搜索质量和用户参与度。</p>
<hr />
<h2>18. 密集检索器训练引发的对LLM生成内容的偏好研究</h2>
<p><strong>英文标题</strong>: Training-Induced Bias Toward LLM-Generated Content in Dense Retrieval</p>
<p><strong>作者</strong>: William Xion、Wolfgang Nejdl</p>
<p><strong>提交时间</strong>: 2026-02-11 21:20</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.10833v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索与排序中的偏差问题，与推荐系统的排序环节相关，但未直接聚焦于重排、LTV或因果推断等核心方向。</p>
<p><strong>摘要总结</strong>:<br />
该论文研究了密集检索模型中存在的“来源偏见”现象，即模型倾向于偏好大语言模型（LLM）生成的文本而非人类撰写的文本。作者通过控制实验，对比了在SciFact和NQ320K数据集上使用不同来源数据（人类文本、LLM生成文本、MS MARCO）进行监督微调前后模型的偏好变化。研究发现，这种偏见主要是由训练过程（尤其是使用MS MARCO或LLM生成数据进行微调）诱导产生的，而非密集检索器的固有属性；同时，研究通过为微调后的编码器重新附加语言建模头进行探测，发现困惑度与相关性的关联近乎随机，从而削弱了“低困惑度导致偏见”这一假设的解释力。论文的创新点在于系统性地追踪了偏见的产生阶段与数据源的关系，并挑战了关于偏见成因的既有假设。</p>
<hr />
<h2>19. 谁的名字会出现？基于LLM的学者推荐系统的基准测试与干预式审计</h2>
<p><strong>英文标题</strong>: Whose Name Comes Up? Benchmarking and Intervention-Based Auditing of LLM-Based Scholar Recommendation</p>
<p><strong>作者</strong>: Lisette Espin-Noboa、Gonzalo Gabriel Mendez</p>
<p><strong>提交时间</strong>: 2026-02-10 00:34</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.08873v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, recommendation, diversity</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及推荐系统的多样性评估和检索增强技术，但核心焦点是LLM的审计与基准测试，而非传统的推荐系统核心算法（如重排、LTV建模）。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对大型语言模型在学术专家推荐中的应用，提出了一个名为LLMScholarBench的基准测试框架，用于联合评估模型基础设施和终端用户在推理时的干预措施。研究通过九个指标同时衡量推荐的技术质量和社会代表性，并在物理学专家推荐任务中实例化了该基准，审计了22个LLM在温度变化、代表性约束提示和基于网络搜索的检索增强生成干预下的表现。核心创新在于将终端用户干预纳入审计范围，揭示了这些干预措施（如RAG、约束提示）并非普遍提升性能，而是会重新分配不同维度（如事实性、多样性、公平性）的误差，重塑了推荐效果中的权衡关系。</p>
<hr />
<h2>20. AmharicIR+Instr：用于神经检索和指令调优的双数据集资源</h2>
<p><strong>英文标题</strong>: AmharicIR+Instr: A Two-Dataset Resource for Neural Retrieval and Instruction Tuning</p>
<p><strong>作者</strong>: Tilahun Yeshambel、Moncef Garouani、Josiane Mothe</p>
<p><strong>提交时间</strong>: 2026-02-10 23:45</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.09914v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要涉及信息检索领域的神经检索和排序，与推荐系统的核心方向（如重排、LTV、因果推断）关联较弱。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对低资源语言阿姆哈拉语，发布了一个包含两个高质量数据集的数据资源，以支持神经检索排序和指令跟随文本生成的研究。检索排序数据集包含1091个经过人工验证的查询-正例-负例文档三元组，通过专家策划、网络采集和LLM辅助生成相结合的方式构建，支持对比训练和神经检索器的基准测试。指令提示-响应数据集包含6285个阿姆哈拉语提示-响应对，涵盖多个领域和指令类型，由多个LLM生成并经过人工审查和修正，以确保语法、相关性、流畅性和事实合理性。该工作的创新点在于为低资源语言提供了系统化的数据集构建方法论，并发布了标准化格式的数据集，可推广至其他低资源语言，促进检索、排序和生成建模的可复现研究。</p>
<hr />
        <div class="footer">
            <p><a href="../../index.html">← 返回主页</a></p>
            <p>生成时间: 2026年02月12日 12:27:16</p>
        </div>
    </div>
</body>
</html>