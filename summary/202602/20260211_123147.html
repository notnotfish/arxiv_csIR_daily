<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv cs.IR 每日论文摘要 - 2026年02月11日 12:31:47</title>
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,
        <svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22>
            <ellipse cx=%2250%22 cy=%2275%22 rx=%2235%22 ry=%2220%22 fill=%22%23FFD700%22 stroke=%22%23E6C200%22 stroke-width=%223%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2225%22 ry=%2215%22 fill=%22%23FFF8E7%22/>
            <circle cx=%2240%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2260%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2242%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <circle cx=%2262%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2210%22 ry=%226%22 fill=%22%23FF6B35%22/>
            <path d=%22Q 35 72, 25 85 Q 20 95, 35 95 Q 50 95, 45 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <path d=%22Q 65 72, 75 85 Q 80 95, 65 95 Q 50 95, 55 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <ellipse cx=%2250%22 cy=%2220%22 rx=%2215%22 ry=%2212%22 fill=%22%238B4513%22/>
        </svg>">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #f6f8fa;
            padding: 20px;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: #ffffff;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);
        }

        h1 {
            font-size: 2em;
            margin-bottom: 0.5em;
            padding-bottom: 0.3em;
            border-bottom: 2px solid #eaecef;
            color: #0366d6;
        }

        h2 {
            font-size: 1.5em;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
            padding-bottom: 0.2em;
            border-bottom: 1px solid #eaecef;
        }

        h3 {
            font-size: 1.25em;
            margin-top: 1em;
            margin-bottom: 0.5em;
        }

        p {
            margin-bottom: 1em;
        }

        strong {
            font-weight: 600;
        }

        a {
            color: #0366d6;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        hr {
            border: 0;
            border-top: 1px solid #eaecef;
            margin: 2em 0;
        }

        code {
            background-color: #f6f8fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            font-size: 0.9em;
        }

        pre {
            background-color: #f6f8fa;
            padding: 16px;
            border-radius: 6px;
            overflow-x: auto;
            margin-bottom: 1em;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        .footer {
            margin-top: 3em;
            padding-top: 1em;
            border-top: 1px solid #eaecef;
            text-align: center;
            color: #586069;
            font-size: 0.9em;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }

            body {
                padding: 10px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ArXiv cs.IR 每日论文摘要</h1>
<p><strong>生成时间</strong>: 2026年02月11日 12:31:47<br />
<strong>论文数量</strong>: 20 篇（Top 20）<br />
<strong>排序规则</strong>: 按关键词命中数 + 兴趣评分排序</p>
<hr />
<h2>1. 基于LLM搜索的生成引擎中输出排名的控制</h2>
<p><strong>英文标题</strong>: Controlling Output Rankings in Generative Engines for LLM-based Search</p>
<p><strong>作者</strong>: Haibo Jin、Ruoxi Chen、Peiyan Zhang、Yifeng Luo、等3人</p>
<p><strong>提交时间</strong>: 2026-02-03 22:59</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.03608v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【5】 amazon, retrieval, ranking, recommendation, explore</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接研究推荐系统的排序（重排）问题，提出了一种新颖的黑盒优化方法，对提升推荐公平性和可控性有重要价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对基于大语言模型（LLM）的搜索或生成引擎中，初始检索顺序对推荐结果产生强烈偏见、不利于小企业和独立创作者曝光的问题，提出了一种名为CORE的优化方法。CORE通过在搜索引擎返回的内容后附加策略性设计的优化内容（包括基于字符串、推理和评论的三种类型），以黑盒方式引导LLM的输出排名，从而控制推荐结果的排序。研究构建了大规模基准测试ProductBench，并在四种具备搜索能力的LLM上进行了广泛实验，结果表明CORE在Top-5、Top-3和Top-1的排名提升成功率分别达到91.4%、86.6%和80.3%，优于现有排名操纵方法且保持了内容的流畅性。</p>
<hr />
<h2>2. SMES：通过专家稀疏化实现可扩展的多任务推荐</h2>
<p><strong>英文标题</strong>: SMES: Towards Scalable Multi-Task Recommendation via Expert Sparsity</p>
<p><strong>作者</strong>: Yukun Zhang、Si Dong、Xu Wang、Bo Chen、等10人</p>
<p><strong>提交时间</strong>: 2026-02-10 11:56</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.09386v1">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, ranking, recommendation, uplift</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接涉及推荐系统核心的排序和多任务价值建模，且来自知名公司快手，具有明确的工业落地价值和创新性。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对工业级推荐系统中多任务学习面临的挑战，提出了一种可扩展的稀疏专家混合框架SMES。核心创新在于通过渐进式专家路由机制，将专家激活分解为跨任务共享的专家子集和任务自适应的私有专家，从而在保证实例级稀疏性的同时满足不同任务的差异化容量需求。此外，SMES引入了全局多门负载均衡正则化器，通过调节所有任务的专家利用率来稳定训练。该方法已在快手大规模短视频服务中部署，支持超过4亿日活用户，在线实验表明其在GAUC和用户观看时长方面均取得了稳定提升。</p>
<hr />
<h2>3. GRAB：一种受大语言模型启发的序列优先点击率预测建模范式</h2>
<p><strong>英文标题</strong>: GRAB: An LLM-Inspired Sequence-First Click-Through Rate Prediction Modeling Paradigm</p>
<p><strong>作者</strong>: Shaopeng Chen、Chuyue Xie、Huimin Ren、Shaozong Zhang、等10人</p>
<p><strong>提交时间</strong>: 2026-02-02 17:38</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.01865v2">查看原文</a></p>
<p><strong>所属公司</strong>: 百度</p>
<p><strong>命中关键词</strong>: 【4】 ranking, recommendation, ctr, causal</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接聚焦于排序阶段的CTR预估核心问题，并创新性地引入了因果推断思想来建模用户行为序列，与工程师的研究方向高度契合。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对传统深度学习推荐模型在泛化能力和长序列建模上的瓶颈，受大语言模型成功经验的启发，提出了一个端到端的生成式点击率预测框架GRAB。其核心创新在于设计了一种新颖的因果动作感知多通道注意力机制，能够有效捕捉用户行为序列中的时序动态和特定动作信号。该模型已在百度广告系统中全面部署，显著提升了收入和点击率，并展现出良好的扩展性，即随着使用更长的交互序列，其表达能力呈现单调且近似线性的提升。</p>
<hr />
<h2>4. 生成式推理重排器</h2>
<p><strong>英文标题</strong>: Generative Reasoning Re-ranker</p>
<p><strong>作者</strong>: Mingfu Liang、Yufei Li、Jay Xu、Kavosh Asadi、等17人</p>
<p><strong>提交时间</strong>: 2026-02-08 10:12</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.07774v2">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, ranking, recommendation, explore</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接针对推荐系统的核心重排阶段，结合了推理增强、强化学习奖励设计和可扩展语义表示等前沿技术，与重排、价值建模等研究方向高度契合。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种名为GR2的生成式推理重排框架，旨在解决当前LLM在推荐系统重排阶段应用的三个关键局限。该方法采用三阶段训练流程：首先通过语义ID编码器对非语义ID进行转换以实现可扩展性；其次利用大规模LLM生成高质量推理轨迹，并通过监督微调注入基础推理能力；最后设计了一种可扩展的强化学习监督方法DAPO，使用针对重排任务设计的可验证奖励进行优化。实验表明，GR2在真实数据集上超越了现有最佳方法，其中高级推理轨迹和精心设计的强化学习奖励对性能提升至关重要，特别是通过条件可验证奖励有效缓解了模型利用奖励漏洞保持物品顺序的问题。</p>
<hr />
<h2>5. LLaTTE：大规模广告推荐中多阶段序列建模的缩放定律</h2>
<p><strong>英文标题</strong>: LLaTTE: Scaling Laws for Multi-Stage Sequence Modeling in Large-Scale Ads Recommendation</p>
<p><strong>作者</strong>: Lee Xiong、Zhirong Chen、Rahul Mayuranath、Shangran Qiu、等16人</p>
<p><strong>提交时间</strong>: 2026-01-28 05:59</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.20083v1">查看原文</a></p>
<p><strong>所属公司</strong>: Meta</p>
<p><strong>命中关键词</strong>: 【4】 facebook, ranking, recommendation, uplift</p>
<p><strong>感兴趣评分</strong>: 【5分】 论文直接涉及大规模工业推荐系统的排序（ranking）和效果提升（uplift）问题，并提出了创新的多阶段序列建模架构，与推荐系统核心技术高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了LLaTTE，一种用于生产环境广告推荐的可扩展Transformer架构。研究发现推荐系统中的序列建模遵循类似大语言模型的幂律缩放定律，并指出语义特征是实现模型有效缩放的前提条件，能够使模型充分利用更深、更长架构的容量。为在严格延迟约束下实现持续缩放，论文引入了一种两阶段架构，将大型长上下文模型的重计算卸载到异步上游用户模型中，并证明上游改进可预测地传递到下游排序任务。该多阶段框架作为Meta最大的用户模型部署，在Facebook Feed和Reels上实现了4.3%的转化提升，为工业推荐系统利用缩放定律提供了实用蓝图。</p>
<hr />
<h2>6. 基于福利主义公式的多样化相似性搜索</h2>
<p><strong>英文标题</strong>: Welfarist Formulations for Diverse Similarity Search</p>
<p><strong>作者</strong>: Siddharth Barman、Nirjhar Das、Shivam Gupta、Kirankumar Shiragur</p>
<p><strong>提交时间</strong>: 2026-02-09 22:42</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.08742v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, recommendation, diversity, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接研究推荐系统中的核心问题——检索结果的多样性与相关性平衡，并提出了具有理论保证的新算法框架，对推荐系统的重排和多样性优化有直接参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对最近邻搜索（NNS）中兼顾相关性与多样性的需求，提出了基于福利函数（特别是纳什社会福利）的数学框架。该方法将多样性视为公平性公理，将相关性视为经济效率公理，通过福利函数自适应地、查询依赖地平衡两者，突破了以往基于约束的方法固定多样性水平再优化相关性的局限。论文设计了高效的近似最近邻算法，该算法可构建于任何标准ANN方法之上，并提供了参数化控制相关性与多样性权衡的灵活机制。实验表明，该方法能显著提升检索结果的多样性，同时保持较高的相关性。</p>
<hr />
<h2>7. RankGR：基于列表直接偏好优化的增强排序生成式检索推荐方法</h2>
<p><strong>英文标题</strong>: RankGR: Rank-Enhanced Generative Retrieval with Listwise Direct Preference Optimization in Recommendation</p>
<p><strong>作者</strong>: Kairui Fu、Changfa Wu、Kun Yuan、Binbin Cao、等7人</p>
<p><strong>提交时间</strong>: 2026-02-09 20:13</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.08575v1">查看原文</a></p>
<p><strong>所属公司</strong>: 阿里巴巴（淘宝）</p>
<p><strong>命中关键词</strong>: 【4】 taobao, retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文聚焦于推荐系统的生成式检索与排序优化，提出了创新的两阶段列表优化方法，并已在淘宝核心场景得到在线验证，与召回、排序等核心技术高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对生成式检索推荐中传统下一词预测范式存在的局限性，提出了一种名为RankGR的增强排序生成式检索方法。该方法将检索过程分解为初始评估阶段和精化评分阶段：在初始评估阶段引入新颖的列表直接偏好优化策略，以更好地建模用户偏好的层次结构和部分序关系；在精化评分阶段则通过轻量级评分模块对候选结果进行精细化评估。两个阶段在一个统一的生成式检索模型下联合优化，确保了系统的一致性和效率。论文还介绍了训练和部署中的多项实用改进，最终实现了一个能够每秒处理近万次请求的实时系统，并在淘宝“猜你喜欢”场景的在线实验中验证了其有效性和可扩展性。</p>
<hr />
<h2>8. QP-OneModel：小红书搜索中多任务查询理解的统一生成式大语言模型</h2>
<p><strong>英文标题</strong>: QP-OneModel: A Unified Generative LLM for Multi-Task Query Understanding in Xiaohongshu Search</p>
<p><strong>作者</strong>: Jianzhao Huang、Xiaorui Huang、Fei Zhao、Yunpeng Liu、等8人</p>
<p><strong>提交时间</strong>: 2026-02-10 23:38</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.09901v1">查看原文</a></p>
<p><strong>所属公司</strong>: 小红书</p>
<p><strong>命中关键词</strong>: 【4】 xiaohongshu, retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接涉及搜索中的排序（ranking）和相关性（relevance）优化，并展示了提升用户留存（与LTV相关）的在线结果，创新性地使用统一生成模型解决多任务问题，对推荐系统的排序环节有借鉴意义。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了QP-OneModel，一个用于社交网络服务（SNS）领域多任务查询理解的统一生成式大语言模型。核心方法是将异构的子任务（如NER、词权重、查询改写等）重新表述为统一的序列生成范式，并采用渐进式三阶段对齐策略，最终结合多奖励强化学习进行优化。主要创新点在于：1）通过统一的生成模型替代传统孤立的判别模型流水线，提升了语义理解能力和降低了维护成本；2）引入生成意图描述作为高保真语义信号，有效增强了下游任务（如查询改写和排序）的性能；3）模型在离线评估中显著超越基线，并在线上A/B测试中验证了其工业价值，提升了检索相关性和用户留存。</p>
<hr />
<h2>9. PIT：一种用于端到端生成式推荐的动态个性化项目分词器</h2>
<p><strong>英文标题</strong>: PIT: A Dynamic Personalized Item Tokenizer for End-to-End Generative Recommendation</p>
<p><strong>作者</strong>: Huanjie Wang、Xinchen Luo、Honghui Bao、Zhang Zixing、等5人</p>
<p><strong>提交时间</strong>: 2026-02-09 19:28</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.08530v1">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, retrieval, recommendation, uplift</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文聚焦于生成式推荐中的召回（retrieval）环节，提出了动态协同进化的创新架构，并已在快手大规模部署验证，与推荐系统核心技术高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对现有生成式推荐方法中项目标识符（token）静态化、忽略协同信号的问题，提出了一种动态个性化项目分词器框架PIT。其核心创新在于采用协同生成架构，通过协同信号对齐来协调协同模式，并利用协同进化学习使项目分词器与生成式推荐器同步更新，实现了索引构建与推荐生成的动态联合端到端进化。此外，论文还设计了一对多波束索引来确保系统的可扩展性和鲁棒性，便于大规模工业部署。在快手的大规模在线A/B测试中，该框架显著提升了App停留时间0.402%，验证了其在动态工业环境中的有效性。</p>
<hr />
<h2>10. MSN：基于记忆的大规模工业推荐稀疏激活扩展框架</h2>
<p><strong>英文标题</strong>: MSN: A Memory-based Sparse Activation Scaling Framework for Large-scale Industrial Recommendation</p>
<p><strong>作者</strong>: Shikang Wu、Hui Lu、Jinqiu Jin、Zheng Chai、等8人</p>
<p><strong>提交时间</strong>: 2026-02-07 20:43</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.07526v1">查看原文</a></p>
<p><strong>所属公司</strong>: 字节跳动（Douyin/抖音）</p>
<p><strong>命中关键词</strong>: 【4】 douyin, retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文聚焦推荐系统排序环节的核心扩展与效率问题，提出创新的稀疏激活与记忆检索框架，具有明确的工业落地价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对大规模工业推荐系统中模型扩展带来的计算开销和延迟约束问题，提出了一种基于记忆的稀疏激活扩展框架MSN。核心方法是通过参数化记忆库动态检索个性化表征，并利用记忆门控机制将其集成到下游特征交互模块，实现细粒度个性化且计算开销低。创新点包括采用乘积键记忆机制将检索复杂度从线性降至亚线性，引入归一化和过参数化技术平衡记忆利用率，并设计了定制化的稀疏聚集算子和AirTopK算子以提升工业场景下的训练和推理效率。该框架已在抖音搜索排序系统中成功部署，在离线指标和大规模在线A/B测试中均取得了显著效果提升。</p>
<hr />
<h2>11. 面向内容推荐的领域自适应可扩展稠密检索</h2>
<p><strong>英文标题</strong>: Domain-Adaptive and Scalable Dense Retrieval for Content-Based Recommendation</p>
<p><strong>作者</strong>: Mritunjay Pandey</p>
<p><strong>提交时间</strong>: 2026-02-01 04:58</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.00899v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 amazon, retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文深入探讨了推荐系统中的核心召回技术，提出了创新的稠密检索方案并实现了高效的工程部署，对推荐算法工程师有很强的实践参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对电商推荐中关键词匹配因词汇不匹配导致的性能下降问题，提出将基于内容的推荐建模为检索任务：利用自然语言意图信号（查询或评论），通过语义相似性从大规模商品库中检索最相关的商品。核心方法是采用双塔编码器架构，在亚马逊评论数据集上使用带有多负例排序损失的监督对比学习进行微调，构建评论文本与商品元数据的训练对。创新点在于提供了一套端到端的可复现方案，结合FAISS HNSW索引和ONNX Runtime INT8动态量化推理管道，在保证高召回率的同时大幅降低了推理延迟和模型大小，实现了从离线训练到高效在线服务的完整流程。</p>
<hr />
<h2>12. OneMall：一种架构，更多场景——快手电商端到端生成式推荐家族</h2>
<p><strong>英文标题</strong>: OneMall: One Architecture, More Scenarios -- End-to-End Generative Recommender Family at Kuaishou E-Commerce</p>
<p><strong>作者</strong>: Kun Zhang、Jingming Zhang、Wei Cheng、Yansong Cheng、等28人</p>
<p><strong>提交时间</strong>: 2026-01-29 22:22</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.21770v2">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文系统性地整合了召回、排序与端到端生成式推荐，并利用强化学习进行联合优化，与推荐系统核心技术高度相关且创新性较强。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一个名为OneMall的端到端生成式推荐框架，旨在统一快手电商平台下的多种商品分发场景，包括商品卡片、短视频和直播。其核心创新点在于：首先，设计了一个电商语义分词器，能够捕捉跨场景的真实世界语义和特定业务商品关系；其次，采用基于Transformer的架构，利用Query-Former进行长序列压缩、交叉注意力进行多行为序列融合，以及稀疏MoE实现可扩展的自回归生成；最后，构建了一个强化学习管道，通过将排序模型作为奖励信号，连接召回和排序模型，实现端到端的策略召回模型优化。实验表明，OneMall在所有电商场景中都取得了显著的性能提升。</p>
<hr />
<h2>13. 学习缓解视频推荐中的熟悉度偏差</h2>
<p><strong>英文标题</strong>: Learning to Alleviate Familiarity Bias in Video Recommendation</p>
<p><strong>作者</strong>: Zheng Ren、Yi Wu、Jianan Lu、Acar Ary、等3人</p>
<p><strong>提交时间</strong>: 2026-02-08 22:27</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.07987v1">查看原文</a></p>
<p><strong>所属公司</strong>: YouTube（Google）</p>
<p><strong>命中关键词</strong>: 【3】 ranking, recommendation, diversity</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接涉及推荐系统的重排阶段，专注于解决熟悉度偏差这一实际问题，并采用了因果推断相关的去偏技术，且来自YouTube这一知名公司的工业级实践。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对视频推荐系统中存在的结构性曝光不平衡问题，提出了一种轻量级且模型无关的后排序框架LAFB，旨在缓解推荐结果中的熟悉度偏差。该方法通过离散和连续的交互特征建模用户与内容的熟悉度，并估计个性化的去偏因子来调整用户评分预测分数，从而减少熟悉内容在最终排序中的主导地位。研究在真实推荐系统中进行了大规模离线评估和在线A/B测试，结果表明LAFB能够提高新颖内容的观看时长占比、增加新兴创作者的曝光机会并提升整体内容多样性，同时保持总体观看时长和短期用户满意度稳定。该框架已在YouTube推荐系统的后排序阶段上线部署，验证了其在实际应用中的有效性。</p>
<hr />
<h2>14. 查询混合兴趣提取与异构交互：面向工业推荐系统的可扩展CTR模型</h2>
<p><strong>英文标题</strong>: Query-Mixed Interest Extraction and Heterogeneous Interaction: A Scalable CTR Model for Industrial Recommender Systems</p>
<p><strong>作者</strong>: Fangye Wang、Guowei Yang、Xiaojiang Zhou、Song Yang、等1人</p>
<p><strong>提交时间</strong>: 2026-02-10 11:56</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.09387v1">查看原文</a></p>
<p><strong>所属公司</strong>: 阿里巴巴（AMAP平台）</p>
<p><strong>命中关键词</strong>: 【3】 ranking, recommendation, ctr</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文聚焦于工业级CTR排序模型的核心创新，提出了新颖的兴趣提取和异构交互机制，具有很高的工程实践价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对工业推荐系统中多域输入稀疏和用户行为序列超长带来的挑战，提出了一种名为HeMix的可扩展排序模型。其核心创新在于设计了查询混合兴趣提取模块，通过动态和固定查询联合建模全局与实时行为序列中的上下文相关和上下文无关用户兴趣。同时，模型采用异构混合器模块替代自注意力机制，实现了高效的多粒度跨特征交互，包含多头令牌融合、异构交互和组对齐重建流程。实验表明，该模型在工业数据集上表现优异，并已在阿里巴巴的AMAP平台成功部署，带来了显著的在线业务指标提升。</p>
<hr />
<h2>15. 谁的名字被提及？基于LLM的学者推荐系统的基准测试与干预式审计</h2>
<p><strong>英文标题</strong>: Whose Name Comes Up? Benchmarking and Intervention-Based Auditing of LLM-Based Scholar Recommendation</p>
<p><strong>作者</strong>: Lisette Espin-Noboa、Gonzalo Gabriel Mendez</p>
<p><strong>提交时间</strong>: 2026-02-10 00:34</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.08873v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, recommendation, diversity</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接研究推荐系统的多样性、检索增强生成等核心技术，并深入探讨了干预措施对推荐质量多维度权衡的影响，创新性强。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对大型语言模型在学术专家推荐中的应用，提出了一个名为LLMScholarBench的基准测试框架，用于联合评估模型基础设施和终端用户在推理时的干预措施。研究通过九个指标同时衡量推荐的技术质量和社会代表性，并在物理学专家推荐任务中实例化了该基准，审计了22个LLM在温度变化、代表性约束提示和基于网络搜索的检索增强生成干预下的表现。核心创新在于将终端用户干预纳入审计范围，揭示了这些干预措施（如RAG、约束提示）并非普遍提升性能，而是会重新分配不同维度（如事实性、多样性、公平性）的误差，从而重塑了推荐系统的权衡关系。</p>
<hr />
<h2>16. 序列作为节点的对比多模态图推荐</h2>
<p><strong>英文标题</strong>: Sequences as Nodes for Contrastive Multimodal Graph Recommendation</p>
<p><strong>作者</strong>: Bucher Sahyouni、Matthew Vowels、Liqun Chen、Simon Hadfield</p>
<p><strong>提交时间</strong>: 2026-02-07 05:35</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.07208v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 amazon, recommendation, cold-start</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文针对推荐系统的冷启动和稀疏性问题，提出了结合多模态、序列和图学习的创新方法，属于推荐系统核心技术范畴。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种名为MuSICRec的多视图图推荐模型，旨在解决推荐系统中的冷启动和数据稀疏性问题。核心方法是通过注意力池化将用户交互序列构建为序列节点，形成序列-物品图视图，并利用图传播自然生成第二视图，避免了人工数据增强带来的噪声。创新点包括采用ID引导的门控机制调节文本和视觉特征的贡献，以减轻模态噪声并实现多模态信息对齐。实验表明，该模型在多个亚马逊数据集上优于现有基线，尤其对交互历史较短的冷启动用户提升显著。</p>
<hr />
<h2>17. 领英的语义搜索系统</h2>
<p><strong>英文标题</strong>: Semantic Search At LinkedIn</p>
<p><strong>作者</strong>: Fedor Borisyuk、Sriram Vasudevan、Muchen Wu、Guoyao Li、等70人</p>
<p><strong>提交时间</strong>: 2026-02-07 09:59</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.07309v1">查看原文</a></p>
<p><strong>所属公司</strong>: LinkedIn</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文深入探讨了搜索排序系统的核心问题（相关性、效率、用户参与度），并提出了创新的多教师蒸馏和推理优化架构，对推荐系统的排序阶段有直接借鉴价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文介绍了LinkedIn基于大语言模型（LLM）的语义搜索框架，应用于AI职位搜索和AI人才搜索场景。核心方法结合了LLM相关性判断、基于嵌入的检索，以及通过多教师蒸馏训练的小型语言模型，以联合优化相关性和用户参与度。创新点在于提出了一种面向预填充的推理架构，结合模型剪枝、上下文压缩和文本-嵌入混合交互技术，在固定延迟约束下将排序吞吐量提升超过75倍，同时保持接近教师模型的NDCG性能，实现了首个在生产环境中效率可与传统方法媲美的LLM排序系统，显著提升了搜索质量和用户参与度。</p>
<hr />
<h2>18. TokenMixer-Large：在工业级推荐系统中扩展大型排序模型</h2>
<p><strong>英文标题</strong>: TokenMixer-Large: Scaling Up Large Ranking Models in Industrial Recommenders</p>
<p><strong>作者</strong>: Yuchen Jiang、Jie Zhu、Xintian Han、Hui Lu、等17人</p>
<p><strong>提交时间</strong>: 2026-02-06 18:04</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.06563v2">查看原文</a></p>
<p><strong>所属公司</strong>: 字节跳动</p>
<p><strong>命中关键词</strong>: 【3】 ranking, recommendation, advertising</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文聚焦推荐系统核心的排序模型规模化问题，提出了创新的架构改进并在工业场景验证，虽未直接涉及重排/LTV/因果推断，但对大规模排序实践有重要参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对现有大规模推荐模型架构（如Wukong、HiFormer、DHEN）存在的设计次优和硬件利用率不足问题，提出了TokenMixer-Large这一面向超大规模推荐的演进架构。核心创新包括：通过引入混合-还原操作、层间残差连接和辅助损失，解决了深层模型中的梯度消失和残差路径次优问题；采用稀疏逐令牌混合专家（Sparse Per-token MoE）实现高效参数扩展。该方法在在线流量和离线实验中分别成功将参数规模扩展至70亿和150亿，并在字节跳动多个业务场景中部署，显著提升了电商订单量、广告点击率和直播收入等关键指标。</p>
<hr />
<h2>19. LIT-GRAPH：评估深度与浅层图嵌入在领域特定知识图谱中高质量文本推荐的效果</h2>
<p><strong>英文标题</strong>: LIT-GRAPH: Evaluating Deep vs. Shallow Graph Embeddings for High-Quality Text Recommendation in Domain-Specific Knowledge Graphs</p>
<p><strong>作者</strong>: Nirmal Gelal、Chloe Snow、Kathleen M. Jagodnik、Ambyr Rios、等1人</p>
<p><strong>提交时间</strong>: 2026-02-07 09:42</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.07307v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 ranking, recommendation, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及推荐系统的排序和相关性建模，但核心是比较图嵌入技术，与重排、LTV、因果推断等工程师的核心研究方向关联度中等。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了LIT-GRAPH，一个基于知识图谱的推荐系统，旨在帮助高中英语教师选择多样化且符合教学要求的文学作品。研究比较了四种图嵌入方法：DeepWalk、偏置随机游走、两者的混合向量以及深度模型R-GCN。结果表明，浅层模型在结构链接预测上表现优异，而R-GCN则在语义排序方面占据主导，因为它通过关系特定的信息传递机制，优先考虑教学相关性而非原始连接性，从而实现了更高质量的领域特定推荐。</p>
<hr />
<h2>20. AmharicIR+Instr：用于神经检索和指令调优的双数据集资源</h2>
<p><strong>英文标题</strong>: AmharicIR+Instr: A Two-Dataset Resource for Neural Retrieval and Instruction Tuning</p>
<p><strong>作者</strong>: Tilahun Yeshambel、Moncef Garouani、Josiane Mothe</p>
<p><strong>提交时间</strong>: 2026-02-10 23:45</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.09914v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要关注信息检索领域的神经检索和排序，与推荐系统的核心方向（如重排、LTV、因果推断）关联较弱。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对低资源语言阿姆哈拉语，发布了一个包含两个高质量数据集的数据资源，以支持神经检索排序和指令跟随文本生成的研究。检索排序数据集包含1091个经过人工验证的查询-正例-负例文档三元组，通过专家策划、网络采集和LLM辅助生成相结合的方式构建，支持对比训练和神经检索器的基准测试。指令提示-响应数据集包含6285个阿姆哈拉语提示-响应对，涵盖多个领域和指令类型，由多个LLM生成并经过人工审查和修正，以确保语法、相关性、流畅性和事实合理性。该研究提出了一套可推广到其他低资源语言的数据集构建方法论，并提供了标准化的数据分割和格式，旨在促进阿姆哈拉语检索、排序和生成建模的可复现研究。</p>
<hr />
        <div class="footer">
            <p><a href="../../index.html">← 返回主页</a></p>
            <p>生成时间: 2026年02月11日 12:31:47</p>
        </div>
    </div>
</body>
</html>