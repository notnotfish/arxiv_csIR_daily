<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv cs.IR 每日论文摘要 - 2026年02月01日 12:31:39</title>
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,
        <svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22>
            <ellipse cx=%2250%22 cy=%2275%22 rx=%2235%22 ry=%2220%22 fill=%22%23FFD700%22 stroke=%22%23E6C200%22 stroke-width=%223%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2225%22 ry=%2215%22 fill=%22%23FFF8E7%22/>
            <circle cx=%2240%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2260%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2242%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <circle cx=%2262%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2210%22 ry=%226%22 fill=%22%23FF6B35%22/>
            <path d=%22Q 35 72, 25 85 Q 20 95, 35 95 Q 50 95, 45 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <path d=%22Q 65 72, 75 85 Q 80 95, 65 95 Q 50 95, 55 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <ellipse cx=%2250%22 cy=%2220%22 rx=%2215%22 ry=%2212%22 fill=%22%238B4513%22/>
        </svg>">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #f6f8fa;
            padding: 20px;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: #ffffff;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);
        }

        h1 {
            font-size: 2em;
            margin-bottom: 0.5em;
            padding-bottom: 0.3em;
            border-bottom: 2px solid #eaecef;
            color: #0366d6;
        }

        h2 {
            font-size: 1.5em;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
            padding-bottom: 0.2em;
            border-bottom: 1px solid #eaecef;
        }

        h3 {
            font-size: 1.25em;
            margin-top: 1em;
            margin-bottom: 0.5em;
        }

        p {
            margin-bottom: 1em;
        }

        strong {
            font-weight: 600;
        }

        a {
            color: #0366d6;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        hr {
            border: 0;
            border-top: 1px solid #eaecef;
            margin: 2em 0;
        }

        code {
            background-color: #f6f8fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            font-size: 0.9em;
        }

        pre {
            background-color: #f6f8fa;
            padding: 16px;
            border-radius: 6px;
            overflow-x: auto;
            margin-bottom: 1em;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        .footer {
            margin-top: 3em;
            padding-top: 1em;
            border-top: 1px solid #eaecef;
            text-align: center;
            color: #586069;
            font-size: 0.9em;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }

            body {
                padding: 10px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ArXiv cs.IR 每日论文摘要</h1>
<p><strong>生成时间</strong>: 2026年02月01日 12:31:39<br />
<strong>论文数量</strong>: 20 篇（Top 20）<br />
<strong>排序规则</strong>: 按关键词命中数 + 兴趣评分排序</p>
<hr />
<h2>1. LLaTTE：大规模广告推荐中多阶段序列建模的缩放定律</h2>
<p><strong>英文标题</strong>: LLaTTE: Scaling Laws for Multi-Stage Sequence Modeling in Large-Scale Ads Recommendation</p>
<p><strong>作者</strong>: Lee Xiong、Zhirong Chen、Rahul Mayuranath、Shangran Qiu、等16人</p>
<p><strong>提交时间</strong>: 2026-01-28 05:59</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.20083v1">查看原文</a></p>
<p><strong>所属公司</strong>: Meta</p>
<p><strong>命中关键词</strong>: 【4】 facebook, ranking, recommendation, uplift</p>
<p><strong>感兴趣评分</strong>: 【5分】 论文直接涉及推荐系统的核心排序技术，提出了创新的多阶段序列建模架构，并来自Meta这样的知名公司，与重排、价值建模等方向高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了LLaTTE，一种用于生产环境广告推荐的可扩展Transformer架构。研究发现推荐系统中的序列建模遵循类似大语言模型的幂律缩放规律，并指出语义特征是实现模型有效缩放的前提条件，能够使模型充分利用更深、更长架构的容量。为在严格延迟约束下实现持续缩放，作者引入了一种两阶段架构，将大型长上下文模型的重计算卸载到异步上游用户模型中，并证明上游改进可预测地传递到下游排序任务。该多阶段框架作为Meta最大的用户模型部署，在Facebook Feed和Reels上实现了4.3%的转化提升，为工业推荐系统利用缩放定律提供了实用蓝图。</p>
<hr />
<h2>2. STCRank：快手电商交互式推荐系统中的时空协同排序框架</h2>
<p><strong>英文标题</strong>: STCRank: Spatio-temporal Collaborative Ranking for Interactive Recommender System at Kuaishou E-shop</p>
<p><strong>作者</strong>: Boyang Xia、Ruilin Bao、Hanjun Jiang、Jun Wang、等1人</p>
<p><strong>提交时间</strong>: 2026-01-15 11:18</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.10027v1">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, ranking, recommendation, dau</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接针对推荐系统核心的排序问题，提出了创新的多目标协同与序列优化框架，且来自知名公司快手并已实际部署，与重排、价值建模等研究方向高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对快手电商交互式推荐系统面临的独特挑战，提出了一个新颖的时空协同排序框架STCRank。核心挑战包括：全屏沉浸式UI下多个排序目标（转化、浏览、下滑）之间存在显式干扰与冲突，以及序列推荐槽位转换中容易陷入时间贪婪陷阱。为解决这些问题，论文设计了多目标协同模块，通过缓解目标重叠与冲突来推动帕累托前沿；同时提出多槽位协同模块，采用双阶段前瞻排序机制实现整体序列槽位的全局优化。实验表明该方法能同时提升购买率和日活跃用户数，并已于2025年6月在快手电商实际部署。</p>
<hr />
<h2>3. 基于对抗对齐与解耦的跨域CTR预测模型：利用全域特征</h2>
<p><strong>英文标题</strong>: Adversarial Alignment and Disentanglement for Cross-Domain CTR Prediction with Domain-Encompassing Features</p>
<p><strong>作者</strong>: Junyou He、Lixi Deng、Huichao Guo、Ye Tang、等2人</p>
<p><strong>提交时间</strong>: 2026-01-24 22:20</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.17472v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 recommendation, ctr, explore, cold-start</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接针对CTR预估和冷启动问题，提出了融合对抗对齐与特征解耦的创新方法，与推荐系统核心技术高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对跨域推荐中的数据稀疏和冷启动问题，提出了一种名为A²DCDR的创新模型。该方法通过三个关键组件提升性能：首先，结合对抗训练改进最大均值差异（MMD）以增强泛化能力；其次，采用特征解耦器和重构机制实现域内特征解耦；最后，创新性地融合了域不变特征、非对齐特征与原始上下文信息，形成更全面的跨域表征。实验表明，该模型在真实数据集和在线A/B测试中均优于现有方法，验证了其有效性和实用性。</p>
<hr />
<h2>4. OneMall：一个模型，更多场景——快手电商端到端生成式推荐家族</h2>
<p><strong>英文标题</strong>: OneMall: One Model, More Scenarios -- End-to-End Generative Recommender Family at Kuaishou E-Commerce</p>
<p><strong>作者</strong>: Kun Zhang、Jingming Zhang、Wei Cheng、Yansong Cheng、等28人</p>
<p><strong>提交时间</strong>: 2026-01-29 22:22</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.21770v1">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文系统性地整合了召回、排序及端到端生成式推荐，并涉及多场景统一、序列建模和强化学习优化等推荐系统核心技术，创新性强且来自头部公司。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一个名为OneMall的端到端生成式推荐框架，旨在统一快手电商平台下的多种商品分发场景，包括商品卡片、短视频和直播。其核心创新点在于：首先，设计了一个电商语义分词器，能够捕捉跨场景的真实世界语义和特定业务商品关系；其次，采用基于Transformer的架构，利用Query-Former进行长序列压缩、交叉注意力进行多行为序列融合、以及稀疏MoE实现可扩展的自回归生成；最后，通过强化学习管道连接召回和排序模型，使排序模型能够作为奖励信号来优化端到端的策略召回模型。实验表明，OneMall在所有电商场景中都取得了显著效果提升，并已部署服务于数亿日活用户。</p>
<hr />
<h2>5. 为何链接：社交媒体帖子中包含超链接的意图分类体系</h2>
<p><strong>英文标题</strong>: Why They Link: An Intent Taxonomy for Including Hyperlinks in Social Posts</p>
<p><strong>作者</strong>: Fangping Lan、Abdullah Aljebreen、Eduard C. Dragut</p>
<p><strong>提交时间</strong>: 2026-01-25 05:32</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.17601v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 twitter, retrieval, recommendation, advertising</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文构建的意图分类体系可应用于推荐系统的内容理解和用户意图建模，但未直接涉及重排、LTV、因果推断等推荐系统核心算法。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对社交媒体中广泛存在的超链接现象，从读者视角出发，研究用户如何理解帖子中包含超链接的发布者意图。作者采用了一种混合研究方法：首先通过大规模众包标注进行自底向上的数据驱动分析，然后借助大语言模型辅助生成描述性类别名称和精确定义，最终构建了一个包含6个顶层类别和26个细粒度意图类别的分类体系。应用该分类体系对1000条用户帖子进行标注分析，发现广告、争论和分享是最普遍的意图。该分类体系为意图感知的信息检索和自然语言处理应用提供了基础，有助于提升社交媒体内容的检索准确性、推荐效果和理解深度。</p>
<hr />
<h2>6. 分块、检索与重排：政策文档问答中RAG架构的实证评估</h2>
<p><strong>英文标题</strong>: Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering</p>
<p><strong>作者</strong>: Anuj Maharjan、Umesh Yadav</p>
<p><strong>提交时间</strong>: 2026-01-22 04:52</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.15457v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, ranking, explore, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索与重排技术，与推荐系统的排序阶段有相关性，但核心聚焦于问答系统而非典型推荐场景。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对大型语言模型在公共卫生政策领域应用时易产生幻觉的问题，实证评估了检索增强生成架构在政策文档问答中的效果。研究比较了基础LLM、基础RAG和采用交叉编码器重排的高级RAG三种方案，使用Mistral-7B模型和MiniLM嵌入模型处理CDC政策文档，并分析了递归字符分块和基于语义的令牌分块两种策略对系统准确性的影响。创新点在于通过两阶段检索机制（检索+重排）显著提升了生成内容的忠实度，证明了高级RAG架构在专业领域问答中实现高精度的必要性，同时指出文档分割结构仍是多步推理任务的主要瓶颈。</p>
<hr />
<h2>7. 指令检索模型真的能支持探索吗？</h2>
<p><strong>英文标题</strong>: Can Instructed Retrieval Models Really Support Exploration?</p>
<p><strong>作者</strong>: Piyush Maheshwari、Sheshera Mysore、Hamed Zamani</p>
<p><strong>提交时间</strong>: 2026-01-16 09:45</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.10936v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, ranking, explore, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索与排序技术，与推荐系统的召回和排序阶段相关，但未直接聚焦于重排、LTV或因果推断等核心推荐技术。</p>
<p><strong>摘要总结</strong>:<br />
该论文研究了指令检索模型在探索性搜索场景下的表现，特别是针对目标不明确、查询意图动态演变的场景。作者通过专家标注的测试集，评估了微调后的指令检索大模型和采用成对排序提示的通用大模型在方面条件种子引导探索任务中的性能。研究发现，虽然最佳指令检索模型在排序相关性上优于无视指令的方法，但其指令遵循能力（对用户体验至关重要）并未同步提升，甚至表现出对指令不敏感或反直觉的行为。论文的创新点在于首次系统评估了指令检索模型在真实探索性任务中的实际效用，揭示了当前模型在长期探索会话中的局限性。</p>
<hr />
<h2>8. LURE-RAG：面向高效RAG的轻量级效用驱动重排序</h2>
<p><strong>英文标题</strong>: LURE-RAG: Lightweight Utility-driven Reranking for Efficient RAG</p>
<p><strong>作者</strong>: Manish Chandra、Debasis Ganguly、Iadh Ounis</p>
<p><strong>提交时间</strong>: 2026-01-27 20:26</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.19535v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接涉及重排序（reranking）这一推荐系统核心技术，并采用列表排序损失进行优化，与推荐系统中的排序问题高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对传统检索增强生成（RAG）管道中基于相关性的检索与下游任务实际效用不匹配的问题，提出了一种轻量级效用驱动的重排序框架LURE-RAG。该方法的核心创新在于，通过引入基于LambdaMART的重排序器，并采用基于LLM效用的列表排序损失进行训练，直接优化检索文档的排序顺序，从而提升生成文本的质量。与现有方法相比，LURE-RAG在训练和推理阶段均保持高效，并在两个标准数据集上实现了接近最先进密集神经基线的性能（达到97-98%），其密集变体UR-RAG甚至比现有最佳基线高出3%。</p>
<hr />
<h2>9. 大语言模型作为编排者：面向推荐系统的约束合规多智能体优化</h2>
<p><strong>英文标题</strong>: LLMs as Orchestrators: Constraint-Compliant Multi-Agent Optimization for Recommendation Systems</p>
<p><strong>作者</strong>: Guilin Zhang、Kai Zhao、Jeffrey Friedman、Xu Chu</p>
<p><strong>提交时间</strong>: 2026-01-27 10:46</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.19121v2">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 amazon, recommendation, diversity</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接针对推荐系统中的多目标优化和硬约束满足问题，提出了一个结合LLM进行智能体协调的创新框架，与重排、多样性等核心技术高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对推荐系统需同时优化多个目标并满足硬性业务约束（如公平性、覆盖率）的挑战，提出了一个名为DualAgent-Rec的LLM协调双智能体框架。该框架将优化过程分解为两个部分：一个是在硬约束下优先考虑准确性的“利用智能体”，另一个是通过无约束帕累托搜索促进多样性的“探索智能体”。核心创新在于利用大语言模型作为协调器，根据优化进度和约束满足情况自适应地在两个智能体之间分配资源，并引入自适应epsilon松弛机制来保证最终解的可行性。在Amazon Reviews 2023数据集上的实验表明，该方法实现了100%的约束满足率，并将帕累托超体积提升了4-6%，同时保持了有竞争力的准确性与多样性权衡。</p>
<hr />
<h2>10. 按需思考：基于LLM排序的模型感知推理路由</h2>
<p><strong>英文标题</strong>: Think When Needed: Model-Aware Reasoning Routing for LLM-based Ranking</p>
<p><strong>作者</strong>: Huizhong Guo、Tianjun Wei、Dongxia Wang、Yingpeng Du、等3人</p>
<p><strong>提交时间</strong>: 2026-01-26 13:09</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.18146v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接针对推荐系统中的排序任务，提出了创新的推理路由机制来优化LLM的效率和效果，与排序核心技术高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对大型语言模型在检索和推荐排序任务中应用推理提示时存在的计算成本高且效果不一致的问题，提出了一个推理路由框架。该框架通过一个轻量级、即插即用的路由器头，在生成前根据预生成信号（包括紧凑的排序感知特征和模型感知的难度信号）为每个实例决策是采用直接推理模式还是复杂推理模式。创新点在于引入了模型感知的诊断清单来估计推理需求，并允许路由器在部署时沿验证帕累托前沿自适应选择操作策略，从而在系统约束变化下动态分配计算资源。实验表明，该方法在多个公开排序数据集上能显著提升排序效果并大幅减少token消耗，实现了精度与效率的权衡。</p>
<hr />
<h2>11. GenCI：基于群体意图学习的生成式用户兴趣漂移建模用于CTR预测</h2>
<p><strong>英文标题</strong>: GenCI: Generative Modeling of User Interest Shift via Cohort-based Intent Learning for CTR Prediction</p>
<p><strong>作者</strong>: Kesha Ou、Zhen Tian、Wayne Xin Zhao、Hongyu Lu、等1人</p>
<p><strong>提交时间</strong>: 2026-01-26 16:15</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.18251v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 ranking, ctr, advertising</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接针对CTR预测的核心排序问题，提出了结合生成式建模与上下文感知的创新框架，对解决兴趣漂移和上下文信息利用不足有重要价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对CTR预测中存在的两个关键问题提出GenCI框架：一是现有判别式模型过度依赖历史主导特征，难以适应快速变化的用户兴趣；二是点对点排序范式忽略了召回集合的整体上下文信息，导致长期偏好掩盖即时意图。核心方法是通过生成式模型（基于下一项预测目标训练）主动生成候选兴趣群体，作为用户即时意图的显式表示，然后通过分层候选感知网络将这一丰富的上下文信号注入排序阶段，并利用交叉注意力机制使其与用户历史和目标商品对齐。创新点在于首次将生成式建模与群体意图学习结合，通过端到端训练构建更符合用户动态意图的CTR预测流程，在三个公开数据集上的实验验证了其有效性。</p>
<hr />
<h2>12. PI2I：一种个性化的基于物品的协同过滤检索框架</h2>
<p><strong>英文标题</strong>: PI2I: A Personalized Item-Based Collaborative Filtering Retrieval Framework</p>
<p><strong>作者</strong>: Shaoqing Wang、Yingcai Ma、Kairui Fu、Ziyang Wang、等3人</p>
<p><strong>提交时间</strong>: 2026-01-23 23:10</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.16815v1">查看原文</a></p>
<p><strong>所属公司</strong>: 阿里巴巴（淘宝）</p>
<p><strong>命中关键词</strong>: 【3】 taobao, retrieval, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文聚焦于推荐系统的核心召回阶段，提出了创新的两阶段个性化检索框架，并在淘宝大规模场景中验证了效果，具有较高的实用性和创新性。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对传统协同过滤和双塔模型在捕捉复杂用户-物品交互时存在的不足，提出了一个名为PI2I的两阶段个性化检索框架。该框架在第一阶段通过放宽截断阈值来优化检索池，以最大化命中率；在第二阶段引入交互式评分模型，克服了内积计算的局限性，从而能更丰富地建模用户-物品交互。此外，论文还基于触发-目标关系构建负样本，确保离线训练与在线推理的一致性，并在淘宝“猜你喜欢”场景中实现了在线交易率的提升。</p>
<hr />
<h2>13. PRISM：面向生成式序列推荐的净化表示与集成语义建模</h2>
<p><strong>英文标题</strong>: PRISM: Purified Representation and Integrated Semantic Modeling for Generative Sequential Recommendation</p>
<p><strong>作者</strong>: Dengzhao Fang、Jingtong Gao、Yu Li、Xiangyu Zhao、等1人</p>
<p><strong>提交时间</strong>: 2026-01-23 16:50</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.16556v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接针对推荐系统的核心环节（召回与排序的统一建模），提出了创新的语义量化与生成框架，对解决实际推荐中的噪声和稀疏性问题有重要价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对生成式序列推荐（GSR）中存在的两大关键问题提出了PRISM框架。首先，通过设计净化语义量化器，采用自适应协同去噪和分层语义锚定机制构建鲁棒的码本，解决了传统量化方法因交互噪声和码本坍缩导致的语义ID歧义问题。其次，提出集成语义推荐器，通过动态语义集成机制融合细粒度语义，并利用语义结构对齐目标增强逻辑有效性，以弥补量化过程中的信息损失并强化项目层次逻辑。实验表明，PRISM在四个真实数据集上显著优于现有基线，尤其在数据稀疏场景下性能提升明显。</p>
<hr />
<h2>14. 通过上下文老虎机优化用户档案以实现检索增强的大语言模型个性化</h2>
<p><strong>英文标题</strong>: Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization</p>
<p><strong>作者</strong>: Linfeng Du、Ye Yuan、Zichen Zhao、Fuyuan Lyu、等7人</p>
<p><strong>提交时间</strong>: 2026-01-17 23:05</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.12078v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文核心涉及检索与排序的优化，这是推荐系统的核心技术，且提出的基于上下文老虎机和Plackett-Luce模型的集合生成方法对推荐系统的重排和多样性优化有直接借鉴意义。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对大语言模型个性化响应中，传统基于语义相关性的检索增强方法存在不足的问题，提出了一种名为PURPLE的上下文老虎机框架。该方法将用户档案构建视为一个集合生成过程，利用Plackett-Luce排序模型来捕捉记录间复杂的依赖关系，而非贪婪地选择最相关记录。通过使用参考响应似然度提供的密集反馈进行训练，PURPLE直接将检索与生成质量对齐，在九个个性化任务上的实验表明，其在效果和效率上均优于现有启发式和检索增强基线。</p>
<hr />
<h2>15. LANCER：基于大语言模型的子信息覆盖重排方法</h2>
<p><strong>英文标题</strong>: LANCER: LLM Reranking for Nugget Coverage</p>
<p><strong>作者</strong>: Jia-Huei Ju、François G. Landry、Eugene Yang、Suzan Verberne、等1人</p>
<p><strong>提交时间</strong>: 2026-01-30 01:16</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.22008v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文聚焦于重排技术，但其核心目标是优化信息覆盖而非传统推荐系统的相关性或商业指标，与推荐核心场景有一定距离。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对长文本检索增强生成任务中信息覆盖不足的问题，提出了一种名为LANCER的大语言模型重排方法。该方法的核心创新在于通过生成子问题来分解信息需求，预测文档对各个子问题的回答能力，并以此对文档进行重排以最大化信息覆盖。实验结果表明，LANCER在信息覆盖指标（如α-nDCG）上优于其他基于大语言模型的重排方法，且子问题生成被证明是关键环节。该方法将重排目标从传统相关性排序转向信息覆盖优化，为长文本生成任务提供了新的检索优化思路。</p>
<hr />
<h2>16. XProvence：面向检索增强生成的多语言零成本上下文剪枝模型</h2>
<p><strong>英文标题</strong>: XProvence: Zero-Cost Multilingual Context Pruning for Retrieval-Augmented Generation</p>
<p><strong>作者</strong>: Youssef Mohamed、Mohamed Elhoseiny、Thibault Formal、Nadezhda Chirkova</p>
<p><strong>提交时间</strong>: 2026-01-27 03:00</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.18886v1">查看原文</a></p>
<p><strong>所属公司</strong>: NAVER</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, explore</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索与重排（re-ranking）技术，这是推荐系统排序阶段的相关技术，但核心应用场景是问答而非典型推荐。</p>
<p><strong>摘要总结</strong>:<br />
本文提出了XProvence，一种面向检索增强生成（RAG）的多语言零成本上下文剪枝模型。该模型在16种语言上训练，并通过有效的跨语言迁移支持100多种语言，旨在将原本仅适用于英语的Provence框架（首次将高效零成本上下文剪枝直接集成到重排模型中）推广到多语言场景。在四个多语言问答基准测试中，XProvence能够在实现上下文剪枝的同时，将性能下降控制在极小甚至为零的程度，并且优于多个强基线模型。</p>
<hr />
<h2>17. 基于大语言模型的金融技术专利实时引文推荐</h2>
<p><strong>英文标题</strong>: LLM-powered Real-time Patent Citation Recommendation for Financial Technologies</p>
<p><strong>作者</strong>: Tianang Deng、Yu Deng、Tianchen Gao、Yonghong Hu、等1人</p>
<p><strong>提交时间</strong>: 2026-01-23 22:21</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.16775v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及推荐系统的召回（近似最近邻搜索）和排序（语义相似度排序）环节，但未深入探讨重排、价值建模或因果推断等更核心的推荐算法方向。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对金融技术领域专利快速增长、更新频繁的特点，提出了一个实时专利引文推荐框架。核心方法采用三阶段流程：首先利用大语言模型（LLM）嵌入表示专利摘要的语义内容；然后通过高效的近似最近邻搜索构建候选集；最后依据语义相似度对候选专利进行排序，生成Top-K推荐。主要创新点在于采用基于分层可导航小世界（HNSW）图的增量索引策略，支持新专利的实时添加而无需重建整个索引，在动态更新实验中显著提升了召回率并大幅降低了计算成本。该方法在金融专利数据集上优于传统的基于文本的基线方法和替代的最近邻检索方法。</p>
<hr />
<h2>18. Rank4Gen：面向RAG偏好对齐的文档集选择与排序</h2>
<p><strong>英文标题</strong>: Rank4Gen: RAG-Preference-Aligned Document Set Selection and Ranking</p>
<p><strong>作者</strong>: Yongqi Fan、Yuxiang Chu、Zhentao Xia、Xiaoyang Chen、等7人</p>
<p><strong>提交时间</strong>: 2026-01-16 21:19</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.11273v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文聚焦于检索排序与下游任务（生成）的对齐优化，虽涉及排序技术，但核心是RAG场景下的检索-生成协同，与推荐系统的核心排序/LTV建模等直接关联度中等。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对RAG（检索增强生成）中传统检索排序模型仅优化查询-文档相关性，而与生成器在证据选择和引用方面的偏好不一致的问题，提出了Rank4Gen框架。其核心创新在于两点：一是将排序优化目标从相关性转向下游生成响应质量，二是通过单一排序器适配不同生成器来建模生成器特定的排序偏好。为支持该建模，作者构建了PRISM数据集，并在五个RAG基准测试中验证了该方法在复杂证据组合任务上的有效性。</p>
<hr />
<h2>19. 科学信息的“三巨头”：Web of Science、Scopus和OpenAlex的比较文献计量综述</h2>
<p><strong>英文标题</strong>: The 'Big Three' of Scientific Information: A comparative bibliometric review of Web of Science, Scopus, and OpenAlex</p>
<p><strong>作者</strong>: Daniel Torres-Salinas、Wenceslao Arroyo-Machado</p>
<p><strong>提交时间</strong>: 2026-01-30 00:00</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.21908v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 recommendation, explore, diversity</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要关注文献数据库的计量比较，与推荐系统的核心技术（如重排、LTV、因果推断）关联较弱，仅涉及“多样性”等边缘概念。</p>
<p><strong>摘要总结</strong>:<br />
该论文对Web of Science、Scopus和OpenAlex这三个主流多学科文献数据库进行了比较研究，旨在通过系统综述和原创文献计量分析，提供关于其覆盖范围、元数据质量和功能特性的最新证据。研究方法包括对近期学术文献的系统回顾，分析记录量、开放获取覆盖、语言多样性、参考文献覆盖和元数据质量，并对2015-2024年期间的数据进行纵向分布、文档类型、主题分布、语言差异和数据库重叠的原创分析。创新点在于全面比较了三大数据库的优劣，为研究评估中的战略决策提供了实证依据，并提出了十点执行摘要和五项建议。</p>
<hr />
<h2>20. FinMetaMind：面向金融知识搜索的自然语言查询系统技术蓝图</h2>
<p><strong>英文标题</strong>: FinMetaMind: A Tech Blueprint on NLQ Systems for Financial Knowledge Search</p>
<p><strong>作者</strong>: Lalit Pant、Shivang Nagar</p>
<p><strong>提交时间</strong>: 2026-01-24 14:30</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.17333v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要关注信息检索中的检索和相关性排序技术，与推荐系统的核心方向（如重排、LTV、因果推断）关联较弱。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种专门针对金融知识搜索的现代自然语言查询（NLQ）系统技术蓝图。该系统利用自然语言处理、搜索工程和向量数据模型等核心技术，旨在解决金融数据检索中存在的发现、相关性排序、数据新鲜度和实体识别等关键挑战。论文详细阐述了金融数据集和文档对NLQ的独特需求，设计了离线索引和在线检索的架构组件，并通过理论依据和实验证据支持了所提出的架构。</p>
<hr />
        <div class="footer">
            <p><a href="../../index.html">← 返回主页</a></p>
            <p>生成时间: 2026年02月01日 12:31:39</p>
        </div>
    </div>
</body>
</html>