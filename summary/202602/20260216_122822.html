<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv cs.IR 每日论文摘要 - 2026年02月16日 12:28:22</title>
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,
        <svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22>
            <ellipse cx=%2250%22 cy=%2275%22 rx=%2235%22 ry=%2220%22 fill=%22%23FFD700%22 stroke=%22%23E6C200%22 stroke-width=%223%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2225%22 ry=%2215%22 fill=%22%23FFF8E7%22/>
            <circle cx=%2240%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2260%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2242%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <circle cx=%2262%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2210%22 ry=%226%22 fill=%22%23FF6B35%22/>
            <path d=%22Q 35 72, 25 85 Q 20 95, 35 95 Q 50 95, 45 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <path d=%22Q 65 72, 75 85 Q 80 95, 65 95 Q 50 95, 55 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <ellipse cx=%2250%22 cy=%2220%22 rx=%2215%22 ry=%2212%22 fill=%22%238B4513%22/>
        </svg>">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #f6f8fa;
            padding: 20px;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: #ffffff;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);
        }

        h1 {
            font-size: 2em;
            margin-bottom: 0.5em;
            padding-bottom: 0.3em;
            border-bottom: 2px solid #eaecef;
            color: #0366d6;
        }

        h2 {
            font-size: 1.5em;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
            padding-bottom: 0.2em;
            border-bottom: 1px solid #eaecef;
        }

        h3 {
            font-size: 1.25em;
            margin-top: 1em;
            margin-bottom: 0.5em;
        }

        p {
            margin-bottom: 1em;
        }

        strong {
            font-weight: 600;
        }

        a {
            color: #0366d6;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        hr {
            border: 0;
            border-top: 1px solid #eaecef;
            margin: 2em 0;
        }

        code {
            background-color: #f6f8fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            font-size: 0.9em;
        }

        pre {
            background-color: #f6f8fa;
            padding: 16px;
            border-radius: 6px;
            overflow-x: auto;
            margin-bottom: 1em;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        .footer {
            margin-top: 3em;
            padding-top: 1em;
            border-top: 1px solid #eaecef;
            text-align: center;
            color: #586069;
            font-size: 0.9em;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }

            body {
                padding: 10px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ArXiv cs.IR 每日论文摘要</h1>
<p><strong>生成时间</strong>: 2026年02月16日 12:28:22<br />
<strong>论文数量</strong>: 20 篇（Top 20）<br />
<strong>排序规则</strong>: 按关键词命中数 + 兴趣评分排序</p>
<hr />
<h2>1. 基于大语言模型搜索的生成引擎中输出排名的控制</h2>
<p><strong>英文标题</strong>: Controlling Output Rankings in Generative Engines for LLM-based Search</p>
<p><strong>作者</strong>: Haibo Jin、Ruoxi Chen、Peiyan Zhang、Yifeng Luo、等3人</p>
<p><strong>提交时间</strong>: 2026-02-03 22:59</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.03608v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【5】 amazon, retrieval, ranking, recommendation, explore</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接研究推荐系统的核心排序问题，提出了一种新颖的、针对生成式搜索场景的重排优化方法，具有明确的工程应用价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对基于大语言模型的搜索（生成引擎）中，初始检索顺序会严重影响最终推荐结果、导致小企业和独立创作者曝光不足的问题，提出了一种名为CORE的优化方法。CORE的核心创新在于，由于LLM与搜索引擎的交互是黑盒的，它通过向搜索引擎返回的内容中附加精心设计的优化内容来间接影响输出排名，具体提出了字符串型、推理型和评论型三种优化内容。为了在真实场景下评估CORE，作者构建了一个名为ProductBench的大规模基准数据集，包含15个产品类别和每个类别200个产品，并关联了来自亚马逊搜索界面的Top-10推荐。实验结果表明，CORE在四种具备搜索能力的LLM上，能够以高成功率（例如Top-1达80.3%）提升目标产品的排名，且优于现有方法，同时保持了内容的流畅性。</p>
<hr />
<h2>2. RGAlign-Rec：推荐系统中基于排序引导对齐的潜在查询推理方法</h2>
<p><strong>英文标题</strong>: RGAlign-Rec: Ranking-Guided Alignment for Latent Query Reasoning in Recommendation Systems</p>
<p><strong>作者</strong>: Junhua Liu、Yang Jihao、Cheng Chang、Kunrong LI、等2人</p>
<p><strong>提交时间</strong>: 2026-02-13 22:38</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.12968v1">查看原文</a></p>
<p><strong>所属公司</strong>: Shopee（虾皮）</p>
<p><strong>命中关键词</strong>: 【4】 shopee, ranking, recommendation, ctr</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接聚焦于推荐系统的核心排序（ranking）与CTR预估问题，并创新性地将LLM推理与排序目标对齐，属于重排和价值建模的前沿方向，且来自知名电商公司Shopee。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对电商聊天机器人中主动意图预测任务存在的两大挑战——离散用户特征与知识库语义意图之间的语义鸿沟，以及通用大语言模型输出与任务特定排序目标之间的不一致性，提出了RGAlign-Rec框架。该框架的核心创新在于构建了一个闭环对齐系统，将基于LLM的语义推理器与查询增强排序模型相结合，并设计了排序引导对齐的多阶段训练范式，利用下游排序信号作为反馈来优化LLM的潜在推理过程。在Shopee大规模工业数据集上的实验表明，该方法在GAUC、错误率降低和召回率等指标上均有显著提升，在线A/B测试进一步验证了其能有效同步语义推理与排序目标，提升主动推荐系统的预测准确性和服务质量。</p>
<hr />
<h2>3. SMES：通过专家稀疏化实现可扩展的多任务推荐</h2>
<p><strong>英文标题</strong>: SMES: Towards Scalable Multi-Task Recommendation via Expert Sparsity</p>
<p><strong>作者</strong>: Yukun Zhang、Si Dong、Xu Wang、Bo Chen、等10人</p>
<p><strong>提交时间</strong>: 2026-02-10 11:56</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.09386v1">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, ranking, recommendation, uplift</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接针对推荐系统核心的排序和多任务价值建模问题，提出了创新的稀疏MoE架构，并在快手大规模场景中验证了效果，与工程师的研究方向高度契合。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对工业级多任务推荐系统中，模型容量均匀扩展与任务异构性需求不匹配的核心挑战，提出了一种基于参数稀疏化的可扩展解决方案。核心创新是提出了SMES框架，它采用渐进式专家路由机制，将专家激活分解为跨任务联合选择的任务共享专家子集和任务自适应的私有专家，从而在保证实例级稀疏性的同时保留任务特定能力。此外，SMES引入了全局多门负载均衡正则器，通过调节所有任务的聚合专家利用率来稳定训练。该方法已在快手大规模短视频服务中部署，支持超过4亿日活用户，在线实验表明其能稳定提升模型性能，带来用户观看时长的显著增长。</p>
<hr />
<h2>4. 生成式推理重排器</h2>
<p><strong>英文标题</strong>: Generative Reasoning Re-ranker</p>
<p><strong>作者</strong>: Mingfu Liang、Yufei Li、Jay Xu、Kavosh Asadi、等17人</p>
<p><strong>提交时间</strong>: 2026-02-08 10:12</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.07774v3">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, ranking, recommendation, explore</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接聚焦于推荐系统的核心重排阶段，并深入探讨了强化学习奖励设计、推理能力增强等关键技术，与重排、价值建模方向高度契合。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一个名为GR2的生成式推理重排框架，旨在解决当前LLM在推荐系统重排阶段应用的三个关键局限。其核心方法包括三个阶段：首先利用语义ID编码器对非语义ID进行转换以提升可扩展性；然后通过精心设计的提示和拒绝采样生成高质量推理轨迹，用于监督微调以赋予模型基础推理能力；最后提出解耦裁剪和动态采样策略优化算法，结合专为重排设计的可验证奖励进行可扩展的强化学习监督。实验表明，GR2在真实数据集上超越了现有最佳方法，并且消融研究证实了高级推理轨迹和精心设计的强化学习奖励对重排性能至关重要。</p>
<hr />
<h2>5. GRAB：一种受大语言模型启发的序列优先点击率预测建模范式</h2>
<p><strong>英文标题</strong>: GRAB: An LLM-Inspired Sequence-First Click-Through Rate Prediction Modeling Paradigm</p>
<p><strong>作者</strong>: Shaopeng Chen、Chuyue Xie、Huimin Ren、Shaozong Zhang、等10人</p>
<p><strong>提交时间</strong>: 2026-02-02 17:38</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.01865v2">查看原文</a></p>
<p><strong>所属公司</strong>: 百度</p>
<p><strong>命中关键词</strong>: 【4】 ranking, recommendation, ctr, causal</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接聚焦于排序阶段的CTR预估核心问题，并创新性地结合了因果推断和长序列建模技术，且来自知名公司百度，具有很高的实践和理论价值。</p>
<p><strong>摘要总结</strong>:<br />
本文针对传统深度学习推荐模型在泛化能力和长序列建模上的瓶颈，受大语言模型成功经验的启发，提出了一个端到端的生成式点击率预测框架GRAB。该框架的核心创新在于引入了因果行为感知的多通道注意力机制，能够有效捕捉用户行为序列中的时序动态和特定行为信号。在线部署结果表明，GRAB在收入和点击率上均显著超越现有模型，并展现出良好的扩展性，即模型表达能力随着使用更长的交互序列而单调且近似线性地提升。</p>
<hr />
<h2>6. KuaiSearch：一个用于召回、排序和相关性判断的大规模电商搜索数据集</h2>
<p><strong>英文标题</strong>: KuaiSearch: A Large-Scale E-Commerce Search Dataset for Recall, Ranking, and Relevance</p>
<p><strong>作者</strong>: Yupeng Li、Ben Chen、Mingyue Cheng、Zhiding Liu、等3人</p>
<p><strong>提交时间</strong>: 2026-02-12 11:22</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.11518v1">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, ranking, cold-start, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文聚焦于电商搜索的核心流程（召回、排序、相关性），并专门覆盖了冷启动这一推荐系统的重要挑战，具有较好的实践和创新价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对现实电商搜索面临的查询模糊、商品文本噪声大、用户偏好多样等挑战，构建并发布了目前已知最大的电商搜索数据集KuaiSearch。该数据集基于快手平台真实的用户搜索交互数据，保留了原始查询和商品自然语言文本，覆盖了冷启动用户和长尾商品，并系统性地涵盖了搜索流程中的召回、排序和相关性判断三个关键阶段。论文从商品、用户和查询等多个角度对数据集进行了全面分析，并在多个代表性搜索任务上建立了基准实验，为基于大语言模型的真实世界电商搜索研究提供了宝贵基础。</p>
<hr />
<h2>7. 推理排序：利用大语言模型进行推荐的端到端解决方案</h2>
<p><strong>英文标题</strong>: Reasoning to Rank: An End-to-End Solution for Exploiting Large Language Models for Recommendation</p>
<p><strong>作者</strong>: Kehan Zheng、Deyao Hong、Qian Li、Jun Zhang、等3人</p>
<p><strong>提交时间</strong>: 2026-02-13 10:22</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.12530v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 amazon, ranking, recommendation, explore</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接涉及推荐系统的核心排序问题，并创新性地将强化学习与大语言模型推理结合进行端到端优化，具有较高的技术新颖性和实用价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种名为'推理排序'的端到端训练框架，旨在将推荐效用优化内化到大语言模型的分步推理学习中。为了解决大语言模型推理中的位置偏差并实现对推理过程的直接优化，该框架在用户-物品级别进行推理，并采用强化学习对大语言模型进行端到端训练。在三个亚马逊数据集和一个大规模工业数据集上的实验表明，该方法相比传统的强基线方案和基于大语言模型的解决方案均取得了持续的性能提升。深入的组件分析验证了框架中关键设计的必要性，并为该方向未来的发展提供了启示。</p>
<hr />
<h2>8. 基于福利主义公式的多样化相似性搜索</h2>
<p><strong>英文标题</strong>: Welfarist Formulations for Diverse Similarity Search</p>
<p><strong>作者</strong>: Siddharth Barman、Nirjhar Das、Shivam Gupta、Kirankumar Shiragur</p>
<p><strong>提交时间</strong>: 2026-02-09 22:42</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.08742v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, recommendation, diversity, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接针对推荐系统的核心问题——多样性平衡，提出了具有理论保障的新框架和实用算法，创新性强。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对最近邻搜索（NNS）中兼顾相关性与多样性的需求，提出了基于福利函数（特别是纳什社会福利）的数学框架。该方法将多样性视为公平性公理，将相关性视为经济效率公理，通过福利函数自适应地、查询依赖地平衡两者，克服了传统约束方法固定多样性水平的局限。论文设计了高效的近似最近邻算法，可在现有ANN方法基础上运行，实验证明其能显著提升多样性同时保持高相关性，为检索和推荐系统提供了灵活的参数化权衡控制。</p>
<hr />
<h2>9. QP-OneModel：小红书搜索中多任务查询理解的统一生成式大语言模型</h2>
<p><strong>英文标题</strong>: QP-OneModel: A Unified Generative LLM for Multi-Task Query Understanding in Xiaohongshu Search</p>
<p><strong>作者</strong>: Jianzhao Huang、Xiaorui Huang、Fei Zhao、Yunpeng Liu、等8人</p>
<p><strong>提交时间</strong>: 2026-02-10 23:38</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.09901v1">查看原文</a></p>
<p><strong>所属公司</strong>: 小红书</p>
<p><strong>命中关键词</strong>: 【4】 xiaohongshu, retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接涉及搜索中的排序和相关性优化，并提及对用户留存（LTV相关指标）的提升，与推荐系统的核心技术高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了QP-OneModel，一个用于社交网络服务搜索领域多任务查询理解的统一生成式大语言模型。核心方法是将异构的子任务（如NER、词权重、查询改写等）重新表述为统一的序列生成范式，并采用渐进式三阶段对齐策略，最终结合多奖励强化学习进行优化。主要创新点在于：1）通过统一的生成模型替代传统判别模型的流水线，提升了语义理解能力并降低了维护开销；2）生成意图描述作为一种新颖的高保真语义信号，有效增强了下游任务（如查询改写和排序）的性能；3）模型在离线评估中显著超越基线，并在线上A/B测试中验证了其工业价值，提升了检索相关性和用户留存。</p>
<hr />
<h2>10. PIT：一种用于端到端生成式推荐的动态个性化项目分词器</h2>
<p><strong>英文标题</strong>: PIT: A Dynamic Personalized Item Tokenizer for End-to-End Generative Recommendation</p>
<p><strong>作者</strong>: Huanjie Wang、Xinchen Luo、Honghui Bao、Zhang Zixing、等5人</p>
<p><strong>提交时间</strong>: 2026-02-09 19:28</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.08530v1">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, retrieval, recommendation, uplift</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文聚焦于生成式推荐这一前沿方向，其提出的动态协同进化机制对召回/检索阶段的索引构建有重要创新，且已在快手大规模工业场景验证有效。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对生成式推荐中现有方法依赖静态、解耦的项目分词（tokenization）而忽略协同信号的问题，提出了一种动态个性化项目分词器框架PIT。其核心创新在于采用协同生成架构，通过协同信号对齐来协调协同模式，并利用协同进化学习使项目分词器与生成式推荐器同步更新，实现了索引构建与推荐的动态、联合、端到端进化。此外，论文设计了一对多波束索引以确保可扩展性和鲁棒性，便于大规模工业部署，并在快手的大规模在线A/B测试中取得了显著的App停留时长提升。</p>
<hr />
<h2>11. RankGR：基于列表直接偏好优化的增强排序生成式检索推荐方法</h2>
<p><strong>英文标题</strong>: RankGR: Rank-Enhanced Generative Retrieval with Listwise Direct Preference Optimization in Recommendation</p>
<p><strong>作者</strong>: Kairui Fu、Changfa Wu、Kun Yuan、Binbin Cao、等7人</p>
<p><strong>提交时间</strong>: 2026-02-09 20:13</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.08575v1">查看原文</a></p>
<p><strong>所属公司</strong>: 阿里巴巴（淘宝）</p>
<p><strong>命中关键词</strong>: 【4】 taobao, retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文提出了结合列表优化和两阶段检索的生成式推荐方法，在召回和排序的交叉领域有创新，且来自淘宝的工业实践具有较高参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对现有生成式检索方法仅关注下一项预测而忽略用户偏好层次结构和标识符交互的问题，提出了RankGR方法。该方法将检索过程分解为初始评估阶段和精化评分阶段：在初始阶段引入列表直接偏好优化策略，以更好地建模用户偏好的层次结构和部分序关系；在精化阶段使用轻量级评分模块对候选项目进行更精确的评估。两个阶段在统一的生成式检索模型下联合优化，确保了系统的一致性和效率。论文在研究和工业数据集上进行了广泛实验，并在淘宝“猜你喜欢”场景中验证了方法的有效性和可扩展性，实现了每秒近万次请求的实时处理能力。</p>
<hr />
<h2>12. MSN：一种基于内存的稀疏激活扩展框架，用于大规模工业推荐系统</h2>
<p><strong>英文标题</strong>: MSN: A Memory-based Sparse Activation Scaling Framework for Large-scale Industrial Recommendation</p>
<p><strong>作者</strong>: Shikang Wu、Hui Lu、Jinqiu Jin、Zheng Chai、等8人</p>
<p><strong>提交时间</strong>: 2026-02-07 20:43</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.07526v1">查看原文</a></p>
<p><strong>所属公司</strong>: 字节跳动（Douyin/抖音）</p>
<p><strong>命中关键词</strong>: 【4】 douyin, retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文聚焦推荐系统排序环节的核心技术（模型扩展与个性化），提出了创新的稀疏激活框架并已在字节跳动大规模工业场景中验证，虽未直接涉及重排、LTV或因果推断，但对排序模型架构有重要参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种名为MSN的基于内存的稀疏激活扩展框架，旨在解决大规模工业推荐系统中模型扩展带来的计算开销和延迟约束问题。核心方法是通过参数化内存动态检索个性化表征，并利用内存门控机制将其集成到下游特征交互模块，实现细粒度个性化且计算开销低。创新点包括采用乘积键内存（PKM）机制将内存检索复杂度从线性降至亚线性，引入归一化和过参数化技术平衡内存利用率，并设计了定制化的Sparse-Gather算子和AirTopK算子以提升工业场景下的训练和推理效率。该框架已在抖音搜索排序系统中成功部署，在离线评估和大规模在线A/B测试中均取得了显著效果提升。</p>
<hr />
<h2>13. 分析式搜索</h2>
<p><strong>英文标题</strong>: Analytical Search</p>
<p><strong>作者</strong>: Yiteng Tu、Shuo Miao、Weihang Su、Yiqun Liu、等1人</p>
<p><strong>提交时间</strong>: 2026-02-12 13:06</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.11581v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, ranking, relevance, causal</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索、排序、相关性等与推荐系统相关的技术，并重点探讨因果推断在信息检索中的应用，但核心是面向搜索范式而非推荐系统。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种新的搜索范式——分析式搜索，旨在满足法律、金融、科学等领域中趋势分析和因果影响评估等复杂分析性信息需求。论文指出传统基于相关性的文档排序或基于大语言模型的检索增强生成方法难以满足此类任务在语料库规模下的端到端要求，因为它们要么侧重信息查找而非问题解决，要么简单视为问答而缺乏对推理过程、证据使用和可验证性的控制。为此，论文构建了一个统一的系统框架，通过显式建模分析意图、检索融合证据、以及基于结构化多步推理生成可验证结论，将搜索重新定义为证据驱动、过程导向的分析工作流，并探讨了构建分析式搜索引擎的潜在研究方向。</p>
<hr />
<h2>14. EST：通过统一建模实现点击率预测的高效扩展规律</h2>
<p><strong>英文标题</strong>: EST: Towards Efficient Scaling Laws in Click-Through Rate Prediction via Unified Modeling</p>
<p><strong>作者</strong>: Mingyang Liu、Yong Bai、Zhangming Chan、Sishuo Chen、等4人</p>
<p><strong>提交时间</strong>: 2026-02-11 20:51</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.10811v1">查看原文</a></p>
<p><strong>所属公司</strong>: 阿里巴巴（淘宝）</p>
<p><strong>命中关键词</strong>: 【3】 taobao, ctr, advertising</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接针对工业级CTR预估的核心扩展问题，提出创新统一建模架构，并在淘宝广告平台验证了显著业务收益，与推荐系统排序阶段核心技术高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对工业级点击率预测模型的高效扩展问题，指出现有方法因早期聚合用户行为而丢失细粒度信息，形成扩展瓶颈。作者通过分析CTR预测与大语言模型的本质差异，提出两个关键特性：行为与非行为特征的信息密度不对称性，以及内容丰富信号的模态特定先验。为此，论文设计了高效可扩展Transformer模型，通过轻量级交叉注意力模块修剪冗余自交互以聚焦高影响力跨特征依赖，并利用内容稀疏注意力模块基于内容相似性动态选择高信号行为，实现了对所有原始输入的无损统一序列建模。实验表明该模型具有稳定高效的能量律扩展关系，在淘宝展示广告平台部署后实现了点击率和收入指标的显著提升。</p>
<hr />
<h2>15. LASER：一种面向目标的高效分段注意力框架，用于端到端长序列建模</h2>
<p><strong>英文标题</strong>: LASER: An Efficient Target-Aware Segmented Attention Framework for End-to-End Long Sequence Modeling</p>
<p><strong>作者</strong>: Tianhe Lin、Ziwei Xiong、Baoyuan Ou、Yingjie Qin、等7人</p>
<p><strong>提交时间</strong>: 2026-02-12 12:33</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.11562v1">查看原文</a></p>
<p><strong>所属公司</strong>: 小红书</p>
<p><strong>命中关键词</strong>: 【3】 xiaohongshu, retrieval, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接针对推荐系统核心的长序列建模问题，提出了兼顾系统与算法效率的创新性解决方案，并在大规模工业场景中验证了其商业价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对推荐系统中超长用户行为序列建模面临的'延迟墙'问题，提出了一个名为LASER的全栈优化框架。该框架包含两个核心创新：一是系统效率方面，设计了名为SeqVault的统一模式感知服务基础设施，通过混合DRAM-SSD索引策略，将检索延迟降低50%，CPU使用率降低75%，实现了对全实时和生命周期用户历史的毫秒级访问；二是算法效率方面，提出了分段目标注意力机制，利用基于Sigmoid的门控策略过滤噪声项目，再通过轻量级的全局堆叠目标注意力模块捕获跨段依赖关系，在降低计算复杂度的同时保留了关键信号。离线评估和在线A/B测试表明，该框架在服务超过1亿日活用户时，显著提升了关键业务指标和收入。</p>
<hr />
<h2>16. ULTRA：基于乌尔都语Transformer的推荐架构</h2>
<p><strong>英文标题</strong>: ULTRA:Urdu Language Transformer-based Recommendation Architecture</p>
<p><strong>作者</strong>: Alishbah Bashir、Fatima Qaiser、Ijaz Hussain</p>
<p><strong>提交时间</strong>: 2026-02-12 19:26</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.11836v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, recommendation, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文聚焦于低资源语言的语义召回和检索技术，与推荐系统的召回阶段相关，但未涉及重排、LTV、因果推断等核心推荐算法方向。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对乌尔都语这类低资源语言缺乏有效语义内容推荐系统的问题，提出了ULTRA自适应语义推荐框架。核心创新在于设计了双嵌入架构和查询长度感知路由机制，能够动态区分短意图查询和长上下文查询，并通过阈值决策将查询路由到针对标题级或全文级表示优化的专用语义管道，确保检索时语义粒度的适应性。该方法利用基于Transformer的嵌入和优化池化策略，超越了表层关键词匹配，实现了上下文感知的相似性搜索，在大规模乌尔都语新闻语料上的实验表明，该架构显著提升了不同查询类型的推荐相关性，相比单管道基线精度提升超过90%。</p>
<hr />
<h2>17. DiffuRank：基于扩散语言模型的有效文档重排</h2>
<p><strong>英文标题</strong>: DiffuRank: Effective Document Reranking with Diffusion Language Models</p>
<p><strong>作者</strong>: Qi Liu、Kun Ai、Jiaxin Mao、Yanzhao Zhang、等5人</p>
<p><strong>提交时间</strong>: 2026-02-13 10:18</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.12528v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 ranking, explore, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文聚焦于文档重排（ranking），属于推荐/搜索系统的排序阶段，但主要面向信息检索场景而非典型的个性化推荐，且未涉及LTV、因果推断等推荐系统核心议题。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对现有基于自回归大语言模型的文档重排方法存在延迟高、生成顺序固定导致错误传播等问题，提出了一种基于扩散语言模型的文档重排框架DiffuRank。该框架利用扩散语言模型支持灵活解码和并行生成的优势，探索了三种重排策略：基于点对的相关性估计、基于logit的列表级联合评估以及基于排列的列表级方法，并为每种策略设计了相应的训练方法。实验表明，在多个基准测试中，扩散语言模型在零样本和微调设置下均能达到与同规模自回归模型相当甚至更优的性能，证明了扩散模型在文档重排任务中作为自回归架构替代方案的潜力。</p>
<hr />
<h2>18. 从噪声到有序：基于去噪扩散的排序学习</h2>
<p><strong>英文标题</strong>: From Noise to Order: Learning to Rank via Denoising Diffusion</p>
<p><strong>作者</strong>: Sajad Ebrahimi、Bhaskar Mitra、Negar Arabzadeh、Ye Yuan、等3人</p>
<p><strong>提交时间</strong>: 2026-02-12 08:02</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.11453v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文聚焦于信息检索的排序学习，虽与推荐系统排序相关，但并非直接针对推荐系统的核心场景（如重排、LTV、因果推断）。</p>
<p><strong>摘要总结</strong>:<br />
本文提出了一种新颖的生成式排序学习方法DiffusionRank，它基于去噪扩散模型来建模查询-文档特征向量与相关性标签的联合概率分布，而非传统判别式方法仅建模条件概率。该方法将经典的逐点与逐对排序学习目标转化为生成式框架，通过解释完整数据分布来提升排序模型的鲁棒性。实验结果表明，DiffusionRank模型相比传统判别式方法取得了显著性能提升。这项工作为利用扩散等深度生成模型技术来改进信息检索中的排序学习开辟了广阔的研究空间。</p>
<hr />
<h2>19. 密集检索器训练引发的对LLM生成内容的偏好研究</h2>
<p><strong>英文标题</strong>: Training-Induced Bias Toward LLM-Generated Content in Dense Retrieval</p>
<p><strong>作者</strong>: William Xion、Wolfgang Nejdl</p>
<p><strong>提交时间</strong>: 2026-02-11 21:20</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.10833v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索与排序中的偏见问题，与推荐系统的排序阶段相关，但未直接聚焦于重排、LTV或因果推断等核心方向。</p>
<p><strong>摘要总结</strong>:<br />
该论文研究了密集检索模型中存在的“来源偏见”现象，即模型更倾向于检索大语言模型生成的文本而非人类撰写的文本。作者通过控制实验，对比了在SciFact和NQ320K数据集上使用不同训练数据（人类文本、LLM生成文本、MS MARCO）进行微调后模型的偏好变化。研究发现，这种偏见主要是由监督微调（尤其是使用MS MARCO或LLM生成数据）诱导产生的，而非密集检索器的固有特性；同时，通过语言建模头进行的困惑度探测表明，困惑度对解释这种偏见的贡献有限。论文的创新点在于系统性地追踪了偏见的产生阶段，并挑战了“低困惑度导致偏见”的假设。</p>
<hr />
<h2>20. ChainRec：一种能够为多样化和动态演变的兴趣学习路由工具链的智能推荐代理</h2>
<p><strong>英文标题</strong>: ChainRec: An Agentic Recommender Learning to Route Tool Chains for Diverse and Evolving Interests</p>
<p><strong>作者</strong>: Fuchun Li、Qian Li、Xingyu Gao、Bocheng Pan、等6人</p>
<p><strong>提交时间</strong>: 2026-02-11 11:50</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.10490v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 amazon, recommendation, cold-start</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文主要关注智能代理在推荐中的应用和动态规划，与重排、LTV、因果推断等核心推荐技术关联度不高。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种名为ChainRec的智能推荐代理系统，旨在解决现有基于大语言模型的推荐方法通常采用固定工作流程、无法适应多样化用户场景的问题。其核心创新在于构建了一个标准化的工具代理库，并训练一个规划器来动态选择推理工具、决定工具执行顺序以及判断何时停止，从而根据用户的具体上下文（如冷启动或兴趣转移）自适应地收集证据。实验结果表明，ChainRec在多个数据集上显著提升了推荐性能，尤其在冷启动和兴趣演变场景中表现突出，并通过消融研究验证了工具标准化和基于偏好的优化规划的重要性。</p>
<hr />
        <div class="footer">
            <p><a href="../../index.html">← 返回主页</a></p>
            <p>生成时间: 2026年02月16日 12:28:22</p>
        </div>
    </div>
</body>
</html>