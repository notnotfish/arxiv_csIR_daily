<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv cs.IR 每日论文摘要 - 2026年02月25日 12:23:45</title>
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,
        <svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22>
            <ellipse cx=%2250%22 cy=%2275%22 rx=%2235%22 ry=%2220%22 fill=%22%23FFD700%22 stroke=%22%23E6C200%22 stroke-width=%223%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2225%22 ry=%2215%22 fill=%22%23FFF8E7%22/>
            <circle cx=%2240%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2260%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2242%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <circle cx=%2262%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2210%22 ry=%226%22 fill=%22%23FF6B35%22/>
            <path d=%22Q 35 72, 25 85 Q 20 95, 35 95 Q 50 95, 45 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <path d=%22Q 65 72, 75 85 Q 80 95, 65 95 Q 50 95, 55 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <ellipse cx=%2250%22 cy=%2220%22 rx=%2215%22 ry=%2212%22 fill=%22%238B4513%22/>
        </svg>">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #f6f8fa;
            padding: 20px;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: #ffffff;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);
        }

        h1 {
            font-size: 2em;
            margin-bottom: 0.5em;
            padding-bottom: 0.3em;
            border-bottom: 2px solid #eaecef;
            color: #0366d6;
        }

        h2 {
            font-size: 1.5em;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
            padding-bottom: 0.2em;
            border-bottom: 1px solid #eaecef;
        }

        h3 {
            font-size: 1.25em;
            margin-top: 1em;
            margin-bottom: 0.5em;
        }

        p {
            margin-bottom: 1em;
        }

        strong {
            font-weight: 600;
        }

        a {
            color: #0366d6;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        hr {
            border: 0;
            border-top: 1px solid #eaecef;
            margin: 2em 0;
        }

        code {
            background-color: #f6f8fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            font-size: 0.9em;
        }

        pre {
            background-color: #f6f8fa;
            padding: 16px;
            border-radius: 6px;
            overflow-x: auto;
            margin-bottom: 1em;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        .footer {
            margin-top: 3em;
            padding-top: 1em;
            border-top: 1px solid #eaecef;
            text-align: center;
            color: #586069;
            font-size: 0.9em;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }

            body {
                padding: 10px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ArXiv cs.IR 每日论文摘要</h1>
<p><strong>生成时间</strong>: 2026年02月25日 12:23:45<br />
<strong>论文数量</strong>: 20 篇（Top 20）<br />
<strong>排序规则</strong>: 按关键词命中数 + 兴趣评分排序</p>
<hr />
<h2>1. 视频排序中的长期价值预测框架</h2>
<p><strong>英文标题</strong>: A Long-term Value Prediction Framework In Video Ranking</p>
<p><strong>作者</strong>: Huabin Chen、Xinao Wang、Huiping Chu、Keqin Xu、等4人</p>
<p><strong>提交时间</strong>: 2026-02-19 12:01</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.17058v1">查看原文</a></p>
<p><strong>所属公司</strong>: 阿里巴巴（淘宝）</p>
<p><strong>命中关键词</strong>: 【7】 taobao, ranking, recommendation, explore, ltv, debias, causal</p>
<p><strong>感兴趣评分</strong>: 【5分】 论文直接聚焦LTV建模、因果推断和位置去偏等推荐系统核心问题，且来自淘宝的工业级实践，创新性与实用性兼备。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对短视频推荐排序阶段长期价值（LTV）建模的挑战，提出了一个实用的框架。核心创新包括：1）提出位置感知去偏分位数（PDQ）模块，通过基于分位数的分布归一化用户互动，实现无需改变模型架构的位置鲁棒LTV估计；2）设计多维度归因模块，学习上下文、行为和内容信号间的连续归因强度，替代静态规则以捕捉视频间的细微影响，并采用带显式噪声过滤的混合损失提升因果清晰度；3）引入跨时空作者建模模块，构建考虑删失的日级LTV目标，以捕捉创作者驱动的长期再互动，该设计可扩展至其他维度（如主题、风格）。该框架作为任务增强集成到现有排序模型中，支持高效训练与部署，已在淘宝生产系统实现十亿级规模落地，在提升长期互动指标的同时保持与短期目标的稳定权衡。</p>
<hr />
<h2>2. SMES：通过专家稀疏化实现可扩展的多任务推荐</h2>
<p><strong>英文标题</strong>: SMES: Towards Scalable Multi-Task Recommendation via Expert Sparsity</p>
<p><strong>作者</strong>: Yukun Zhang、Si Dong、Xu Wang、Bo Chen、等10人</p>
<p><strong>提交时间</strong>: 2026-02-10 11:56</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.09386v1">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, ranking, recommendation, uplift</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接涉及推荐系统核心的排序和多任务价值建模，且来自知名公司快手，具有实际落地效果。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对工业级多任务推荐系统中模型规模扩展时面临的参数均匀缩放与任务异构容量需求不匹配的问题，提出了一种基于稀疏专家混合（MoE）的可扩展框架SMES。核心创新在于设计了渐进式专家路由机制，将专家激活分解为跨任务联合选择的任务共享专家子集和任务自适应的私有专家，从而在保证实例级稀疏性的同时保留任务特定容量。此外，SMES引入了全局多门负载均衡正则化器，通过调节所有任务的聚合专家利用率来稳定训练。该方法已在快手大规模短视频服务中部署，支持超过4亿日活用户，在线实验表明其在GAUC和用户观看时长上均取得了稳定提升。</p>
<hr />
<h2>3. 推理排序：利用大语言模型进行推荐的端到端解决方案</h2>
<p><strong>英文标题</strong>: Reasoning to Rank: An End-to-End Solution for Exploiting Large Language Models for Recommendation</p>
<p><strong>作者</strong>: Kehan Zheng、Deyao Hong、Qian Li、Jun Zhang、等3人</p>
<p><strong>提交时间</strong>: 2026-02-13 10:22</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.12530v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 amazon, ranking, recommendation, explore</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接针对推荐系统的核心排序问题，提出了结合大语言模型推理与强化学习的创新端到端训练框架，具有较高的技术新颖性和实用价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种名为'推理排序'的端到端训练框架，旨在将推荐效用优化内化到大语言模型的逐步推理学习中。为了解决大语言模型推理中的位置偏差并实现对推理过程的直接优化，该框架在用户-物品级别进行推理，并采用强化学习对大语言模型进行端到端训练。在三个亚马逊数据集和一个大规模工业数据集上的实验表明，该方法相比传统的强基线方案和基于大语言模型的解决方案均取得了稳定的性能提升。深入的实验分析验证了所提框架中关键组件的必要性，并为该方向未来的发展提供了启示。</p>
<hr />
<h2>4. 通过极端分类在双边市场中实现高精度受众扩展</h2>
<p><strong>英文标题</strong>: High Precision Audience Expansion via Extreme Classification in a Two-Sided Marketplace</p>
<p><strong>作者</strong>: Dillon Davis、Huiji Gao、Thomas Legrand、Juan Manuel Caicedo Carvajal、等7人</p>
<p><strong>提交时间</strong>: 2026-02-16 08:23</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.14358v1">查看原文</a></p>
<p><strong>所属公司</strong>: Airbnb</p>
<p><strong>命中关键词</strong>: 【4】 airbnb, retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文深入探讨了推荐系统中召回阶段的核心挑战——地理位置检索，并提出了创新的极端分类解决方案，对优化推荐系统检索效率有直接参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对Airbnb搜索系统中地理位置召回这一独特挑战，提出了一种新的架构方法。核心内容是将全球划分为2500万个均匀的地图网格单元，通过极端分类技术识别出最可能被预订的高精度矩形网格子集，作为召回阶段的候选区域。该方法取代了原有的基于深度贝叶斯多臂老虎机的矩形边界预测系统，旨在在资源密集的排序模型应用之前，更高效地过滤房源库存。创新点在于将地理位置检索问题转化为大规模分类问题，实现了更高精度的受众扩展，从而提升搜索效率和用户体验。</p>
<hr />
<h2>5. PRECTR-V2：融合跨用户偏好挖掘、曝光偏差校正与LLM蒸馏编码器优化的统一相关性-CTR框架</h2>
<p><strong>英文标题</strong>: PRECTR-V2:Unified Relevance-CTR Framework with Cross-User Preference Mining, Exposure Bias Correction, and LLM-Distilled Encoder Optimization</p>
<p><strong>作者</strong>: Shuzhi Cao、Rong Chen、Ailong He、Shuguang Han、等1人</p>
<p><strong>提交时间</strong>: 2026-02-24 16:26</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.20676v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 ranking, ctr, cold-start, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接针对排序、CTR预估和冷启动等推荐系统核心技术，提出了融合多任务学习、偏差校正和模型蒸馏的创新框架。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对搜索系统中相关性匹配与点击率预测两大核心任务的不一致问题，提出了PRECTR-V2统一框架。为解决低活跃用户行为稀疏问题，该方法通过挖掘特定查询下的全局相关性偏好来实现冷启动场景的个性化建模；针对曝光偏差，采用嵌入噪声注入和相关性标签重构构建困难负样本，并通过成对损失优化正负样本的相对排序；最后，通过LLM知识蒸馏和文本相关性分类任务的监督微调，预训练了一个轻量级Transformer编码器，取代了原有的冻结BERT模块，实现了表征学习与CTR精调的对齐优化。</p>
<hr />
<h2>6. RGAlign-Rec：推荐系统中基于排序引导对齐的潜在查询推理方法</h2>
<p><strong>英文标题</strong>: RGAlign-Rec: Ranking-Guided Alignment for Latent Query Reasoning in Recommendation Systems</p>
<p><strong>作者</strong>: Junhua Liu、Yang Jihao、Cheng Chang、Kunrong LI、等2人</p>
<p><strong>提交时间</strong>: 2026-02-13 22:38</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.12968v1">查看原文</a></p>
<p><strong>所属公司</strong>: Shopee（虾皮）</p>
<p><strong>命中关键词</strong>: 【4】 shopee, ranking, recommendation, ctr</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文紧密结合推荐系统的排序核心任务，提出了利用排序信号对齐和优化LLM推理的创新框架，对重排和价值建模有直接启发。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对电商聊天机器人中主动意图预测任务存在的两大挑战——离散用户特征与知识库语义意图之间的语义鸿沟，以及通用大语言模型输出与任务特定排序目标之间的不一致性，提出了RGAlign-Rec框架。该框架的核心创新在于构建了一个闭环对齐系统，将基于LLM的语义推理器与查询增强排序模型相结合，并设计了排序引导对齐的多阶段训练范式，利用下游排序信号作为反馈来优化LLM的潜在推理过程。在Shopee大规模工业数据集上的实验表明，该方法在GAUC、错误率降低和召回率等指标上均有显著提升，在线A/B测试进一步验证了其能有效同步语义推理与排序目标，提升主动推荐系统的预测准确性和服务质量。</p>
<hr />
<h2>7. KuaiSearch：一个用于召回、排序和相关性的大规模电商搜索数据集</h2>
<p><strong>英文标题</strong>: KuaiSearch: A Large-Scale E-Commerce Search Dataset for Recall, Ranking, and Relevance</p>
<p><strong>作者</strong>: Yupeng Li、Ben Chen、Mingyue Cheng、Zhiding Liu、等3人</p>
<p><strong>提交时间</strong>: 2026-02-12 11:22</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.11518v1">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, ranking, cold-start, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文聚焦于电商搜索的核心环节（召回、排序、相关性），并专门处理了冷启动问题，与推荐系统核心技术高度相关且具有创新性。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对电商搜索中存在的查询歧义、商品文本噪声大、用户偏好多样等挑战，构建并发布了当前最大的电商搜索数据集KuaiSearch。该数据集基于快手平台真实的用户搜索交互数据，保留了原始的用户查询和自然语言商品文本，覆盖了冷启动用户和长尾商品，并系统性地涵盖了搜索流程中的召回、排序和相关性判断三个关键阶段。论文从商品、用户和查询等多个角度对数据集进行了全面分析，并在多个代表性搜索任务上建立了基准实验，为基于大语言模型的真实世界电商搜索研究提供了宝贵的基础。</p>
<hr />
<h2>8. QP-OneModel：小红书搜索中多任务查询理解的统一生成式大语言模型</h2>
<p><strong>英文标题</strong>: QP-OneModel: A Unified Generative LLM for Multi-Task Query Understanding in Xiaohongshu Search</p>
<p><strong>作者</strong>: Jianzhao Huang、Xiaorui Huang、Fei Zhao、Yunpeng Liu、等8人</p>
<p><strong>提交时间</strong>: 2026-02-10 23:38</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.09901v1">查看原文</a></p>
<p><strong>所属公司</strong>: 小红书</p>
<p><strong>命中关键词</strong>: 【4】 xiaohongshu, retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接涉及搜索中的排序（ranking）和相关性（relevance）优化，这是推荐系统的核心技术，且来自知名公司小红书，创新性较强。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了QP-OneModel，一个用于社交网络服务（SNS）领域多任务查询理解的统一生成式大语言模型。核心方法是将异构的子任务（如NER、词权重、查询改写等）重新表述为统一的序列生成范式，并采用渐进式三阶段对齐策略，最终结合多奖励强化学习进行优化。其创新点在于：1）通过统一的生成模型替代传统判别模型管道，解决了语义理解有限和维护成本高的问题；2）生成了意图描述作为一种新颖的高保真语义信号，有效增强了下游任务（如查询改写和排序）的性能。离线评估显示模型在多个任务上显著优于基线，在线A/B测试也证实了其在提升检索相关性和用户留存方面的工业价值。</p>
<hr />
<h2>9. 分析式搜索</h2>
<p><strong>英文标题</strong>: Analytical Search</p>
<p><strong>作者</strong>: Yiteng Tu、Shuo Miao、Weihang Su、Yiqun Liu、等1人</p>
<p><strong>提交时间</strong>: 2026-02-12 13:06</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.11581v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, ranking, relevance, causal</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索、排序、相关性等与推荐系统相关的技术，并重点探讨了因果影响评估，但核心是面向搜索范式创新而非直接针对推荐系统。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种新的搜索范式——分析式搜索，旨在满足法律、金融、科学等领域中趋势分析和因果影响评估等复杂分析性信息需求。论文指出传统基于相关性的文档排序或基于大语言模型的检索增强生成方法难以满足此类任务在语料库规模下的端到端需求，因为它们要么侧重信息查找而非问题解决，要么将一切简化为简单问答，缺乏对推理过程、证据使用和可验证性的控制。为此，论文构建了一个统一的系统框架，通过显式建模分析意图、检索融合证据、基于结构化多步推理生成可验证结论，将搜索重新定义为证据驱动、过程导向的分析工作流，并探讨了构建分析式搜索引擎的潜在研究方向。</p>
<hr />
<h2>10. HiSAC：推荐系统中超长序列建模的分层稀疏激活压缩方法</h2>
<p><strong>英文标题</strong>: HiSAC: Hierarchical Sparse Activation Compression for Ultra-long Sequence Modeling in Recommenders</p>
<p><strong>作者</strong>: Kun Yuan、Junyu Bi、Daixuan Cheng、Changfa Wu、等4人</p>
<p><strong>提交时间</strong>: 2026-02-24 23:28</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.21009v1">查看原文</a></p>
<p><strong>所属公司</strong>: 阿里巴巴（淘宝）</p>
<p><strong>命中关键词</strong>: 【3】 taobao, uplift, ctr</p>
<p><strong>感兴趣评分</strong>: 【5分】 论文直接涉及推荐系统核心的CTR预估问题，并提出了创新的序列建模方法，且来自阿里巴巴淘宝的工业级应用验证。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对推荐系统中超长用户行为序列建模面临的计算延迟和内存限制问题，提出了一种名为HiSAC的高效个性化序列建模框架。其核心创新在于：首先，通过将用户交互编码为多层语义ID并构建全局分层码本；其次，采用分层投票机制稀疏激活个性化的兴趣代理作为细粒度偏好中心；最后，在语义空间中通过软路由注意力机制聚合历史信号，并根据相似度加权以减少量化误差并保留长尾行为。该方法已在淘宝“猜你喜欢”首页部署，在线A/B测试显示CTR持续提升1.65%，证明了其可扩展性和实际有效性。</p>
<hr />
<h2>11. CaliCausalRank：基于鲁棒反事实效用优化的校准多目标广告排序</h2>
<p><strong>英文标题</strong>: CaliCausalRank: Calibrated Multi-Objective Ad Ranking with Robust Counterfactual Utility Optimization</p>
<p><strong>作者</strong>: Xikai Yang、Sebastian Sun、Yilin Li、Yue Xing、等2人</p>
<p><strong>提交时间</strong>: 2026-02-21 18:35</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.18786v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 ranking, ctr, cvr</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接聚焦于广告排序中的多目标优化、因果推断和校准问题，与重排、价值建模及因果推断等核心研究方向高度契合。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对广告排序系统中多目标优化面临的挑战，提出了一个统一的框架CaliCausalRank。核心方法包括：将分数校准作为首要训练目标而非后处理，采用拉格朗日松弛法满足约束条件，并利用方差缩减的反事实估计器进行可靠的离线评估。创新点在于解决了流量分段间分数尺度不一致导致的阈值可迁移性问题，以及点击日志中的位置偏差导致的离线-在线指标差异问题。在Criteo和Avazu数据集上的实验表明，该方法在AUC、校准误差和效用增益方面均优于基线模型。</p>
<hr />
<h2>12. 将语义转化为拓扑：基于大语言模型的属性增强协同过滤</h2>
<p><strong>英文标题</strong>: Turning Semantics into Topology: LLM-Driven Attribute Augmentation for Collaborative Filtering</p>
<p><strong>作者</strong>: Junjie Meng、Ranxu zhang、Wei Wu、Rui Zhang、等5人</p>
<p><strong>提交时间</strong>: 2026-02-25 01:01</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.21099v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, cold-start, causal</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文涉及推荐系统的召回（通过图结构增强）和冷启动问题，并明确提及利用LLM推断因果关系的创新方法，与因果推断方向高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种名为TAGCF的新框架，旨在解决如何将大语言模型（LLM）的语义知识有效整合到传统协同过滤推荐系统中的挑战。其核心方法是通过LLM从用户-物品对中推断交互意图和潜在因果关系，并将这些语义信息转化为中间属性节点，从而构建一个增强的用户-属性-物品（U-A-I）异构图。为了有效建模图中异构关系，论文还提出了自适应关系加权图卷积（ARGC）模块，能够动态估计不同关系类型的重要性。实验表明，该方法在多个基准数据集和冷启动场景下均能带来性能提升，验证了其有效性和鲁棒性。</p>
<hr />
<h2>13. 基于大语言模型的预排序生成式伪标签方法</h2>
<p><strong>英文标题</strong>: Generative Pseudo-Labeling for Pre-Ranking with LLMs</p>
<p><strong>作者</strong>: Junyu Bi、Xinting Niu、Daixuan Cheng、Kun Yuan、等4人</p>
<p><strong>提交时间</strong>: 2026-02-24 23:14</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.20995v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 ranking, recommendation, diversity</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接针对推荐系统核心排序阶段的关键难题（样本选择偏差），提出了结合LLMs的创新解决方案，并取得了显著的线上效果提升。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对工业推荐系统中预排序阶段面临的训练-服务分布不一致问题，提出了一种名为生成式伪标签（GPL）的创新框架。该方法的核心是利用大语言模型（LLMs）为未曝光物品生成无偏且内容感知的伪标签，从而将训练数据分布与线上服务空间对齐，缓解样本选择偏差和长尾内容推荐效果差的问题。其具体实现是通过离线生成用户特定的兴趣锚点，并在冻结的语义空间中与候选物品进行匹配，从而在不增加线上延迟的前提下提供高质量的监督信号。在大型生产系统中的部署结果表明，该方法不仅将点击率提升了3.07%，还显著增强了推荐的多样性和对长尾物品的发掘能力。</p>
<hr />
<h2>14. E-MMKGR：面向电子商务应用的统一多模态知识图谱框架</h2>
<p><strong>英文标题</strong>: E-MMKGR: A Unified Multimodal Knowledge Graph Framework for E-commerce Applications</p>
<p><strong>作者</strong>: Jiwoo Kang、Yeon-Chang Lee</p>
<p><strong>提交时间</strong>: 2026-02-24 21:19</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.20877v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 amazon, retrieval, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该研究聚焦于利用多模态知识图谱学习统一物品表征以同时提升推荐和检索效果，属于推荐系统核心技术（召回/表征学习）的创新性工作。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对现有多模态推荐系统依赖固定模态集合和任务特定目标，导致模态扩展性和任务泛化性受限的问题，提出了一个名为E-MMKGR的统一框架。该框架首先构建了一个面向电子商务的多模态知识图谱（E-MMKG），然后通过基于图神经网络的传播和面向知识图谱的优化，学习统一的物品表征。这些表征作为一个共享的语义基础，能够直接应用于推荐、产品搜索等多种下游任务。在真实亚马逊数据集上的实验表明，该方法在推荐任务的Recall@10指标上最高提升10.18%，在产品搜索任务上相比基于向量的检索方法最高提升21.72%，证明了其有效性和良好的扩展性。</p>
<hr />
<h2>15. LiveGraph：用于习题推荐的主动结构神经重排框架</h2>
<p><strong>英文标题</strong>: LiveGraph: Active-Structure Neural Re-ranking for Exercise Recommendation</p>
<p><strong>作者</strong>: Rong Fu、Zijian Zhang、Haiyun Wei、Jiekai Wu、等8人</p>
<p><strong>提交时间</strong>: 2026-02-19 11:14</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.17036v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 ranking, recommendation, diversity</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接涉及推荐系统的重排和多样性优化核心技术，并提出了创新的图结构增强方法，具有较好的研究价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种名为LiveGraph的新型主动结构神经重排框架，旨在解决当前习题推荐系统中学生参与度长尾分布和无法适应个性化学习轨迹的问题。该方法采用基于图的表示增强策略，弥合活跃与非活跃学生之间的信息鸿沟，并集成动态重排机制以提升内容多样性。通过优先考虑学习历史中的结构关系，该模型有效平衡了推荐精度与教学多样性。在多个真实数据集上的实验表明，LiveGraph在预测准确性和习题多样性广度上均优于现有基线方法。</p>
<hr />
<h2>16. 诊断固定证据池下LLM重排模型的行为</h2>
<p><strong>英文标题</strong>: Diagnosing LLM Reranker Behavior Under Fixed Evidence Pools</p>
<p><strong>作者</strong>: Baris Arat、Emre Sefer</p>
<p><strong>提交时间</strong>: 2026-02-21 05:07</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.18613v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, diversity</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接研究重排模型的多样性行为，并提出了消除检索偏差的诊断方法，对推荐系统排序阶段有重要参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种诊断LLM重排模型行为的新方法，通过使用Multi-News文档簇作为固定证据池来隔离重排过程，消除了上游检索质量对评估的干扰。研究将每个证据池限制为8个文档，并向所有排序器提供相同输入，以BM25和MMR作为词汇匹配和多样性优化的可解释基准。在345个文档簇上的实验发现，不同LLM的冗余模式存在差异：一个模型在较大选择预算下隐式地增加多样性，而另一个却增加冗余；同时，LLM在小选择预算下的词汇覆盖表现不佳。该诊断方法具有模型无关性，适用于包括开源系统和专有API在内的任何排序器。</p>
<hr />
<h2>17. 通过严格估计器分离缓解偏好泄漏的规范性生成排序</h2>
<p><strong>英文标题</strong>: Mitigating Preference Leakage via Strict Estimator Separation for Normative Generative Ranking</p>
<p><strong>作者</strong>: Dalia Nahhas、Xiaohao Cai、Imran Razzak、Shoaib Jameel</p>
<p><strong>提交时间</strong>: 2026-02-24 19:38</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.20800v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及排序任务和评估偏差问题，与推荐系统相关，但更侧重于信息检索的评估方法而非核心推荐技术。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对生成式信息检索中LLM-as-a-Judge评估存在的循环性和偏好泄漏问题，提出了一种无泄漏的双评估框架。核心方法是将文化相关性定义为查询内排序任务，并严格分离监督模型（Judge B）与评估模型（Judge A），从而避免评估偏差。创新点在于构建了包含33,052个文化故事的新基准NGR-33k，并通过从监督式交叉编码器蒸馏出的稠密双编码器实现高效排序，实验表明该方法在无泄漏评估下显著优于传统基线，并在人工标注数据集上验证了与人类规范的强对齐。</p>
<hr />
<h2>18. 超越流水线：生成式检索架构在网络研究中的兴起及其基础性研究</h2>
<p><strong>英文标题</strong>: Beyond Pipelines: A Fundamental Study on the Rise of Generative-Retrieval Architectures in Web Research</p>
<p><strong>作者</strong>: Amirereza Abbasi、Mohsen Hooshmand</p>
<p><strong>提交时间</strong>: 2026-02-19 23:14</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.17450v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, recommendation, explore</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文虽提及推荐系统作为LLMs的应用领域之一，但核心是综述LLMs和RAG对网络研究的广泛影响，并未深入探讨推荐系统的核心技术（如重排、LTV、因果推断）。</p>
<p><strong>摘要总结</strong>:<br />
该论文是一篇综述性研究，核心探讨了大型语言模型（LLMs）如何重塑网络研究与应用，特别是通过检索增强生成（RAG）等技术，将传统的信息处理流水线转变为生成式解决方案。论文重点分析了LLMs在信息检索、问答系统、推荐系统和网络分析等任务中的影响与变革，并涵盖了基于网络的摘要和教育工具等新兴应用。其创新点在于系统性地梳理了LLMs（尤其是RAG架构）对网络研究和产业实践带来的关键进展、开放挑战及未来方向，强调了从传统范式向生成式范式的根本性转变。</p>
<hr />
<h2>19. KNIGHT：基于知识图谱驱动的多项选择题生成与自适应难度校准</h2>
<p><strong>英文标题</strong>: KNIGHT: Knowledge Graph-Driven Multiple-Choice Question Generation with Adaptive Hardness Calibration</p>
<p><strong>作者</strong>: Mohammad Amanlou、Erfan Shafiee Moghaddam、Yasaman Amou Jafari、Mahdi Noori、等2人</p>
<p><strong>提交时间</strong>: 2026-02-24 02:46</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.20135v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要关注信息检索中的评估数据生成，与推荐系统的核心技术关联较弱。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种名为KNIGHT的框架，利用大语言模型和知识图谱从外部知识源自动生成多项选择题数据集，以解决RAG等系统评估时构建专用测试集成本高、耗时长的问题。其核心方法是通过构建特定主题的知识图谱，将实体和关系压缩为可重用的结构化表示，从而支持按需生成不同难度（包括多跳推理）的题目，无需反复读取原始文本。创新点在于将知识图谱作为可复用的中间状态，实现了高效、可控的题目生成，并在历史、生物、数学等领域验证了生成题目的质量与实用性。</p>
<hr />
<h2>20. 当LLM评分者夸大分数：探索相关性评估中的过高评分现象</h2>
<p><strong>英文标题</strong>: When LLM Judges Inflate Scores: Exploring Overrating in Relevance Assessment</p>
<p><strong>作者</strong>: Chuting Yu、Hang Li、Guido Zuccon、Joel Mackenzie、等1人</p>
<p><strong>提交时间</strong>: 2026-02-19 16:37</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2602.17170v2">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, explore, relevance</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要关注信息检索中的相关性评估问题，与推荐系统的核心技术（如重排、LTV、因果推断）关联较弱。</p>
<p><strong>摘要总结</strong>:<br />
该论文系统研究了大型语言模型（LLM）作为人类相关性评估代理时存在的系统性过高评分行为。研究通过在不同模型架构、评估范式（点式和配对式）以及文本修改策略下进行实验，发现LLM会以高置信度给不真正满足信息需求的段落赋予过高的相关性分数，揭示了这是一种系统性的偏见而非随机波动。论文还通过控制实验证明，LLM的相关性判断对文本长度和表面词汇线索高度敏感，这挑战了LLM作为人类评估者直接替代品的可靠性。其创新点在于首次系统性地诊断了LLM在相关性评估中的过评分偏差，并强调了建立谨慎诊断评估框架的紧迫性。</p>
<hr />
        <div class="footer">
            <p><a href="../../index.html">← 返回主页</a></p>
            <p>生成时间: 2026年02月25日 12:23:45</p>
        </div>
    </div>
</body>
</html>