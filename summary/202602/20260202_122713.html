<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv cs.IR 每日论文摘要 - 2026年02月02日 12:27:13</title>
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,
        <svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22>
            <ellipse cx=%2250%22 cy=%2275%22 rx=%2235%22 ry=%2220%22 fill=%22%23FFD700%22 stroke=%22%23E6C200%22 stroke-width=%223%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2225%22 ry=%2215%22 fill=%22%23FFF8E7%22/>
            <circle cx=%2240%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2260%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2242%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <circle cx=%2262%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2210%22 ry=%226%22 fill=%22%23FF6B35%22/>
            <path d=%22Q 35 72, 25 85 Q 20 95, 35 95 Q 50 95, 45 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <path d=%22Q 65 72, 75 85 Q 80 95, 65 95 Q 50 95, 55 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <ellipse cx=%2250%22 cy=%2220%22 rx=%2215%22 ry=%2212%22 fill=%22%238B4513%22/>
        </svg>">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #f6f8fa;
            padding: 20px;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: #ffffff;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);
        }

        h1 {
            font-size: 2em;
            margin-bottom: 0.5em;
            padding-bottom: 0.3em;
            border-bottom: 2px solid #eaecef;
            color: #0366d6;
        }

        h2 {
            font-size: 1.5em;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
            padding-bottom: 0.2em;
            border-bottom: 1px solid #eaecef;
        }

        h3 {
            font-size: 1.25em;
            margin-top: 1em;
            margin-bottom: 0.5em;
        }

        p {
            margin-bottom: 1em;
        }

        strong {
            font-weight: 600;
        }

        a {
            color: #0366d6;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        hr {
            border: 0;
            border-top: 1px solid #eaecef;
            margin: 2em 0;
        }

        code {
            background-color: #f6f8fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            font-size: 0.9em;
        }

        pre {
            background-color: #f6f8fa;
            padding: 16px;
            border-radius: 6px;
            overflow-x: auto;
            margin-bottom: 1em;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        .footer {
            margin-top: 3em;
            padding-top: 1em;
            border-top: 1px solid #eaecef;
            text-align: center;
            color: #586069;
            font-size: 0.9em;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }

            body {
                padding: 10px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ArXiv cs.IR 每日论文摘要</h1>
<p><strong>生成时间</strong>: 2026年02月02日 12:27:13<br />
<strong>论文数量</strong>: 20 篇（Top 20）<br />
<strong>排序规则</strong>: 按关键词命中数 + 兴趣评分排序</p>
<hr />
<h2>1. LLaTTE：大规模广告推荐中多阶段序列建模的缩放定律</h2>
<p><strong>英文标题</strong>: LLaTTE: Scaling Laws for Multi-Stage Sequence Modeling in Large-Scale Ads Recommendation</p>
<p><strong>作者</strong>: Lee Xiong、Zhirong Chen、Rahul Mayuranath、Shangran Qiu、等16人</p>
<p><strong>提交时间</strong>: 2026-01-28 05:59</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.20083v1">查看原文</a></p>
<p><strong>所属公司</strong>: Meta</p>
<p><strong>命中关键词</strong>: 【4】 facebook, ranking, recommendation, uplift</p>
<p><strong>感兴趣评分</strong>: 【5分】 论文直接涉及推荐系统核心的排序（ranking）和价值建模（通过转化提升/uplift体现），来自Meta公司，并提出了创新的多阶段架构和缩放定律分析。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了LLaTTE（用于时序事件的LLM风格潜在Transformer），这是一种用于生产环境广告推荐的可扩展Transformer架构。通过系统实验，作者证明了推荐系统中的序列建模遵循类似大语言模型的可预测幂律缩放规律，并发现语义特征是实现有效缩放的前提条件，能够使模型充分利用更深、更长架构的能力。为了在严格延迟约束下实现持续缩放的优势，论文引入了一种两阶段架构，将大型长上下文模型的重计算卸载到异步上游用户模型中，并证明了上游改进可预测地传递到下游排序任务。该多阶段框架作为Meta最大的用户模型部署，在Facebook Feed和Reels上实现了4.3%的转化提升，为工业推荐系统利用缩放定律提供了实用蓝图。</p>
<hr />
<h2>2. 基于对抗对齐与解耦的跨域CTR预测模型：利用全域特征</h2>
<p><strong>英文标题</strong>: Adversarial Alignment and Disentanglement for Cross-Domain CTR Prediction with Domain-Encompassing Features</p>
<p><strong>作者</strong>: Junyou He、Lixi Deng、Huichao Guo、Ye Tang、等2人</p>
<p><strong>提交时间</strong>: 2026-01-24 22:20</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.17472v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 recommendation, ctr, explore, cold-start</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接针对CTR预估和冷启动问题，提出了融合对抗对齐与特征解耦的创新方法，属于推荐系统排序阶段的核心技术。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对跨域推荐中数据稀疏和冷启动问题，提出了一种名为A²DCDR的创新模型。该方法通过三个核心组件改进传统跨域推荐：首先，结合对抗训练优化最大均值差异（MMD）以提升泛化能力；其次，采用特征解耦器和重构机制实现域内特征解耦；最后，创新性地融合了域不变特征、未对齐特征与原始上下文信息，形成更全面的跨域表征。实验表明，该模型在真实数据集和在线A/B测试中均优于现有方法，验证了其有效性和实用性。</p>
<hr />
<h2>3. OneMall：一个模型，更多场景——快手电商端到端生成式推荐家族</h2>
<p><strong>英文标题</strong>: OneMall: One Model, More Scenarios -- End-to-End Generative Recommender Family at Kuaishou E-Commerce</p>
<p><strong>作者</strong>: Kun Zhang、Jingming Zhang、Wei Cheng、Yansong Cheng、等28人</p>
<p><strong>提交时间</strong>: 2026-01-29 22:22</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.21770v1">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文系统性地整合了召回、排序及端到端生成式推荐，并涉及多场景统一、序列建模和强化学习优化等推荐系统核心技术，创新性强且来自头部公司。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一个名为OneMall的端到端生成式推荐框架，旨在统一快手电商平台下的多种商品分发场景，包括商品卡片、短视频和直播。其核心创新点在于：首先，设计了一个电商语义分词器，能够捕捉跨场景的真实世界语义和特定业务商品关系；其次，采用基于Transformer的架构，利用Query-Former进行长序列压缩、交叉注意力进行多行为序列融合，以及稀疏MoE实现可扩展的自回归生成；最后，通过强化学习管道连接召回和排序模型，使排序模型能够作为奖励信号，以优化端到端的策略召回模型。实验表明，OneMall在所有电商场景中均取得了显著效果提升，并已部署服务于数亿日活用户。</p>
<hr />
<h2>4. 为何链接：社交媒体帖子中包含超链接的意图分类体系</h2>
<p><strong>英文标题</strong>: Why They Link: An Intent Taxonomy for Including Hyperlinks in Social Posts</p>
<p><strong>作者</strong>: Fangping Lan、Abdullah Aljebreen、Eduard C. Dragut</p>
<p><strong>提交时间</strong>: 2026-01-25 05:32</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.17601v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 twitter, retrieval, recommendation, advertising</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及用户意图理解这一推荐系统相关方向，但主要聚焦信息检索和内容理解层面，未深入推荐系统的核心排序或价值建模技术。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对社交媒体中广泛存在的超链接现象，从读者视角出发研究用户对帖子中包含超链接意图的感知。研究采用混合方法构建了一个意图分类体系：首先通过大规模众包标注进行自下而上的数据驱动分析，然后借助大语言模型辅助生成描述性类别名称和精确定义。最终形成的分类体系包含6个顶层类别和26个细粒度意图类别，涵盖了多样化的传播目的。通过对1000条用户帖子的标注分析，发现广告、争论和分享是最普遍的链接意图，该分类体系为意图感知的信息检索和自然语言处理应用提供了基础框架。</p>
<hr />
<h2>5. 分块、检索与重排：政策文档问答中RAG架构的实证评估</h2>
<p><strong>英文标题</strong>: Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering</p>
<p><strong>作者</strong>: Anuj Maharjan、Umesh Yadav</p>
<p><strong>提交时间</strong>: 2026-01-22 04:52</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.15457v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, ranking, explore, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索与重排技术，与推荐系统的排序环节相关，但主要聚焦于问答任务而非典型推荐场景。</p>
<p><strong>摘要总结</strong>:<br />
本研究针对公共卫生政策领域，评估了检索增强生成（RAG）架构在减少大语言模型（LLM）幻觉风险方面的效果。论文比较了基础LLM、基础RAG和采用交叉编码器重排的高级RAG三种方案，使用Mistral-7B模型和MiniLM嵌入模型处理CDC政策文档，并分析了基于字符递归分块和基于语义分块两种策略对系统准确性的影响。核心创新在于通过两阶段检索与重排机制显著提升了答案的忠实度（从基准的0.347提升至0.797），证明了高级RAG在专业政策问答中实现高精度的必要性，同时指出文档分割结构仍是多步推理任务的主要瓶颈。</p>
<hr />
<h2>6. 指令检索模型真的能支持探索吗？</h2>
<p><strong>英文标题</strong>: Can Instructed Retrieval Models Really Support Exploration?</p>
<p><strong>作者</strong>: Piyush Maheshwari、Sheshera Mysore、Hamed Zamani</p>
<p><strong>提交时间</strong>: 2026-01-16 09:45</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.10936v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, ranking, explore, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索与排序技术，与推荐系统的召回和排序阶段相关，但未直接聚焦于重排、LTV或因果推断等核心推荐方向。</p>
<p><strong>摘要总结</strong>:<br />
该论文研究了指令检索模型在探索性搜索场景下的表现，特别是针对目标不明确、查询意图动态演变的场景。作者通过专家标注的测试集，评估了微调用于指令检索的LLM和使用成对排序提示的通用LLM在方面条件种子引导探索任务中的效果。研究发现，最佳指令检索模型在排序相关性上优于无视指令的方法，但其指令遵循能力并未同步提升，且对指令表现出不敏感或反直觉的行为。论文的创新点在于揭示了当前指令检索模型在需要长期、敏感响应指令的探索性会话中的局限性，为检索模型的用户体验评估提供了新视角。</p>
<hr />
<h2>7. LURE-RAG：面向高效RAG的轻量级效用驱动重排序</h2>
<p><strong>英文标题</strong>: LURE-RAG: Lightweight Utility-driven Reranking for Efficient RAG</p>
<p><strong>作者</strong>: Manish Chandra、Debasis Ganguly、Iadh Ounis</p>
<p><strong>提交时间</strong>: 2026-01-27 20:26</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.19535v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接涉及重排序（reranking）这一推荐系统核心技术，并采用列表排序损失进行优化，与推荐系统中的排序问题高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对传统检索增强生成（RAG）管道中基于相关性的检索与下游任务实际效用不匹配的问题，提出了一种轻量级效用驱动的重排序框架LURE-RAG。该方法的核心创新在于，通过引入基于LambdaMART的重排序器，并采用基于LLM效用的列表排序损失进行训练，直接优化检索文档的排序顺序，从而提升生成文本的质量。与现有方法相比，LURE-RAG在训练和推理阶段均保持高效，并在两个标准数据集上实现了接近最先进密集神经基线的性能（达到97-98%），其密集变体UR-RAG甚至比现有最佳基线显著提升达3%。</p>
<hr />
<h2>8. 大语言模型作为编排者：面向推荐系统的约束合规多智能体优化</h2>
<p><strong>英文标题</strong>: LLMs as Orchestrators: Constraint-Compliant Multi-Agent Optimization for Recommendation Systems</p>
<p><strong>作者</strong>: Guilin Zhang、Kai Zhao、Jeffrey Friedman、Xu Chu</p>
<p><strong>提交时间</strong>: 2026-01-27 10:46</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.19121v2">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 amazon, recommendation, diversity</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接针对推荐系统中的多目标优化和硬约束满足问题，提出了结合LLM进行智能体协调的创新框架，与重排、多样性等核心推荐技术高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对推荐系统需同时优化多个目标并满足硬性业务约束（如公平性、覆盖率）的挑战，提出了一个名为DualAgent-Rec的LLM协调双智能体框架。该框架将优化过程分解为两个部分：一个是在硬约束下优先考虑准确性的“利用智能体”，另一个是通过无约束帕累托搜索来促进多样性的“探索智能体”。核心创新在于引入一个基于LLM的协调器，根据优化进度和约束满足情况自适应地在两个智能体之间分配资源，并采用自适应epsilon松弛机制来保证最终解的可行性。在Amazon Reviews 2023数据集上的实验表明，该方法实现了100%的约束满足率，并将帕累托超体积提升了4-6%，同时保持了有竞争力的准确性与多样性权衡。</p>
<hr />
<h2>9. GenCI：基于群体意图学习的生成式用户兴趣迁移建模用于CTR预测</h2>
<p><strong>英文标题</strong>: GenCI: Generative Modeling of User Interest Shift via Cohort-based Intent Learning for CTR Prediction</p>
<p><strong>作者</strong>: Kesha Ou、Zhen Tian、Wayne Xin Zhao、Hongyu Lu、等1人</p>
<p><strong>提交时间</strong>: 2026-01-26 16:15</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.18251v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 ranking, ctr, advertising</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接针对CTR预测的核心问题，提出了结合生成式建模和上下文感知排序的创新框架，对重排和用户意图建模有重要参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对CTR预测中存在的两个关键问题提出了一种生成式用户意图框架GenCI。首先，现有判别式方法容易过度拟合历史主导特征，难以适应快速变化的用户兴趣；其次，点对点排序范式忽略了召回集合整体的丰富上下文信息，导致长期偏好压制了用户的即时意图。GenCI的核心方法是：首先使用基于下一项预测目标的生成模型主动生成候选兴趣群体，作为用户即时意图的显式表示；然后通过分层候选感知网络将这些上下文信号注入排序阶段，并利用交叉注意力机制使其与用户历史及目标物品对齐。整个模型采用端到端训练，在三个公开数据集上的实验证明了该方法的有效性。</p>
<hr />
<h2>10. 按需思考：基于LLM排序的模型感知推理路由</h2>
<p><strong>英文标题</strong>: Think When Needed: Model-Aware Reasoning Routing for LLM-based Ranking</p>
<p><strong>作者</strong>: Huizhong Guo、Tianjun Wei、Dongxia Wang、Yingpeng Du、等3人</p>
<p><strong>提交时间</strong>: 2026-01-26 13:09</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.18146v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接针对推荐系统中的排序任务，提出了创新的推理路由机制来优化LLM的效率和效果，与排序核心技术高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对大语言模型应用于检索和推荐排序任务时，推理提示技术带来的计算成本高且效果不稳定的问题，提出了一种推理路由框架。核心方法是设计一个轻量级、即插即用的路由头，在生成前根据预生成信号（包括紧凑的排序感知特征和模型感知的难度信号）为每个实例选择直接推理或推理模式。创新点在于通过诊断清单评估模型对推理的需求，并允许在部署时沿验证帕累托前沿自适应选择操作策略，从而在系统约束变化下动态分配计算资源。实验表明，该方法在多个公开排序数据集上能显著提升排序效果并大幅减少token消耗，实现了精度与效率的权衡。</p>
<hr />
<h2>11. PI2I：一种个性化的基于物品的协同过滤检索框架</h2>
<p><strong>英文标题</strong>: PI2I: A Personalized Item-Based Collaborative Filtering Retrieval Framework</p>
<p><strong>作者</strong>: Shaoqing Wang、Yingcai Ma、Kairui Fu、Ziyang Wang、等3人</p>
<p><strong>提交时间</strong>: 2026-01-23 23:10</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.16815v1">查看原文</a></p>
<p><strong>所属公司</strong>: 阿里巴巴（淘宝）</p>
<p><strong>命中关键词</strong>: 【3】 taobao, retrieval, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文聚焦于推荐系统的核心召回阶段，提出了创新的两阶段个性化检索框架，并在淘宝大规模场景中验证了效果，具有较高的实践参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对传统协同过滤和双塔模型在捕捉复杂用户-物品交互时存在的截断策略单一和交互建模不足的问题，提出了一个名为PI2I的两阶段个性化检索框架。该框架在第一阶段通过放宽截断阈值来最大化命中率，构建更丰富的候选池；在第二阶段引入交互式评分模型，超越传统内积计算，以更好地建模用户-物品交互。此外，论文基于触发-目标关系构建负样本，确保离线训练与在线推理的一致性，并在淘宝“猜你喜欢”场景中实现了在线交易率的显著提升。</p>
<hr />
<h2>12. PRISM：面向生成式序列推荐的净化表示与集成语义建模</h2>
<p><strong>英文标题</strong>: PRISM: Purified Representation and Integrated Semantic Modeling for Generative Sequential Recommendation</p>
<p><strong>作者</strong>: Dengzhao Fang、Jingtong Gao、Yu Li、Xiangyu Zhao、等1人</p>
<p><strong>提交时间</strong>: 2026-01-23 16:50</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.16556v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接针对推荐系统中的召回与排序一体化框架进行创新，提出了解决语义表示质量和生成结构化的新方法，具有较高的技术相关性。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对生成式序列推荐（GSR）中存在的两大关键问题提出了PRISM框架。首先，通过设计净化语义量化器，采用自适应协同去噪和分层语义锚定机制构建鲁棒的码本，解决了传统量化方法因交互噪声和码本坍缩导致的语义ID歧义问题。其次，提出集成语义推荐器，通过动态语义集成机制融合细粒度语义，并利用语义结构对齐目标增强逻辑有效性，以弥补量化过程中的信息损失。实验表明，PRISM在四个真实数据集上显著优于现有基线，尤其在数据稀疏场景下性能提升明显。</p>
<hr />
<h2>13. 通过上下文老虎机优化用户档案以实现检索增强的大语言模型个性化</h2>
<p><strong>英文标题</strong>: Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization</p>
<p><strong>作者</strong>: Linfeng Du、Ye Yuan、Zichen Zhao、Fuyuan Lyu、等7人</p>
<p><strong>提交时间</strong>: 2026-01-17 23:05</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.12078v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文核心涉及检索后的重排（ranking）优化，通过新的建模方法（上下文老虎机与Plackett-Luce模型）提升个性化效果，与推荐系统的排序和列表优化技术高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对大语言模型（LLM）个性化响应中，传统基于语义相关性检索用户历史记录的方法存在不足的问题，提出了一种名为PURPLE的上下文老虎机框架。该方法的核心创新在于将用户档案构建视为一个集合生成过程，利用Plackett-Luce排序模型来捕捉记录间复杂的相互依赖关系，而非贪婪地选择最相关的记录。通过使用参考响应的似然概率作为密集反馈进行训练，PURPLE直接将检索过程与生成质量对齐，从而在多个个性化任务上，在效果和效率上均优于现有的启发式和检索增强基线。</p>
<hr />
<h2>14. LANCER：基于大语言模型的子信息覆盖重排方法</h2>
<p><strong>英文标题</strong>: LANCER: LLM Reranking for Nugget Coverage</p>
<p><strong>作者</strong>: Jia-Huei Ju、François G. Landry、Eugene Yang、Suzan Verberne、等1人</p>
<p><strong>提交时间</strong>: 2026-01-30 01:16</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.22008v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索结果的重排优化，与推荐系统的排序阶段有技术关联，但其核心目标是信息覆盖度而非用户行为建模或价值预估。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对长文本检索增强生成任务中传统检索方法过度关注相关性排序而忽视信息覆盖度的问题，提出了一种名为LANCER的大语言模型重排方法。该方法的核心创新在于通过生成子问题来分解信息需求，预测文档对各个子问题的回答能力，并以此对文档进行重排以最大化信息覆盖度。实验结果表明，LANCER在信息覆盖度指标上优于其他基于大语言模型的重排方法，且子问题生成被证明是提升覆盖效果的关键环节。</p>
<hr />
<h2>15. XProvence：面向检索增强生成的多语言零成本上下文剪枝模型</h2>
<p><strong>英文标题</strong>: XProvence: Zero-Cost Multilingual Context Pruning for Retrieval-Augmented Generation</p>
<p><strong>作者</strong>: Youssef Mohamed、Mohamed Elhoseiny、Thibault Formal、Nadezhda Chirkova</p>
<p><strong>提交时间</strong>: 2026-01-27 03:00</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.18886v1">查看原文</a></p>
<p><strong>所属公司</strong>: NAVER</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, explore</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索与重排（re-ranking）技术，这是推荐系统排序阶段的核心组成部分，但其主要应用场景是问答而非典型推荐。</p>
<p><strong>摘要总结</strong>:<br />
本文提出了XProvence，一种面向检索增强生成（RAG）的多语言零成本上下文剪枝模型。该模型在16种语言上训练，并通过有效的跨语言迁移支持100多种语言，旨在将原本仅适用于英语的Provence框架（首次将高效零成本上下文剪枝直接集成到重排模型中）推广到多语言场景。在四个多语言问答基准测试中，XProvence能够在几乎不损失性能的情况下有效剪枝RAG上下文，并优于多个强基线模型。</p>
<hr />
<h2>16. 基于大语言模型的金融技术专利实时引文推荐</h2>
<p><strong>英文标题</strong>: LLM-powered Real-time Patent Citation Recommendation for Financial Technologies</p>
<p><strong>作者</strong>: Tianang Deng、Yu Deng、Tianchen Gao、Yonghong Hu、等1人</p>
<p><strong>提交时间</strong>: 2026-01-23 22:21</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.16775v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及推荐系统的召回（近似最近邻搜索）和排序（语义相似度排序）环节，但未深入探讨重排、价值建模或因果推断等推荐系统核心方向。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对金融技术领域专利快速增长、动态变化的特点，提出了一种实时专利引文推荐框架。核心方法采用三阶段流程：首先利用大语言模型（LLM）嵌入表示专利摘要的语义内容；然后通过高效的近似最近邻搜索构建候选集；最后基于语义相似度对候选专利进行排序生成推荐。主要创新点在于采用基于分层可导航小世界（HNSW）图的增量索引策略，支持新专利的实时添加而无需重建整个索引，在动态环境中显著提升了召回率并大幅降低了计算成本。</p>
<hr />
<h2>17. Rank4Gen：面向RAG偏好对齐的文档集选择与排序</h2>
<p><strong>英文标题</strong>: Rank4Gen: RAG-Preference-Aligned Document Set Selection and Ranking</p>
<p><strong>作者</strong>: Yongqi Fan、Yuxiang Chu、Zhentao Xia、Xiaoyang Chen、等7人</p>
<p><strong>提交时间</strong>: 2026-01-16 21:19</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.11273v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文聚焦于检索排序与下游任务（生成）的对齐优化，虽涉及排序技术，但更偏向信息检索与生成模型的交叉领域，而非推荐系统核心的CTR/CVR预估或重排多样性等方向。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对RAG（检索增强生成）中传统检索排序模型仅优化查询-文档相关性，而与生成器在证据选择和引用方面的偏好不一致的问题，提出了Rank4Gen框架。其核心创新在于两点：一是将排序优化目标从相关性转向下游生成响应质量，二是通过单一排序器适配不同生成器来建模生成器特定的排序偏好。为支持该模型，作者构建了PRISM数据集，并在五个RAG基准测试中验证了该方法在复杂证据组合任务上的有效性。</p>
<hr />
<h2>18. 科学信息的“三巨头”：Web of Science、Scopus与OpenAlex的比较文献计量综述</h2>
<p><strong>英文标题</strong>: The 'Big Three' of Scientific Information: A comparative bibliometric review of Web of Science, Scopus, and OpenAlex</p>
<p><strong>作者</strong>: Daniel Torres-Salinas、Wenceslao Arroyo-Machado</p>
<p><strong>提交时间</strong>: 2026-01-30 00:00</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.21908v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 recommendation, explore, diversity</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要关注文献数据库的计量比较，与推荐系统的核心技术关联较弱，仅涉及“多样性”等边缘概念。</p>
<p><strong>摘要总结</strong>:<br />
该论文对Web of Science、Scopus和OpenAlex这三个主流多学科文献数据库进行了比较研究，旨在通过系统综述和原创文献计量分析，提供关于其覆盖范围、元数据质量和功能特性的最新证据。研究方法包括对近期学术文献的系统回顾，分析记录量、开放获取覆盖、语言多样性、参考文献覆盖和元数据质量，并对2015-2024年期间的数据进行纵向分布、文档类型、主题分布、语言差异和数据库重叠的原创分析。创新点在于全面比较了三大数据库的现状，为研究评估中的战略决策提供了实证依据，并提出了十点执行摘要和五项建议。</p>
<hr />
<h2>19. FinMetaMind：面向金融知识搜索的自然语言查询系统技术蓝图</h2>
<p><strong>英文标题</strong>: FinMetaMind: A Tech Blueprint on NLQ Systems for Financial Knowledge Search</p>
<p><strong>作者</strong>: Lalit Pant、Shivang Nagar</p>
<p><strong>提交时间</strong>: 2026-01-24 14:30</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.17333v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要关注信息检索中的检索和排序技术，与推荐系统的核心方向（如重排、LTV、因果推断）关联较弱。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种面向金融知识搜索的现代自然语言查询（NLQ）系统技术蓝图，旨在通过自然语言处理、搜索工程和向量数据模型等核心技术，提升金融数据检索的准确性和召回率。论文详细阐述了系统架构，包括离线索引和在线检索组件，并针对金融数据特有的实体识别、相关性排序和数据新鲜度等挑战提出了解决方案。创新点在于将NLQ技术专门应用于金融领域，通过高效连接分散的金融对象、事件和关系，为用户提供更深入的洞察，同时论文还提供了实验方法和未来优化方向的详细分析。</p>
<hr />
<h2>20. 大语言模型辅助的伪相关反馈</h2>
<p><strong>英文标题</strong>: LLM-Assisted Pseudo-Relevance Feedback</p>
<p><strong>作者</strong>: David Otero、Javier Parapar</p>
<p><strong>提交时间</strong>: 2026-01-16 20:31</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.11238v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要聚焦于信息检索领域的查询扩展技术，与推荐系统的核心方向（如重排、LTV、因果推断）关联较弱。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对传统伪相关反馈方法（如RM3）在查询扩展时容易因初始检索结果中的噪声或不相关内容导致主题漂移的问题，提出了一种结合大语言模型与经典方法的混合方案。其核心创新在于，在RM3估计之前引入一个基于LLM的过滤阶段：让LLM对初始排名靠前的文档进行相关性判断，然后仅使用被判定为相关的文档来计算RM3扩展查询模型。这种方法既保留了传统PRF方法的鲁棒性和可解释性，又利用了LLM的语义判断能力来过滤噪声。实验表明，这种简单的干预在多个数据集和指标上均优于盲目的PRF和强基线方法。</p>
<hr />
        <div class="footer">
            <p><a href="../../index.html">← 返回主页</a></p>
            <p>生成时间: 2026年02月02日 12:27:13</p>
        </div>
    </div>
</body>
</html>