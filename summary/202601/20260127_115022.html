<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv cs.IR 每日论文摘要 - 2026年01月27日 11:50:22</title>
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,
        <svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22>
            <ellipse cx=%2250%22 cy=%2275%22 rx=%2235%22 ry=%2220%22 fill=%22%23FFD700%22 stroke=%22%23E6C200%22 stroke-width=%223%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2225%22 ry=%2215%22 fill=%22%23FFF8E7%22/>
            <circle cx=%2240%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2260%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2242%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <circle cx=%2262%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2210%22 ry=%226%22 fill=%22%23FF6B35%22/>
            <path d=%22Q 35 72, 25 85 Q 20 95, 35 95 Q 50 95, 45 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <path d=%22Q 65 72, 75 85 Q 80 95, 65 95 Q 50 95, 55 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <ellipse cx=%2250%22 cy=%2220%22 rx=%2215%22 ry=%2212%22 fill=%22%238B4513%22/>
        </svg>">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #f6f8fa;
            padding: 20px;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: #ffffff;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);
        }

        h1 {
            font-size: 2em;
            margin-bottom: 0.5em;
            padding-bottom: 0.3em;
            border-bottom: 2px solid #eaecef;
            color: #0366d6;
        }

        h2 {
            font-size: 1.5em;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
            padding-bottom: 0.2em;
            border-bottom: 1px solid #eaecef;
        }

        h3 {
            font-size: 1.25em;
            margin-top: 1em;
            margin-bottom: 0.5em;
        }

        p {
            margin-bottom: 1em;
        }

        strong {
            font-weight: 600;
        }

        a {
            color: #0366d6;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        hr {
            border: 0;
            border-top: 1px solid #eaecef;
            margin: 2em 0;
        }

        code {
            background-color: #f6f8fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            font-size: 0.9em;
        }

        pre {
            background-color: #f6f8fa;
            padding: 16px;
            border-radius: 6px;
            overflow-x: auto;
            margin-bottom: 1em;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        .footer {
            margin-top: 3em;
            padding-top: 1em;
            border-top: 1px solid #eaecef;
            text-align: center;
            color: #586069;
            font-size: 0.9em;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }

            body {
                padding: 10px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ArXiv cs.IR 每日论文摘要</h1>
<p><strong>生成时间</strong>: 2026年01月27日 11:50:22<br />
<strong>论文数量</strong>: 20 篇（Top 20）<br />
<strong>排序规则</strong>: 按关键词命中数 + 兴趣评分排序</p>
<hr />
<h2>1. STCRank：快手电商交互式推荐系统中的时空协同排序框架</h2>
<p><strong>英文标题</strong>: STCRank: Spatio-temporal Collaborative Ranking for Interactive Recommender System at Kuaishou E-shop</p>
<p><strong>作者</strong>: Boyang Xia、Ruilin Bao、Hanjun Jiang、Jun Wang、等1人</p>
<p><strong>提交时间</strong>: 2026-01-15 11:18</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.10027v1">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, ranking, recommendation, dau</p>
<p><strong>感兴趣评分</strong>: 【5分】 论文直接针对推荐系统核心的排序问题，涉及多目标优化和序列决策，与重排、价值建模高度相关，且来自工业界知名公司。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对快手电商交互式推荐系统面临的独特挑战，提出了一个新颖的时空协同排序框架。核心挑战包括：全屏沉浸式UI设计导致排序目标（转化、浏览、下滑）之间存在显式干扰，以及序列推荐槽位转换中容易陷入短期贪婪陷阱。为解决这些问题，论文设计了两个关键模块：多目标协同模块通过缓解目标间的重叠与冲突来推动帕累托前沿；多槽位协同模块通过双阶段前瞻排序机制，在整体序列槽位上实现全局最优。实验表明该方法能同时提升购买率和日活跃用户数，并已于2025年6月在快手电商实际部署。</p>
<hr />
<h2>2. 基于对抗对齐与解耦的跨域CTR预测模型：利用全域特征</h2>
<p><strong>英文标题</strong>: Adversarial Alignment and Disentanglement for Cross-Domain CTR Prediction with Domain-Encompassing Features</p>
<p><strong>作者</strong>: Junyou He、Lixi Deng、Huichao Guo、Ye Tang、等2人</p>
<p><strong>提交时间</strong>: 2026-01-24 22:20</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.17472v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 recommendation, ctr, explore, cold-start</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接针对CTR预估这一核心排序问题，提出了创新的跨域特征对齐与解耦方法，对解决冷启动和稀疏性问题有实用价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对跨域推荐中的数据稀疏和冷启动问题，提出了一种名为A²DCDR的创新模型。该方法通过三个关键组件提升性能：采用对抗训练改进最大均值差异以增强泛化能力，利用特征解耦器和重构机制实现域内特征解耦，并创新性地融合了域不变特征、非对齐特征与原始上下文信息。实验表明，该模型在真实数据集和在线A/B测试中均优于现有方法，有效解决了传统方法仅依赖域不变特征与目标域特定特征导致的性能局限。</p>
<hr />
<h2>3. 为何链接：社交媒体帖子中包含超链接的意图分类体系</h2>
<p><strong>英文标题</strong>: Why They Link: An Intent Taxonomy for Including Hyperlinks in Social Posts</p>
<p><strong>作者</strong>: Fangping Lan、Abdullah Aljebreen、Eduard C. Dragut</p>
<p><strong>提交时间</strong>: 2026-01-25 05:32</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.17601v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 twitter, retrieval, recommendation, advertising</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及推荐系统的意图理解和内容理解方向，但未直接涉及重排、LTV、因果推断等核心推荐算法。</p>
<p><strong>摘要总结</strong>:<br />
该论文研究了社交媒体中用户发布包含超链接帖子的意图，提出了一个以读者为中心的意图分类体系。研究方法采用混合方法：首先通过大规模众包标注进行自下而上的数据驱动分析，然后借助大语言模型辅助生成描述性类别名称和精确定义。最终构建了一个包含6个顶层类别和26个细粒度意图类别的分类体系，涵盖了广告、争论、分享等多种传播目的。该分类体系为意图感知的信息检索和自然语言处理应用提供了基础，有助于提升社交媒体内容的检索准确性、推荐效果和理解深度。</p>
<hr />
<h2>4. 指令检索模型真的能支持探索吗？</h2>
<p><strong>英文标题</strong>: Can Instructed Retrieval Models Really Support Exploration?</p>
<p><strong>作者</strong>: Piyush Maheshwari、Sheshera Mysore、Hamed Zamani</p>
<p><strong>提交时间</strong>: 2026-01-16 09:45</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.10936v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, ranking, explore, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索与排序技术，与推荐系统的召回和排序阶段相关，但未直接聚焦于重排、LTV或因果推断等核心推荐方向。</p>
<p><strong>摘要总结</strong>:<br />
该论文研究了指令检索模型在探索性搜索场景下的表现，特别是针对目标不明确且查询意图动态演变的场景。作者通过专家标注的测试集，评估了专门微调的指令检索大模型和采用成对排序提示的通用大模型在方面条件种子引导探索任务中的效果。研究发现，虽然最佳指令检索模型在排序相关性上优于非指令感知方法，但其指令遵循能力并未同步提升，甚至表现出对指令不敏感或反直觉的行为。论文的创新点在于揭示了当前指令检索模型在需要长期、精细指令交互的探索性会话中存在局限性，为检索模型的用户体验评估提供了新视角。</p>
<hr />
<h2>5. 分块、检索与重排：政策文档问答中RAG架构的实证评估</h2>
<p><strong>英文标题</strong>: Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering</p>
<p><strong>作者</strong>: Anuj Maharjan、Umesh Yadav</p>
<p><strong>提交时间</strong>: 2026-01-22 04:52</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.15457v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, ranking, explore, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索与重排技术，与推荐系统的排序阶段有相关性，但核心聚焦于问答系统而非典型推荐场景。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对大型语言模型在公共卫生政策领域应用时易产生幻觉的问题，实证评估了检索增强生成架构在政策文档问答中的有效性。研究比较了基础LLM、基础RAG和采用交叉编码器重排的高级RAG管道，使用Mistral-7B和MiniLM嵌入模型处理CDC政策文档，并分析了递归字符分块和基于语义的令牌分块两种策略对系统准确性的影响。创新点在于通过两阶段检索机制（检索后重排）显著提升了生成答案的忠实度，证明高级RAG架构在专业领域问答中能达到更高精度，同时指出文档分割的结构限制仍是多步推理任务的主要瓶颈。</p>
<hr />
<h2>6. 重新审视基于TREC播客赛道的人类与LLM相关性判断</h2>
<p><strong>英文标题</strong>: Revisiting Human-vs-LLM judgments using the TREC Podcast Track</p>
<p><strong>作者</strong>: Watheq Mansour、J. Shane Culpepper、Joel Mackenzie、Andrew Yates</p>
<p><strong>提交时间</strong>: 2026-01-09 15:45</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.05603v2">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, ranking, explore, relevance</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要研究信息检索中相关性标注的评估方法，与推荐系统的核心技术（如重排、LTV、因果推断）关联较弱。</p>
<p><strong>摘要总结</strong>:<br />
该论文研究了在信息检索中利用大语言模型（LLM）进行相关性标注的可靠性，重点关注了与传统文本搜索不同的音频播客场景（TREC 2020-2021播客赛道）。研究采用五种不同的LLM模型对原本由TREC评估员标注的查询-片段对进行了重新评估，并分析了LLM与人类专家判断的一致性差异及其对系统排序的影响。创新点在于发现，在LLM与TREC评估员分歧最大的样本子集中，人类专家更倾向于同意LLM的判断，从而强化了“依赖单一评估员会降低判断一致性”的已有见解。</p>
<hr />
<h2>7. PI2I：一种个性化的基于物品的协同过滤召回框架</h2>
<p><strong>英文标题</strong>: PI2I: A Personalized Item-Based Collaborative Filtering Retrieval Framework</p>
<p><strong>作者</strong>: Shaoqing Wang、Yingcai Ma、Kairui Fu、Ziyang Wang、等3人</p>
<p><strong>提交时间</strong>: 2026-01-23 23:10</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.16815v1">查看原文</a></p>
<p><strong>所属公司</strong>: 阿里巴巴（淘宝）</p>
<p><strong>命中关键词</strong>: 【3】 taobao, retrieval, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文聚焦于推荐系统的核心召回阶段，提出了创新的两阶段个性化框架，并在淘宝大规模场景中验证了效果，对召回技术有重要参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对传统协同过滤和双塔模型在捕捉复杂用户-物品交互时存在的截断策略单一和交互不足问题，提出了一个名为PI2I的两阶段个性化召回框架。该框架在第一阶段通过放宽截断阈值来最大化命中率，构建更丰富的候选池；在第二阶段引入交互式评分模型，超越传统内积计算，以更好地建模用户-物品交互。此外，论文还基于触发-目标关系构建负样本，确保离线训练与在线推理的一致性，并在淘宝“猜你喜欢”场景中实现了在线交易率的显著提升。</p>
<hr />
<h2>8. 按需思考：基于LLM排序的模型感知推理路由</h2>
<p><strong>英文标题</strong>: Think When Needed: Model-Aware Reasoning Routing for LLM-based Ranking</p>
<p><strong>作者</strong>: Huizhong Guo、Tianjun Wei、Dongxia Wang、Yingpeng Du、等3人</p>
<p><strong>提交时间</strong>: 2026-01-26 13:09</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.18146v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接针对LLM在推荐排序中的应用，提出了创新的推理路由机制以优化计算效率，与推荐系统核心的排序技术高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对大语言模型应用于检索和推荐排序任务时，推理提示方法带来的计算成本高且效果不一致的问题，提出了一种推理路由框架。该框架通过一个轻量级、即插即用的路由头，在生成前根据预生成信号（如候选分散度等排序感知特征和模型感知的难度信号）为每个实例选择直接推理或推理模式。创新点在于引入模型感知的诊断清单来估计推理需求，并允许在部署时沿验证帕累托前沿自适应选择操作策略，从而在系统约束变化下动态分配计算资源。在三个公开排序数据集上的实验表明，该方法能显著提升排序效果并大幅减少token消耗，实现了精度与效率的权衡。</p>
<hr />
<h2>9. GenCI：基于群体意图学习的生成式用户兴趣迁移建模用于CTR预测</h2>
<p><strong>英文标题</strong>: GenCI: Generative Modeling of User Interest Shift via Cohort-based Intent Learning for CTR Prediction</p>
<p><strong>作者</strong>: Kesha Ou、Zhen Tian、Wayne Xin Zhao、Hongyu Lu、等1人</p>
<p><strong>提交时间</strong>: 2026-01-26 16:15</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.18251v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 ranking, ctr, advertising</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接针对CTR预测的核心问题，提出了结合生成式建模和上下文感知的创新排序方法，对重排和用户动态兴趣建模有重要参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对CTR预测中存在的两个关键问题提出GenCI框架：一是现有判别式模型过度依赖历史主导特征，难以适应快速变化的用户兴趣；二是点级排序范式忽略了召回集合的整体上下文信息，导致长期偏好掩盖即时意图。方法上，首先采用基于下一项预测目标的生成模型主动生成候选兴趣群体，作为用户即时意图的显式表示；然后通过分层候选感知网络将这一丰富的上下文信号注入排序阶段，并利用交叉注意力机制使其与用户历史及目标商品对齐。创新点在于通过生成式建模和群体意图学习，将动态的上下文信息引入CTR预测，实现了更精准的用户即时意图捕捉和端到端的训练流程。</p>
<hr />
<h2>10. PRISM：用于生成式序列推荐的净化表示与集成语义建模</h2>
<p><strong>英文标题</strong>: PRISM: Purified Representation and Integrated Semantic Modeling for Generative Sequential Recommendation</p>
<p><strong>作者</strong>: Dengzhao Fang、Jingtong Gao、Yu Li、Xiangyu Zhao、等1人</p>
<p><strong>提交时间</strong>: 2026-01-23 16:50</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.16556v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接涉及推荐系统的召回与排序一体化框架，在生成式序列推荐的语义表示和结构建模方面有实质性创新。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对生成式序列推荐（GSR）中存在的两大关键问题提出了PRISM框架。首先，通过设计净化语义量化器，采用自适应协同去噪和分层语义锚定机制构建鲁棒码本，解决了传统量化方法因交互噪声和码本坍缩导致的语义ID歧义问题。其次，提出集成语义推荐器，通过动态语义集成机制融合细粒度语义，并利用语义结构对齐目标增强逻辑有效性，以弥补量化过程中的信息损失。实验表明，PRISM在四个真实数据集上显著优于现有基线，尤其在数据稀疏场景下性能提升明显。</p>
<hr />
<h2>11. 通过上下文赌博机优化用户档案以实现检索增强的大语言模型个性化</h2>
<p><strong>英文标题</strong>: Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization</p>
<p><strong>作者</strong>: Linfeng Du、Ye Yuan、Zichen Zhao、Fuyuan Lyu、等7人</p>
<p><strong>提交时间</strong>: 2026-01-17 23:05</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.12078v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文核心涉及检索与排序的优化，特别是将档案构建建模为集合生成并使用高级排序模型，与推荐系统的排序和多样性优化高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对大语言模型在个性化响应上的挑战，提出了一种名为PURPLE的检索增强框架。核心创新在于将用户档案构建视为一个集合生成过程，使用Plackett-Luce排序模型来捕捉记录间复杂的依赖关系，而非仅依赖语义相关性进行贪婪选择。该方法通过参考响应的似然概率作为密集反馈进行训练，直接将检索与生成质量对齐，在九个个性化任务上的实验表明其在效果和效率上均优于现有基线方法。</p>
<hr />
<h2>12. MLPlatt：一种简单的排序模型校准框架</h2>
<p><strong>英文标题</strong>: MLPlatt: Simple Calibration Framework for Ranking Models</p>
<p><strong>作者</strong>: Piotr Bajger、Roman Dusek、Krzysztof Galias、Paweł Młyniec、等2人</p>
<p><strong>提交时间</strong>: 2026-01-13 17:04</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.08345v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 ranking, ctr, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接涉及排序模型校准和CTR预估，这是推荐系统排序阶段的核心技术，具有明确的业务应用价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对排序模型在训练后常存在的可解释性差和尺度未校准问题，提出了一种名为MLPlatt的后处理校准方法。该方法能够在保持物品排序不变的前提下，将排序模型的输出转换为可用于下游任务的可解释点击率概率，实现了上下文感知的全局和分层校准。实验表明，MLPlatt在两个数据集上优于现有方法，在F-ECE指标上提升超过10%，且不损害排序质量。</p>
<hr />
<h2>13. 利用大语言模型弥合语义理解与流行度偏差</h2>
<p><strong>英文标题</strong>: Bridging Semantic Understanding and Popularity Bias with LLMs</p>
<p><strong>作者</strong>: Renqiang Luo、Dong Zhang、Yupeng Gao、Wen Shi、等4人</p>
<p><strong>提交时间</strong>: 2026-01-14 21:37</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.09478v3">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 recommendation, diversity, causal</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接针对推荐系统的核心问题（流行度偏差），并创新性地结合了因果推断的视角和大语言模型技术来解决该问题。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对推荐系统中流行度偏差的语义理解这一关键但未被充分探索的挑战，提出了FairLRM框架。该方法将流行度偏差分解为物品侧和用户侧两部分，并利用基于结构化指令的提示来增强模型对全局物品分布和个体用户偏好的理解。其创新点在于超越了传统方法仅关注“多样性”或“去偏”等表层特征的局限，通过大语言模型（RecLLM）从语义层面理解和解决偏差的因果根源，从而在提升公平性的同时保证了推荐准确性。</p>
<hr />
<h2>14. 基于大语言模型的金融技术专利实时引文推荐</h2>
<p><strong>英文标题</strong>: LLM-powered Real-time Patent Citation Recommendation for Financial Technologies</p>
<p><strong>作者</strong>: Tianang Deng、Yu Deng、Tianchen Gao、Yonghong Hu、等1人</p>
<p><strong>提交时间</strong>: 2026-01-23 22:21</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.16775v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及推荐系统的召回（近似最近邻搜索）和排序（语义相似度排序）环节，但未深入探讨重排、价值建模或因果推断等推荐系统核心方向。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对金融技术领域专利快速增长、动态变化的特点，提出了一种实时专利引文推荐框架。核心方法采用三阶段流程：首先利用大语言模型（LLM）嵌入表示专利摘要的语义内容；然后通过高效的近似最近邻搜索构建候选集；最后基于语义相似度对候选专利进行排序，生成top-k引文推荐。主要创新点在于采用基于分层可导航小世界（HNSW）图的增量索引策略，能够在不重建整个索引的情况下添加新专利，从而有效应对专利系统的动态性，在提升召回率的同时显著降低计算成本。</p>
<hr />
<h2>15. Rank4Gen：面向RAG偏好对齐的文档集选择与排序</h2>
<p><strong>英文标题</strong>: Rank4Gen: RAG-Preference-Aligned Document Set Selection and Ranking</p>
<p><strong>作者</strong>: Yongqi Fan、Yuxiang Chu、Zhentao Xia、Xiaoyang Chen、等7人</p>
<p><strong>提交时间</strong>: 2026-01-16 21:19</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.11273v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及排序模型优化和偏好建模，与推荐系统的排序技术相关，但主要面向RAG而非传统推荐场景。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对RAG（检索增强生成）中传统检索排序模型仅优化查询-文档相关性，而与生成器在证据选择和引用方面的偏好不一致的问题，提出了Rank4Gen方法。核心创新包括两点：一是将排序优化目标从相关性转向下游生成响应质量，二是通过单一排序器适配不同生成器来建模其特异性偏好。为此，作者构建了PRISM数据集，并在五个RAG基准测试中验证了该方法在复杂证据组合任务上的有效性和竞争力。</p>
<hr />
<h2>16. Deep GraphRAG：一种分层检索与自适应集成的平衡方法</h2>
<p><strong>英文标题</strong>: Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval and Adaptive Integration</p>
<p><strong>作者</strong>: Yuejie Li、Ke Yang、Tao Wang、Bolin Chen、等2人</p>
<p><strong>提交时间</strong>: 2026-01-16 18:02</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.11144v2">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文核心涉及检索、多阶段重排和相关性优化，与推荐系统的排序和召回技术有较强关联，但主要聚焦于RAG框架而非传统推荐场景。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种名为Deep GraphRAG的新型图检索增强生成框架，旨在解决现有方法在全局搜索全面性与局部搜索效率之间的权衡难题。其核心创新在于设计了一个从全局到局部的分层检索策略，该策略包含三个阶段：社区间过滤、社区级精炼和实体级细粒度搜索，并通过一个基于波束搜索优化的动态重排模块来引导整个过程，以平衡效率与全局覆盖。此外，论文还引入了一个知识集成模块，该模块采用一种新颖的强化学习方法——动态加权奖励GRPO（DW-GRPO）来训练紧凑的LLM，使其能够动态调整奖励权重以平衡相关性、忠实性和简洁性三个关键目标，从而使小模型（1.5B）在集成任务上能接近大模型（70B）的性能。</p>
<hr />
<h2>17. OpenDecoder：开放大语言模型解码以在RAG中融入文档质量</h2>
<p><strong>英文标题</strong>: OpenDecoder: Open Large Language Model Decoding to Incorporate Document Quality in RAG</p>
<p><strong>作者</strong>: Fengran Mo、Zhan Su、Yuchen Hui、Jinghan Zhang、等5人</p>
<p><strong>提交时间</strong>: 2026-01-14 07:26</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.09028v2">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及信息检索中的相关性评估和排序，与推荐系统的排序阶段有间接关联，但核心是RAG的生成优化而非推荐系统的核心任务。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对检索增强生成（RAG）中检索信息质量参差不齐的问题，提出了一种名为OpenDecoder的新方法。其核心创新在于，在LLM生成答案时，显式地引入对检索信息的质量评估特征作为生成过程的指导信号。具体方法考虑了三种显式评估信息：相关性分数、排序分数和查询性能预测（QPP）分数，旨在构建一个对噪声上下文更具鲁棒性的RAG模型。实验在五个基准数据集上进行，结果表明OpenDecoder在效果和鲁棒性上优于多种基线方法，并且该范式灵活，可与任何目的的LLM后训练结合，并融入任何类型的外部指标。</p>
<hr />
<h2>18. FinCARDS：基于卡片分析的金融文档问答重排框架</h2>
<p><strong>英文标题</strong>: FinCARDS: Card-Based Analyst Reranking for Financial Document Question Answering</p>
<p><strong>作者</strong>: Yixi Zhou、Fan Zhang、Yu Chen、Haipeng Zhang、等2人</p>
<p><strong>提交时间</strong>: 2026-01-12 01:03</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.06992v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索与重排技术，但主要面向金融文档QA的专业领域，与通用推荐系统的核心场景关联度有限。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对金融领域长文档问答中的证据检索问题，提出了FinCards结构化重排框架。核心方法是将金融证据选择重新定义为在金融感知模式下的约束满足问题，通过对文档片段和问题进行模式字段对齐（实体、指标、期间、数值跨度），实现确定性字段级匹配。创新点在于采用多阶段锦标赛重排与稳定性感知聚合机制进行证据选择，并生成可审计的决策轨迹，无需模型微调即可显著提升检索效果并降低排序方差。</p>
<hr />
<h2>19. FinMetaMind：面向金融知识搜索的自然语言查询系统技术蓝图</h2>
<p><strong>英文标题</strong>: FinMetaMind: A Tech Blueprint on NLQ Systems for Financial Knowledge Search</p>
<p><strong>作者</strong>: Lalit Pant、Shivang Nagar</p>
<p><strong>提交时间</strong>: 2026-01-24 14:30</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.17333v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要关注信息检索中的检索和排序技术，与推荐系统的核心方向（如重排、LTV、因果推断）关联较弱。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种面向金融知识搜索的现代自然语言查询（NLQ）系统技术蓝图，旨在通过自然语言处理、搜索工程和向量数据模型等核心技术，提升金融数据检索的准确性和召回率。论文详细阐述了系统架构，包括离线索引和在线检索组件，并针对金融数据特有的实体识别、相关性排序和数据新鲜度等挑战提出了解决方案。创新点在于将NLQ技术专门应用于金融领域，通过高效关联分散的金融对象、事件和关系，为用户提供更深入的洞察，同时论文还提供了实验方法和未来优化方向的详细分析。</p>
<hr />
<h2>20. 大语言模型辅助的伪相关反馈</h2>
<p><strong>英文标题</strong>: LLM-Assisted Pseudo-Relevance Feedback</p>
<p><strong>作者</strong>: David Otero、Javier Parapar</p>
<p><strong>提交时间</strong>: 2026-01-16 20:31</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.11238v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要研究信息检索中的查询扩展技术，与推荐系统的核心方向（如重排、LTV、因果推断）关联较弱。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对传统伪相关反馈方法（如RM3）在查询扩展时容易因初始检索结果中的噪声或不相关内容而导致主题漂移的问题，提出了一种结合大语言模型的混合方法。核心创新在于在RM3估计之前引入一个基于LLM的过滤阶段：LLM对初始排名靠前的文档进行相关性判断，RM3仅基于被判定为相关的文档来计算扩展查询模型。这种方法既保留了经典PRF方法的鲁棒性和可解释性，又利用了LLM的语义判断能力，从而避免了LLM直接生成扩展可能带来的幻觉或与特定文档集术语不匹配的风险。实验表明，这种简单的干预在多个数据集和指标上均优于盲目的PRF和强基线方法。</p>
<hr />
        <div class="footer">
            <p><a href="../../index.html">← 返回主页</a></p>
            <p>生成时间: 2026年01月27日 11:50:22</p>
        </div>
    </div>
</body>
</html>