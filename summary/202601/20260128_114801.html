<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ArXiv cs.IR 每日论文摘要 - 2026年01月28日 11:48:01</title>
    <link rel="icon" type="image/svg+xml" href="data:image/svg+xml,
        <svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22>
            <ellipse cx=%2250%22 cy=%2275%22 rx=%2235%22 ry=%2220%22 fill=%22%23FFD700%22 stroke=%22%23E6C200%22 stroke-width=%223%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2225%22 ry=%2215%22 fill=%22%23FFF8E7%22/>
            <circle cx=%2240%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2260%22 cy=%2260%22 r=%228%22 fill=%22%23333%22/>
            <circle cx=%2242%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <circle cx=%2262%22 cy=%2258%22 r=%223%22 fill=%22%23FFF%22/>
            <ellipse cx=%2250%22 cy=%2270%22 rx=%2210%22 ry=%226%22 fill=%22%23FF6B35%22/>
            <path d=%22Q 35 72, 25 85 Q 20 95, 35 95 Q 50 95, 45 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <path d=%22Q 65 72, 75 85 Q 80 95, 65 95 Q 50 95, 55 85%22 fill=%22%23FF8C00%22 stroke=%22%23E67300%22 stroke-width=%222%22/>
            <ellipse cx=%2250%22 cy=%2220%22 rx=%2215%22 ry=%2212%22 fill=%22%238B4513%22/>
        </svg>">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            line-height: 1.6;
            color: #24292e;
            background-color: #f6f8fa;
            padding: 20px;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: #ffffff;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);
        }

        h1 {
            font-size: 2em;
            margin-bottom: 0.5em;
            padding-bottom: 0.3em;
            border-bottom: 2px solid #eaecef;
            color: #0366d6;
        }

        h2 {
            font-size: 1.5em;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
            padding-bottom: 0.2em;
            border-bottom: 1px solid #eaecef;
        }

        h3 {
            font-size: 1.25em;
            margin-top: 1em;
            margin-bottom: 0.5em;
        }

        p {
            margin-bottom: 1em;
        }

        strong {
            font-weight: 600;
        }

        a {
            color: #0366d6;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        hr {
            border: 0;
            border-top: 1px solid #eaecef;
            margin: 2em 0;
        }

        code {
            background-color: #f6f8fa;
            padding: 0.2em 0.4em;
            border-radius: 3px;
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, monospace;
            font-size: 0.9em;
        }

        pre {
            background-color: #f6f8fa;
            padding: 16px;
            border-radius: 6px;
            overflow-x: auto;
            margin-bottom: 1em;
        }

        pre code {
            background-color: transparent;
            padding: 0;
        }

        .footer {
            margin-top: 3em;
            padding-top: 1em;
            border-top: 1px solid #eaecef;
            text-align: center;
            color: #586069;
            font-size: 0.9em;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }

            body {
                padding: 10px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ArXiv cs.IR 每日论文摘要</h1>
<p><strong>生成时间</strong>: 2026年01月28日 11:48:01<br />
<strong>论文数量</strong>: 20 篇（Top 20）<br />
<strong>排序规则</strong>: 按关键词命中数 + 兴趣评分排序</p>
<hr />
<h2>1. STCRank：快手电商交互式推荐系统中的时空协同排序框架</h2>
<p><strong>英文标题</strong>: STCRank: Spatio-temporal Collaborative Ranking for Interactive Recommender System at Kuaishou E-shop</p>
<p><strong>作者</strong>: Boyang Xia、Ruilin Bao、Hanjun Jiang、Jun Wang、等1人</p>
<p><strong>提交时间</strong>: 2026-01-15 11:18</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.10027v1">查看原文</a></p>
<p><strong>所属公司</strong>: 快手</p>
<p><strong>命中关键词</strong>: 【4】 kuaishou, ranking, recommendation, dau</p>
<p><strong>感兴趣评分</strong>: 【5分】 该论文直接针对推荐系统排序阶段的多目标优化和序列决策问题，涉及重排、价值建模和因果推断相关技术，且来自工业界头部公司。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对快手电商交互式推荐系统在沉浸式全屏UI和下滑浏览功能下面临的两大挑战：一是转化、浏览和下滑等多目标之间存在显式干扰与冲突；二是全屏设计容易导致序列推荐槽位转换时陷入短期贪婪陷阱。为此，作者提出了时空协同排序框架STCRank，包含多目标协同模块和多槽位协同模块。多目标协同模块通过缓解目标间的重叠与冲突来推动帕累托前沿；多槽位协同模块则通过双阶段前瞻排序机制实现整体序列槽位的全局优化。实验表明该方法能同时提升购买率和日活跃用户数，并已部署于快手电商平台。</p>
<hr />
<h2>2. 基于对抗对齐与解耦的跨域CTR预测模型：利用全域特征</h2>
<p><strong>英文标题</strong>: Adversarial Alignment and Disentanglement for Cross-Domain CTR Prediction with Domain-Encompassing Features</p>
<p><strong>作者</strong>: Junyou He、Lixi Deng、Huichao Guo、Ye Tang、等2人</p>
<p><strong>提交时间</strong>: 2026-01-24 22:20</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.17472v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 recommendation, ctr, explore, cold-start</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文聚焦于CTR预估和冷启动等推荐系统核心问题，提出的对抗对齐与特征解耦方法具有较好的创新性。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对跨域推荐中的数据稀疏和冷启动问题，提出了一种名为A²DCDR的创新模型。该方法通过三个关键组件提升性能：首先，结合对抗训练改进最大均值差异（MMD）以增强泛化能力；其次，采用特征解耦器和重构机制实现域内特征解耦；最后，创新性地融合了域不变特征、未对齐特征与原始上下文信息，形成更全面的跨域表征。实验表明，该模型在真实数据集和在线A/B测试中均优于现有方法，验证了其有效性和实用性。</p>
<hr />
<h2>3. 为何链接：社交媒体帖子中包含超链接的意图分类体系</h2>
<p><strong>英文标题</strong>: Why They Link: An Intent Taxonomy for Including Hyperlinks in Social Posts</p>
<p><strong>作者</strong>: Fangping Lan、Abdullah Aljebreen、Eduard C. Dragut</p>
<p><strong>提交时间</strong>: 2026-01-25 05:32</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.17601v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 twitter, retrieval, recommendation, advertising</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文构建的意图分类体系可直接应用于推荐系统的内容理解和用户意图建模，但未直接涉及重排、LTV、因果推断等推荐系统核心算法。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对社交媒体中广泛存在的超链接现象，从读者视角而非作者视角出发，研究用户如何理解帖子中包含超链接的意图。研究方法采用混合方法：首先通过大规模众包标注进行自底向上的数据驱动分析，然后借助大语言模型辅助生成描述性类别名称和精确定义，最终构建了一个包含6个顶层类别和26个细粒度意图类别的分类体系。该分类体系揭示了广告、争论和分享是最普遍的链接意图，为意图感知的信息检索和自然语言处理应用提供了基础，能够提升社交媒体内容的检索、推荐和理解准确性。</p>
<hr />
<h2>4. 指令检索模型真的能支持探索吗？</h2>
<p><strong>英文标题</strong>: Can Instructed Retrieval Models Really Support Exploration?</p>
<p><strong>作者</strong>: Piyush Maheshwari、Sheshera Mysore、Hamed Zamani</p>
<p><strong>提交时间</strong>: 2026-01-16 09:45</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.10936v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, ranking, explore, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索与排序技术，与推荐系统的召回和排序阶段相关，但未直接聚焦于重排、LTV或因果推断等核心推荐技术。</p>
<p><strong>摘要总结</strong>:<br />
该论文研究了指令检索模型在探索性搜索场景下的表现，探索性搜索的特点是目标不明确且查询意图不断演变。作者通过专家标注的测试集，评估了针对指令微调的LLM和使用成对排序提示的通用LLM在方面条件种子引导探索任务中的性能。研究发现，虽然最佳指令检索器在排序相关性上优于无视指令的方法，但其指令跟随能力（对用户体验至关重要）并未同步提升，甚至表现出对指令不敏感或反直觉的行为。论文的创新点在于揭示了当前指令检索模型在需要长期、对指令敏感的探索性会话中的局限性，为检索模型的评估和应用提供了新视角。</p>
<hr />
<h2>5. 分块、检索与重排：政策文档问答中RAG架构的实证评估</h2>
<p><strong>英文标题</strong>: Chunking, Retrieval, and Re-ranking: An Empirical Evaluation of RAG Architectures for Policy Document Question Answering</p>
<p><strong>作者</strong>: Anuj Maharjan、Umesh Yadav</p>
<p><strong>提交时间</strong>: 2026-01-22 04:52</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.15457v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【4】 retrieval, ranking, explore, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索与重排技术，与推荐系统的排序环节相关，但核心场景是文档问答而非典型推荐。</p>
<p><strong>摘要总结</strong>:<br />
本研究针对公共卫生政策领域，评估了检索增强生成（RAG）架构在减少大语言模型（LLM）幻觉风险方面的有效性。论文比较了基础LLM、基础RAG和采用交叉编码器重排的高级RAG三种方案，使用Mistral-7B模型和MiniLM嵌入模型处理CDC政策文档，并分析了递归字符分块与基于语义的令牌分块两种策略对系统准确性的影响。核心创新在于通过两阶段检索与重排机制显著提升了答案的忠实度（从基线0.347提升至0.797），证明了高级RAG在专业政策问答中实现高精度的必要性，同时指出文档分割结构仍是多步推理任务的主要瓶颈。</p>
<hr />
<h2>6. LURE-RAG：面向高效RAG的轻量级效用驱动重排序</h2>
<p><strong>英文标题</strong>: LURE-RAG: Lightweight Utility-driven Reranking for Efficient RAG</p>
<p><strong>作者</strong>: Manish Chandra、Debasis Ganguly、Iadh Ounis</p>
<p><strong>提交时间</strong>: 2026-01-27 20:26</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.19535v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接涉及推荐系统中的核心排序技术（列表排序损失、LambdaMART重排序），且创新性地将效用建模与排序优化结合，对推荐系统的重排算法设计有借鉴意义。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对传统检索增强生成（RAG）管道中基于相关性的检索与下游任务实际效用不匹配的问题，提出了一种轻量级效用驱动重排序框架LURE-RAG。该方法的核心创新在于：首先，通过引入基于LambdaMART的重排序器，无需查询编码即可高效运行；其次，在训练中采用基于LLM效用的列表排序损失，直接优化检索文档的排序顺序以提升生成质量。实验表明，LURE-RAG在保持训练和推理高效性的同时，性能达到当前最优密集神经基线的97-98%，其密集变体UR-RAG甚至比现有最佳基线提升高达3%。</p>
<hr />
<h2>7. 大语言模型作为编排者：面向推荐系统的约束合规多智能体优化</h2>
<p><strong>英文标题</strong>: LLMs as Orchestrators: Constraint-Compliant Multi-Agent Optimization for Recommendation Systems</p>
<p><strong>作者</strong>: Guilin Zhang、Kai Zhao、Jeffrey Friedman、Xu Chu</p>
<p><strong>提交时间</strong>: 2026-01-27 10:46</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.19121v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 amazon, recommendation, diversity</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接针对推荐系统的核心挑战——多目标优化与硬约束满足，并创新性地将LLM用于重排阶段的智能体协调与资源分配，与重排、多样性等研究方向高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对推荐系统需优化多目标并满足硬性业务约束（如公平性、覆盖率）的挑战，提出了一个名为DualAgent-Rec的LLM协调双智能体框架。该框架将优化过程分解为两个部分：一个是在硬约束下优先考虑准确性的“利用智能体”，另一个是通过无约束帕累托搜索来促进多样性的“探索智能体”。核心创新在于利用大语言模型作为协调器，根据优化进度和约束满足情况自适应地在两个智能体之间分配资源，并引入自适应epsilon松弛机制来保证最终解的可行性。在Amazon Reviews 2023数据集上的实验表明，该方法实现了100%的约束满足率，并将帕累托超体积提升了4-6%，同时保持了有竞争力的准确性与多样性权衡。</p>
<hr />
<h2>8. 按需思考：基于LLM排序的模型感知推理路由</h2>
<p><strong>英文标题</strong>: Think When Needed: Model-Aware Reasoning Routing for LLM-based Ranking</p>
<p><strong>作者</strong>: Huizhong Guo、Tianjun Wei、Dongxia Wang、Yingpeng Du、等3人</p>
<p><strong>提交时间</strong>: 2026-01-26 13:09</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.18146v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文直接针对推荐系统的排序环节，提出了创新的推理路由机制来优化LLM在排序任务中的效率与效果平衡。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对大型语言模型在检索和推荐排序任务中应用时，推理提示技术带来的计算成本高且效果不稳定的问题，提出了一种推理路由框架。核心方法是设计一个轻量级、即插即用的路由头，在生成前根据预生成信号（包括紧凑的排序感知特征和模型感知的难度信号）为每个实例选择直接推理或推理模式。创新点在于通过诊断清单反映模型对推理的预估需求，使路由器能够输出可控令牌决定是否启用思考模式，并能在部署时沿验证帕累托前沿自适应选择操作策略，动态分配计算资源。实验表明，该方法在多个公开排序数据集上能显著提升排序效果并大幅减少令牌消耗，实现了精度与效率的权衡。</p>
<hr />
<h2>9. GenCI：基于群体意图学习的生成式用户兴趣漂移建模用于CTR预测</h2>
<p><strong>英文标题</strong>: GenCI: Generative Modeling of User Interest Shift via Cohort-based Intent Learning for CTR Prediction</p>
<p><strong>作者</strong>: Kesha Ou、Zhen Tian、Wayne Xin Zhao、Hongyu Lu、等1人</p>
<p><strong>提交时间</strong>: 2026-01-26 16:15</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.18251v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 ranking, ctr, advertising</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接针对CTR预测的核心排序问题，提出了结合生成式建模和上下文感知的创新方法，对解决兴趣漂移和上下文信息利用不足有重要价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对CTR预测中存在的两个关键问题提出了一种生成式用户意图框架GenCI。首先，现有判别式方法容易过度拟合历史主导特征，难以适应快速变化的用户兴趣；其次，点对点排序范式忽略了召回集合整体的丰富上下文信息，导致长期偏好压制了用户的即时意图。GenCI的核心方法是：使用基于下一项预测目标训练的生成模型，主动生成候选兴趣群体作为用户即时意图的显式表示；然后通过分层候选感知网络，利用交叉注意力将这些上下文信号注入排序阶段，使其与用户历史和目标商品对齐。整个模型采用端到端训练，构建了一个更对齐、更有效的CTR预测流程。在三个广泛使用的数据集上的实验证明了该方法的有效性。</p>
<hr />
<h2>10. PI2I：一种个性化的基于物品的协同过滤检索框架</h2>
<p><strong>英文标题</strong>: PI2I: A Personalized Item-Based Collaborative Filtering Retrieval Framework</p>
<p><strong>作者</strong>: Shaoqing Wang、Yingcai Ma、Kairui Fu、Ziyang Wang、等3人</p>
<p><strong>提交时间</strong>: 2026-01-23 23:10</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.16815v1">查看原文</a></p>
<p><strong>所属公司</strong>: 阿里巴巴（淘宝）</p>
<p><strong>命中关键词</strong>: 【3】 taobao, retrieval, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文聚焦于推荐系统的核心召回阶段，提出了创新的两阶段个性化检索框架，并在淘宝真实场景中验证了效果，具有较高的实践参考价值。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对传统协同过滤和双塔模型在捕捉复杂用户-物品交互时存在的截断策略单一和交互建模不足的问题，提出了一个名为PI2I的两阶段个性化检索框架。该框架在第一阶段通过放宽截断阈值来最大化命中率，构建更丰富的候选池；在第二阶段引入交互式评分模型，以超越内积计算的限制，从而更精细地建模用户-物品交互。此外，论文还基于触发-目标关系构建负样本，确保离线训练与在线推理的一致性。通过在淘宝“猜你喜欢”场景的部署，该模型实现了在线交易率1.05%的提升，并开源了一个包含1.3亿真实用户交互的大规模数据集。</p>
<hr />
<h2>11. PRISM：用于生成式序列推荐的净化表示与集成语义建模</h2>
<p><strong>英文标题</strong>: PRISM: Purified Representation and Integrated Semantic Modeling for Generative Sequential Recommendation</p>
<p><strong>作者</strong>: Dengzhao Fang、Jingtong Gao、Yu Li、Xiangyu Zhao、等1人</p>
<p><strong>提交时间</strong>: 2026-01-23 16:50</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.16556v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接针对推荐系统的召回与排序统一框架进行创新，提出了解决语义表示质量和生成结构化的新方法，具有较高的技术相关性。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对生成式序列推荐（GSR）中存在的两大关键问题提出了PRISM框架。首先，通过设计净化语义量化器，采用自适应协同去噪和分层语义锚定机制构建鲁棒的码本，解决了语义ID因交互噪声和码本坍缩导致的歧义性问题。其次，提出集成语义推荐器，通过动态语义集成机制融合细粒度语义，并利用语义结构对齐目标增强逻辑有效性，弥补了量化过程中的信息损失。实验表明，PRISM在四个真实数据集上显著优于现有基线，尤其在数据稀疏场景下表现突出。</p>
<hr />
<h2>12. 通过上下文老虎机优化用户档案以实现检索增强的大语言模型个性化</h2>
<p><strong>英文标题</strong>: Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization</p>
<p><strong>作者</strong>: Linfeng Du、Ye Yuan、Zichen Zhao、Fuyuan Lyu、等7人</p>
<p><strong>提交时间</strong>: 2026-01-17 23:05</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.12078v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【4分】 论文核心涉及检索后的重排（ranking）优化，并利用反馈信号（似然）进行学习，与推荐系统的排序和反馈建模高度相关，创新性较强。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对大语言模型个性化响应中，传统基于语义相关性检索用户历史记录的方法存在不足的问题，提出了PURPLE框架。该方法将用户档案构建视为一个集合生成过程，利用Plackett-Luce排序模型来捕捉记录间复杂的依赖关系，而非贪婪地选择最相关记录。通过使用参考响应的似然作为密集反馈进行训练，PURPLE直接将检索与生成质量对齐，在九个个性化任务上的实验表明，其在效果和效率上均优于现有启发式和检索增强基线。</p>
<hr />
<h2>13. 利用大语言模型弥合语义理解与流行度偏差</h2>
<p><strong>英文标题</strong>: Bridging Semantic Understanding and Popularity Bias with LLMs</p>
<p><strong>作者</strong>: Renqiang Luo、Dong Zhang、Yupeng Gao、Wen Shi、等4人</p>
<p><strong>提交时间</strong>: 2026-01-14 21:37</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.09478v3">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 recommendation, diversity, causal</p>
<p><strong>感兴趣评分</strong>: 【4分】 该论文直接涉及推荐系统的核心问题（流行度偏差），并创新性地结合因果推断视角和大语言模型进行语义层面的去偏，与工程师的研究方向高度相关。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对推荐系统中流行度偏差的语义理解这一关键但未被充分探索的挑战，提出了FairLRM框架。该方法创新性地将流行度偏差分解为物品侧和用户侧两个组成部分，并利用基于结构化指令的提示来增强模型对全局物品分布和个体用户偏好的理解。与传统仅关注“多样性”或“去偏”等表层特征的方法不同，FairLRM通过大语言模型（RecLLM）从语义层面深入解读并解决偏差的因果根源，从而在提升公平性的同时保证了推荐准确性。实证评估表明，该框架显著提高了公平性和推荐精度，为流行度偏差的语义理解提供了更可信的解决方案。</p>
<hr />
<h2>14. XProvence：面向检索增强生成的多语言零成本上下文剪枝模型</h2>
<p><strong>英文标题</strong>: XProvence: Zero-Cost Multilingual Context Pruning for Retrieval-Augmented Generation</p>
<p><strong>作者</strong>: Youssef Mohamed、Mohamed Elhoseiny、Thibault Formal、Nadezhda Chirkova</p>
<p><strong>提交时间</strong>: 2026-01-27 03:00</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.18886v1">查看原文</a></p>
<p><strong>所属公司</strong>: NAVER</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, explore</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文核心涉及检索后的重排（re-ranking）技术，这是推荐系统排序阶段的关键组成部分，但其应用场景（多语言RAG上下文剪枝）与典型的商品/内容推荐有差异。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了XProvence模型，这是一种面向检索增强生成（RAG）的多语言零成本上下文剪枝模型。该模型在16种语言上进行训练，并通过有效的跨语言迁移支持100多种语言，旨在将原本仅适用于英语的Provence框架（首次将高效零成本上下文剪枝直接集成到重排模型中）推广到多语言场景。在四个多语言问答基准测试中，XProvence能够在实现最小甚至无性能损失的前提下对RAG上下文进行剪枝，并优于多个强基线模型。</p>
<hr />
<h2>15. 基于大语言模型的金融技术专利实时引文推荐</h2>
<p><strong>英文标题</strong>: LLM-powered Real-time Patent Citation Recommendation for Financial Technologies</p>
<p><strong>作者</strong>: Tianang Deng、Yu Deng、Tianchen Gao、Yonghong Hu、等1人</p>
<p><strong>提交时间</strong>: 2026-01-23 22:21</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.16775v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, recommendation</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及推荐系统的召回（近似最近邻搜索）和排序（语义相似度排序）环节，但未深入探讨重排、价值建模或因果推断等推荐系统核心方向。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对金融技术领域专利快速增长、动态变化的特点，提出了一种实时专利引文推荐框架。该方法采用三阶段流程：首先利用大语言模型（LLM）嵌入表示专利摘要的语义内容；然后通过高效的近似最近邻搜索构建候选集；最后基于语义相似度对候选专利进行排序，生成top-k推荐。核心创新在于采用基于分层可导航小世界（HNSW）图的增量索引策略，支持新专利的实时添加而无需重建整个索引，在动态环境中显著提升了召回率并大幅降低了计算成本。实验表明，该方法在金融专利数据集上优于传统的基于文本的基线方法和替代的最近邻检索方法。</p>
<hr />
<h2>16. Rank4Gen：面向RAG偏好对齐的文档集选择与排序</h2>
<p><strong>英文标题</strong>: Rank4Gen: RAG-Preference-Aligned Document Set Selection and Ranking</p>
<p><strong>作者</strong>: Yongqi Fan、Yuxiang Chu、Zhentao Xia、Xiaoyang Chen、等7人</p>
<p><strong>提交时间</strong>: 2026-01-16 21:19</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.11273v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文聚焦于排序模型与下游任务（生成质量）的对齐优化，与推荐系统中的重排、多目标优化等方向有较强关联，但未直接涉及LTV、因果推断等推荐核心议题。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对RAG（检索增强生成）范式中的信息检索模块，指出现有排序模型主要优化查询-文档相关性，与生成器在证据选择和引用上的偏好存在偏差，从而影响最终响应质量。作者提出Rank4Gen方法，包含两大核心创新：一是将排序优化目标从相关性转向下游响应质量，二是通过单一排序器适配不同生成器，以建模其特定的排序偏好。为支持该研究，作者构建了PRISM数据集，并在五个RAG基准测试中验证了Rank4Gen在复杂证据组合任务上的优越性能。</p>
<hr />
<h2>17. Deep GraphRAG：一种分层检索与自适应融合的平衡方法</h2>
<p><strong>英文标题</strong>: Deep GraphRAG: A Balanced Approach to Hierarchical Retrieval and Adaptive Integration</p>
<p><strong>作者</strong>: Yuejie Li、Ke Yang、Tao Wang、Bolin Chen、等2人</p>
<p><strong>提交时间</strong>: 2026-01-16 18:02</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.11144v2">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【3分】 论文涉及检索、重排和相关性优化，与推荐系统的排序和检索环节相关，但核心聚焦于图检索增强生成而非典型的推荐场景。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对基于图的检索增强生成框架在全局搜索全面性与局部搜索效率之间的权衡问题，提出了Deep GraphRAG框架。其核心创新在于设计了一种从全局到局部的分层检索策略，通过社区间过滤、社区级细化和实体级精细搜索的三阶段过程，结合基于束搜索优化的动态重排模块来平衡效率与全局覆盖。此外，框架引入了一个知识融合模块，采用新颖的强化学习方法动态加权奖励GRPO，动态调整相关性、忠实性和简洁性三个目标的权重，使小型模型在融合任务上能接近大型模型的性能。</p>
<hr />
<h2>18. FinMetaMind：面向金融知识搜索的自然语言查询系统技术蓝图</h2>
<p><strong>英文标题</strong>: FinMetaMind: A Tech Blueprint on NLQ Systems for Financial Knowledge Search</p>
<p><strong>作者</strong>: Lalit Pant、Shivang Nagar</p>
<p><strong>提交时间</strong>: 2026-01-24 14:30</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.17333v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要关注信息检索中的检索和排序技术，与推荐系统的核心方向（如重排、LTV、因果推断）关联较弱。</p>
<p><strong>摘要总结</strong>:<br />
该论文提出了一种面向金融知识搜索的现代自然语言查询（NLQ）系统技术蓝图，旨在通过自然语言处理、搜索工程和向量数据模型等核心技术，提升金融数据检索的准确性和召回率。论文详细阐述了系统架构，包括离线索引和在线检索组件，并针对金融数据特有的实体识别、相关性排序和数据新鲜度等挑战提出了解决方案。创新点在于将NLQ技术专门应用于金融领域，通过高效连接分散的金融对象、事件和关系，为用户提供更深入的洞察，同时论文还提供了实验方法和未来优化方向的详细分析。</p>
<hr />
<h2>19. 大语言模型辅助的伪相关反馈</h2>
<p><strong>英文标题</strong>: LLM-Assisted Pseudo-Relevance Feedback</p>
<p><strong>作者</strong>: David Otero、Javier Parapar</p>
<p><strong>提交时间</strong>: 2026-01-16 20:31</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.11238v1">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要研究信息检索中的查询扩展技术，与推荐系统的核心方向（如重排、LTV、因果推断）关联较弱。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对传统伪相关反馈方法（如RM3）在查询扩展时容易因初始检索结果中的噪声或不相关内容而导致主题漂移的问题，提出了一种结合大语言模型的混合方法。核心创新在于在RM3估计之前引入了一个基于LLM的过滤阶段：LLM对初始排名靠前的文档进行相关性判断，RM3仅基于被判定为相关的文档来计算扩展查询模型。这种方法既保留了经典PRF方法的鲁棒性和可解释性，又利用了LLM的语义判断能力，从而避免了直接使用LLM生成扩展内容可能带来的幻觉或与特定文档集术语不匹配的风险。实验表明，这种简单的干预在多个数据集和指标上均优于盲目的PRF和强基线方法。</p>
<hr />
<h2>20. OpenDecoder：开放大语言模型解码以在RAG中融入文档质量</h2>
<p><strong>英文标题</strong>: OpenDecoder: Open Large Language Model Decoding to Incorporate Document Quality in RAG</p>
<p><strong>作者</strong>: Fengran Mo、Zhan Su、Yuchen Hui、Jinghan Zhang、等5人</p>
<p><strong>提交时间</strong>: 2026-01-14 07:26</p>
<p><strong>文章链接</strong>: <a href="http://arxiv.org/abs/2601.09028v2">查看原文</a></p>
<p><strong>所属公司</strong>: 未知</p>
<p><strong>命中关键词</strong>: 【3】 retrieval, ranking, relevance</p>
<p><strong>感兴趣评分</strong>: 【2分】 论文主要关注信息检索（IR）与LLM生成的结合，虽然涉及“ranking”和“relevance”等关键词，但其核心是RAG系统的生成质量优化，与推荐系统的核心任务（如CTR预估、重排、LTV建模）关联较弱。</p>
<p><strong>摘要总结</strong>:<br />
该论文针对检索增强生成（RAG）中检索信息质量参差不齐的问题，提出了一种名为OpenDecoder的新方法。其核心创新在于，在LLM生成答案时，显式地利用对检索信息的质量评估作为特征，以提升模型对噪声上下文的鲁棒性。具体方法考虑了三种显式评估信息：相关性分数、排序分数和查询性能预测（QPP）分数。实验在五个基准数据集上进行，结果表明OpenDecoder在效果和鲁棒性上均优于多种基线方法，并且该范式灵活，可与任何目的的LLM后训练结合，并融入任何类型的外部指标。</p>
<hr />
        <div class="footer">
            <p><a href="../../index.html">← 返回主页</a></p>
            <p>生成时间: 2026年01月28日 11:48:01</p>
        </div>
    </div>
</body>
</html>